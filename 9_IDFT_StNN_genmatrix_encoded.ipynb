{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parallel IDFT Model on Gen Matrix Encoded Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "8m_ze_Sj4q4A"
      },
      "outputs": [],
      "source": [
        "# (r + 1) | (q - 1)\n",
        "# (r + 1) | n\n",
        "# q is a prime number\n",
        "# n = 2^t\n",
        "# r < n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ccmbx6f4zPw",
        "outputId": "7e95db5b-80d9-4d4d-8def-f060c6c37414"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%reset -f\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "rhVrn-AO40rv"
      },
      "outputs": [],
      "source": [
        "w0 = 4\n",
        "z0 = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "te9xSExt45Xb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "n = 27\n",
        "q = 7\n",
        "num_samples = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Me5-3Y8v42D0",
        "outputId": "66456c64-9b37-4011-98c7-5b0ba643e309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original n: 27\n",
            "Padded n: 32\n",
            "Generated dataset shape: (1000, 32)\n"
          ]
        }
      ],
      "source": [
        "def next_power_of_two(x):\n",
        "    return 1 if x == 0 else 2**(x - 1).bit_length()\n",
        "\n",
        "n_padded = next_power_of_two(n)\n",
        "\n",
        "dataset = np.random.randint(0, q, size=(num_samples, n))\n",
        "\n",
        "if n_padded > n:\n",
        "    pad_width = n_padded - n\n",
        "    dataset = np.pad(dataset, ((0, 0), (0, pad_width)), mode='constant', constant_values=0)\n",
        "\n",
        "print(\"Original n:\", n)\n",
        "print(\"Padded n:\", n_padded)\n",
        "print(\"Generated dataset shape:\", dataset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuGqeiKM453b",
        "outputId": "f2b59284-ea10-4f1b-c64c-956107a9dbe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[6 3 4 ... 0 0 0]\n",
            " [1 5 4 ... 0 0 0]\n",
            " [0 6 1 ... 0 0 0]\n",
            " ...\n",
            " [4 1 1 ... 0 0 0]\n",
            " [6 1 2 ... 0 0 0]\n",
            " [1 5 4 ... 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xcJ1tae4-C0"
      },
      "source": [
        "$$\n",
        "\\tilde{M}_{kj} = \\left[ \\left( \\frac{w_0}{z_0} \\right)^j \\zeta^{kj} \\right]_{k,j=0}^{n-1}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "k7J3o1bA48XS"
      },
      "outputs": [],
      "source": [
        "def padded_generator_matrix(N, w0, z0):\n",
        "    n = np.arange(N)\n",
        "    k = n.reshape((N, 1))\n",
        "    zeta = np.exp(-2j * np.pi / N)\n",
        "    M_tilde = ((w0 / z0) ** n) * (zeta ** (k * n))\n",
        "    return M_tilde"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBG-7uZo4_20",
        "outputId": "f688fde7-c53c-4363-ce80-3f3032d6944b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(32, 32)\n"
          ]
        }
      ],
      "source": [
        "M_tilde = padded_generator_matrix(n_padded, w0, z0)\n",
        "print(M_tilde.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "TWiwL_m35BJQ"
      },
      "outputs": [],
      "source": [
        "encoded_dataset = np.array([np.dot(M_tilde, x) for x in dataset])\n",
        "encoded_dataset[np.abs(encoded_dataset) < 1e-10] = 0\n",
        "encoded_dataset = np.round(encoded_dataset, decimals=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruM0ZOQr5CrT",
        "outputId": "1f90135a-1e43-411e-99fc-9296f12f204b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 32)\n"
          ]
        }
      ],
      "source": [
        "print(encoded_dataset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgk2CBTy5Igf",
        "outputId": "5c2b00f0-eba2-4f73-bcc4-033f16d31800"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[6 3 4 6 2 4 4 6 1 2 6 2 2 4 3 2 5 4 1 3 5 5 1 3 4 0 3 0 0 0 0 0]\n",
            "[18563.60052945    +0.j         -3175.07412411+14542.65392496j\n",
            " -9480.13851167 -1549.89213738j  -850.18419129 -5788.51248279j\n",
            "  2813.63372348 -2457.36436449j  3312.0476391   +337.88077825j\n",
            "  1059.2907911  +3489.68169028j -2366.82367016  +909.74502726j\n",
            "  -210.29906943  +357.85181443j -3878.07651347  +373.95548592j\n",
            "   -49.25036994 -6370.32567308j  6901.71964373 -1088.5938127j\n",
            "  2896.76301761 +7252.43377368j -6714.83312544 +4427.90575271j\n",
            " -5496.28870703 -5330.43278044j  2828.24226801 -6162.17891893j\n",
            "  6446.94186958    -0.j          2828.24226801 +6162.17891893j\n",
            " -5496.28870703 +5330.43278044j -6714.83312544 -4427.90575271j\n",
            "  2896.76301761 -7252.43377368j  6901.71964373 +1088.5938127j\n",
            "   -49.25036994 +6370.32567308j -3878.07651347  -373.95548592j\n",
            "  -210.29906943  -357.85181443j -2366.82367016  -909.74502726j\n",
            "  1059.2907911  -3489.68169028j  3312.0476391   -337.88077825j\n",
            "  2813.63372348 +2457.36436449j  -850.18419129 +5788.51248279j\n",
            " -9480.13851167 +1549.89213738j -3175.07412411-14542.65392496j]\n"
          ]
        }
      ],
      "source": [
        "print(dataset[0])\n",
        "print(encoded_dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPAzs4ML5JtN",
        "outputId": "86085f53-2843-4917-9a72-e62dfb0f02c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "X_train_real : (1000, 32)\n",
            "[18563.6     -3175.0742  -9480.139    -850.1842   2813.6338   3312.0476\n",
            "  1059.2908  -2366.8237   -210.29907 -3878.0764    -49.25037  6901.7197\n",
            "  2896.763   -6714.833   -5496.2886   2828.2422   6446.942    2828.2422\n",
            " -5496.2886  -6714.833    2896.763    6901.7197    -49.25037 -3878.0764\n",
            "  -210.29907 -2366.8237   1059.2908   3312.0476   2813.6338   -850.1842\n",
            " -9480.139   -3175.0742 ]\n",
            "\n",
            "X_train_imag : (1000, 32)\n",
            "[     0.       14542.654    -1549.8921   -5788.5127   -2457.3643\n",
            "    337.88077   3489.6816     909.74506    357.8518     373.95547\n",
            "  -6370.3257   -1088.5939    7252.4336    4427.906    -5330.4326\n",
            "  -6162.1787      -0.        6162.1787    5330.4326   -4427.906\n",
            "  -7252.4336    1088.5939    6370.3257    -373.95547   -357.8518\n",
            "   -909.74506  -3489.6816    -337.88077   2457.3643    5788.5127\n",
            "   1549.8921  -14542.654  ]\n"
          ]
        }
      ],
      "source": [
        "X_real = np.real(encoded_dataset).astype(np.float32)\n",
        "X_imag = np.imag(encoded_dataset).astype(np.float32)\n",
        "\n",
        "print(\"\\nX_train_real :\", X_real.shape)\n",
        "print(X_real[0])\n",
        "print(\"\\nX_train_imag :\", X_imag.shape)\n",
        "print(X_imag[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ9O-pNK5LPX",
        "outputId": "604a0e7a-10be-408b-affe-065cad560067"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.         0.5        0.6666667  1.         0.33333334 0.6666667\n",
            " 0.6666667  1.         0.16666667 0.33333334 1.         0.33333334\n",
            " 0.33333334 0.6666667  0.5        0.33333334 0.8333333  0.6666667\n",
            " 0.16666667 0.5        0.8333333  0.8333333  0.16666667 0.5\n",
            " 0.6666667  0.         0.5        0.         0.         0.\n",
            " 0.         0.        ]\n"
          ]
        }
      ],
      "source": [
        "y = dataset.astype(np.float32)\n",
        "y_normalized = y / (q - 1)  # Scale to [0, 1]\n",
        "\n",
        "print(y_normalized[0])\n",
        "\n",
        "labels = y_normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTSgp2pR5U3a",
        "outputId": "f096ec9c-ef0d-4ee4-ebcf-419a170de153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shapes: X_real: (800, 32) X_imag: (800, 32) y: (800, 32)\n",
            "Testing data shapes: X_real: (200, 32) X_imag: (200, 32) y: (200, 32)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_real_train, X_real_test, y_train, y_test = train_test_split(\n",
        "    X_real, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X_imag_train, X_imag_test, _, _ = train_test_split(\n",
        "    X_imag, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training data shapes: X_real:\", X_real_train.shape, \"X_imag:\", X_imag_train.shape, \"y:\", y_train.shape)\n",
        "print(\"Testing data shapes: X_real:\", X_real_test.shape, \"X_imag:\", X_imag_test.shape, \"y:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "KOHGgxkC5XwY"
      },
      "outputs": [],
      "source": [
        "# Normalize real part\n",
        "real_mean = np.mean(X_real_train, axis=0)\n",
        "real_std = np.std(X_real_train, axis=0)\n",
        "X_real_train = (X_real_train - real_mean) / (real_std + 1e-8)\n",
        "X_real_test = (X_real_test - real_mean) / (real_std + 1e-8)\n",
        "\n",
        "# Normalize imag part\n",
        "imag_mean = np.mean(X_imag_train, axis=0)\n",
        "imag_std = np.std(X_imag_train, axis=0)\n",
        "X_imag_train = (X_imag_train - imag_mean) / (imag_std + 1e-8)\n",
        "X_imag_test = (X_imag_test - imag_mean) / (imag_std + 1e-8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqr4Z1EV6AZ9"
      },
      "source": [
        "IDFT - Structure Imposed Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "YhDWyV9M6AuE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "Ip1i_Iab6CVu"
      },
      "outputs": [],
      "source": [
        "class IDFT(tf.keras.layers.Layer):\n",
        "    def __init__(self, n, kernel_initializer='he_normal', trainable=True, **kwargs):\n",
        "        super(IDFT, self).__init__(**kwargs)\n",
        "        self.n = n\n",
        "        self.n1 = n // 2\n",
        "        self.trainable = trainable\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "\n",
        "        if n == 2:\n",
        "            self.F_2 = self.add_weight(\n",
        "                shape=(2, 2),\n",
        "                initializer=tf.keras.initializers.Constant([[0.5, 0.5], [0.5, -0.5]]),\n",
        "                trainable=self.trainable,\n",
        "                name='F_2'\n",
        "            )\n",
        "        else:\n",
        "            self.idft1 = IDFT(self.n1, trainable=self.trainable)\n",
        "            self.idft2 = IDFT(self.n1, trainable=self.trainable)\n",
        "\n",
        "            self.Dn = self.add_weight(\n",
        "                shape=(self.n1,),\n",
        "                initializer=tf.keras.initializers.get(self.kernel_initializer),\n",
        "                trainable=self.trainable,\n",
        "                name='Dn'\n",
        "            )\n",
        "\n",
        "    def call(self, x):\n",
        "        if self.n == 2:\n",
        "            return tf.matmul(x, self.F_2)\n",
        "\n",
        "        even = x[:, ::2]\n",
        "        odd = x[:, 1::2]\n",
        "\n",
        "        B1 = self.idft1(even)\n",
        "        B2 = self.idft2(odd)\n",
        "\n",
        "        Dn_scaled = tf.multiply(B2, self.Dn)\n",
        "\n",
        "        sum_part = B1 + Dn_scaled\n",
        "        diff_part = B1 - Dn_scaled\n",
        "\n",
        "        out = tf.concat([sum_part, diff_part], axis=1) / tf.sqrt(tf.constant(2.0, dtype=tf.float32))\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "NnX9oB2-6GVp"
      },
      "outputs": [],
      "source": [
        "class FirstIDFTLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, kernel_initializer='he_normal', bias_initializer='zeros', trainable=True, **kwargs):\n",
        "        super(FirstIDFTLayer, self).__init__(**kwargs)\n",
        "        self.n = units\n",
        "        self.n1 = units // 2\n",
        "        self.trainable = trainable\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.bias_initializer = bias_initializer\n",
        "\n",
        "        self.b1 = IDFT(self.n1, kernel_initializer=self.kernel_initializer, trainable=self.trainable)\n",
        "        self.b2 = IDFT(self.n1, kernel_initializer=self.kernel_initializer, trainable=self.trainable)\n",
        "\n",
        "        self.bias = self.add_weight(\n",
        "            shape=(units,),\n",
        "            initializer=tf.keras.initializers.get(self.bias_initializer),\n",
        "            trainable=True,\n",
        "            name='bias'\n",
        "        )\n",
        "\n",
        "    def call(self, x):\n",
        "      q = tf.concat([x[:, ::2], x[:, 1::2]], axis=1)\n",
        "      B1 = self.b1(q[:, :self.n1])\n",
        "      B2 = self.b2(q[:, self.n1:])\n",
        "      out = tf.concat([B1, B2], axis=1)\n",
        "\n",
        "      return out + self.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "8JU2xoi46Imn"
      },
      "outputs": [],
      "source": [
        "class SecondIDFTLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, kernel_initializer='he_normal', bias_initializer='zeros', trainable=True, **kwargs):\n",
        "        super(SecondIDFTLayer, self).__init__(**kwargs)\n",
        "        self.n = units\n",
        "        self.n1 = units // 2\n",
        "        self.trainable = trainable\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.bias_initializer = bias_initializer\n",
        "\n",
        "        self.Dn = self.add_weight(\n",
        "                shape=(self.n1,),\n",
        "                initializer=tf.keras.initializers.get(self.kernel_initializer),\n",
        "                trainable=self.trainable,\n",
        "                name='Dn'\n",
        "            )\n",
        "\n",
        "        self.bias = self.add_weight(\n",
        "            shape=(units,),\n",
        "            initializer=tf.keras.initializers.get(self.bias_initializer),\n",
        "            trainable=True,\n",
        "            name='bias'\n",
        "        )\n",
        "\n",
        "    def call(self, x):\n",
        "        x1 = x[:, :self.n1]\n",
        "        x2 = x[:, self.n1:]\n",
        "\n",
        "        Dn_scaled = tf.multiply(x2, self.Dn)\n",
        "\n",
        "        sum_part = x1 + Dn_scaled\n",
        "        diff_part = x1 - Dn_scaled\n",
        "\n",
        "        out = tf.concat([sum_part, diff_part], axis=1) / tf.sqrt(tf.constant(2.0, dtype=tf.float32))\n",
        "\n",
        "        return out + self.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "FD3tKDxV6yTv"
      },
      "outputs": [],
      "source": [
        "class DiagonalLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, kernel_initializer='he_normal', bias_initializer='zeros', use_bias=True, **kwargs):\n",
        "        super(DiagonalLayer, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.bias_initializer = bias_initializer\n",
        "        self.use_bias = use_bias\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        n = self.units\n",
        "\n",
        "        self.m = self.add_weight(name=\"kernel_m\",\n",
        "                                 shape=(n,),\n",
        "                                 initializer=tf.keras.initializers.get(self.kernel_initializer),\n",
        "                                 trainable=True)\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(name=\"bias\",\n",
        "                                        shape=(self.units,),\n",
        "                                        initializer=tf.keras.initializers.get(self.bias_initializer),\n",
        "                                        trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        out = tf.multiply(inputs, self.m)\n",
        "        if self.use_bias:\n",
        "            out += self.bias\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "GAIISW2C63qj"
      },
      "outputs": [],
      "source": [
        "class ScalingLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, initial_scale=0.1, kernel_initializer='ones', bias_initializer='zeros', use_bias=True, **kwargs):\n",
        "        super(ScalingLayer, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.bias_initializer = bias_initializer\n",
        "        self.use_bias = use_bias\n",
        "        self.initial_scale = initial_scale\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        n = self.units\n",
        "\n",
        "        self.m = self.add_weight(name=\"kernel_m_1\",\n",
        "                                 shape=(n,),\n",
        "                                 initializer=tf.keras.initializers.get(self.kernel_initializer),\n",
        "                                 regularizer=tf.keras.regularizers.l2(1e-4),\n",
        "                                 trainable=True)\n",
        "\n",
        "        self.log_scale = self.add_weight(\n",
        "                                  shape=(),\n",
        "                                  initializer=tf.keras.initializers.Constant(self.initial_scale),\n",
        "                                  trainable=True,\n",
        "                                  name=\"log_scale\",\n",
        "                                  )\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(name=\"bias\",\n",
        "                                        shape=(self.units,),\n",
        "                                        initializer=tf.keras.initializers.get(self.bias_initializer),\n",
        "                                        trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        inputs1 = inputs[:, :int(inputs.shape[1] / 2)]\n",
        "        inputs2 = inputs[:, int(inputs.shape[1] / 2):]\n",
        "\n",
        "        out = tf.math.sqrt(inputs1**2 + inputs2**2)\n",
        "\n",
        "        dim = tf.shape(out)[1]\n",
        "        D_hat_n = tf.exp(self.log_scale * tf.cast(tf.range(dim), tf.float32))\n",
        "\n",
        "        out2 = out * D_hat_n * self.m\n",
        "\n",
        "        if self.use_bias:\n",
        "            out2 += self.bias\n",
        "\n",
        "        return out2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZE0QuJE7W6R"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "LysmDMtv7YEB"
      },
      "outputs": [],
      "source": [
        "def custom_accuracy(y_true, y_pred):\n",
        "    y_true_int = tf.cast(y_true*(q-1), tf.int32)\n",
        "    y_pred_int = tf.cast(tf.round(y_pred*(q-1)), tf.int32)\n",
        "    correct = tf.cast(tf.equal(y_true_int, y_pred_int), tf.float32)\n",
        "    return tf.reduce_mean(correct)\n",
        "\n",
        "def custom_accuracy_without_padding(y_true, y_pred):\n",
        "    y_true_int = tf.cast(y_true * (q - 1), tf.int32)\n",
        "    y_pred_int = tf.cast(tf.round(y_pred * (q - 1)), tf.int32)\n",
        "    mask = tf.concat(\n",
        "        [tf.ones((tf.shape(y_true)[0], n), dtype=tf.float32),\n",
        "         tf.zeros((tf.shape(y_true)[0], n_padded - n), dtype=tf.float32)],\n",
        "        axis=1\n",
        "    )\n",
        "    correct = tf.cast(tf.equal(y_true_int, y_pred_int), tf.float32) * mask\n",
        "    return tf.reduce_sum(correct) / tf.reduce_sum(mask)\n",
        "\n",
        "def custom_mse(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    # weights = 1.0 / (1.0 + tf.abs(y_true))\n",
        "    # loss = tf.reduce_mean(weights * tf.square(y_true - y_pred))\n",
        "    loss = tf.reduce_mean(tf.square(tf.cast(y_true - y_pred, tf.float32)))\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 993
        },
        "id": "AONwiXc1692g",
        "outputId": "94ac03d6-c8b5-4eff-85c2-0fbfc6ed7546"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ real_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ imag_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ real_layer1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │ real_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">FirstIDFTLayer</span>)          │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ imag_layer1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │ imag_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">FirstIDFTLayer</span>)          │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_13            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ real_layer1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_16            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ imag_layer1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ real_support_layer_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ leaky_re_lu_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DiagonalLayer</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ imag_support_layer_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ leaky_re_lu_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DiagonalLayer</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_14            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ real_support_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_17            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ imag_support_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ real_layer2               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │ leaky_re_lu_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SecondIDFTLayer</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ imag_layer2               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │ leaky_re_lu_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SecondIDFTLayer</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_15            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ real_layer2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_18            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ imag_layer2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ merge_real_imag           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ leaky_re_lu_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ scaling_layer             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ merge_real_imag[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ScalingLayer</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_19            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ scaling_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ output_layer              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ leaky_re_lu_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DiagonalLayer</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ output_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ real_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ imag_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ real_layer1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │            \u001b[38;5;34m144\u001b[0m │ real_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mFirstIDFTLayer\u001b[0m)          │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ imag_layer1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │            \u001b[38;5;34m144\u001b[0m │ imag_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mFirstIDFTLayer\u001b[0m)          │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_13            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ real_layer1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_16            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ imag_layer1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ real_support_layer_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m64\u001b[0m │ leaky_re_lu_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mDiagonalLayer\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ imag_support_layer_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m64\u001b[0m │ leaky_re_lu_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mDiagonalLayer\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_14            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ real_support_layer_1[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_17            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ imag_support_layer_1[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ real_layer2               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m48\u001b[0m │ leaky_re_lu_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSecondIDFTLayer\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ imag_layer2               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m48\u001b[0m │ leaky_re_lu_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSecondIDFTLayer\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_15            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ real_layer2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_18            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ imag_layer2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ merge_real_imag           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ leaky_re_lu_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ scaling_layer             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m65\u001b[0m │ merge_real_imag[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mScalingLayer\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_19            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ scaling_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ output_layer              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m64\u001b[0m │ leaky_re_lu_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mDiagonalLayer\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ output_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">641</span> (2.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m641\u001b[0m (2.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">577</span> (2.25 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m577\u001b[0m (2.25 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Concatenate, LeakyReLU, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "global initial_log_scale\n",
        "initial_log_scale = np.log(z0 / w0)\n",
        "\n",
        "def structured_NN(input_dim, output_dim):\n",
        "    real_input = Input(shape=(input_dim,), name=\"real_input\")\n",
        "    imag_input = Input(shape=(input_dim,), name=\"imag_input\")\n",
        "\n",
        "    real_x = FirstIDFTLayer(units=input_dim, kernel_initializer='he_normal', bias_initializer='zeros', name=\"real_layer1\")(real_input)\n",
        "    real_x = LeakyReLU(negative_slope=0.1)(real_x)\n",
        "    real_x = DiagonalLayer(units=input_dim, kernel_initializer='he_normal', bias_initializer='zeros', name=\"real_support_layer_1\")(real_x)\n",
        "    real_x = LeakyReLU(negative_slope=0.1)(real_x)\n",
        "    real_x = SecondIDFTLayer(units=input_dim, kernel_initializer='he_normal', bias_initializer='zeros', name=\"real_layer2\")(real_x)\n",
        "    real_x = LeakyReLU(negative_slope=0.1)(real_x)\n",
        "\n",
        "    imag_x = FirstIDFTLayer(units=input_dim, kernel_initializer='he_normal', bias_initializer='zeros', name=\"imag_layer1\")(imag_input)\n",
        "    imag_x = LeakyReLU(negative_slope=0.1)(imag_x)\n",
        "    imag_x = DiagonalLayer(units=input_dim, kernel_initializer='he_normal', bias_initializer='zeros', name=\"imag_support_layer_1\")(imag_x)\n",
        "    imag_x = LeakyReLU(negative_slope=0.1)(imag_x)\n",
        "    imag_x = SecondIDFTLayer(units=input_dim, kernel_initializer='he_normal', bias_initializer='zeros', name=\"imag_layer2\")(imag_x)\n",
        "    imag_x = LeakyReLU(negative_slope=0.1)(imag_x)\n",
        "\n",
        "    merged = Concatenate(name=\"merge_real_imag\")([real_x, imag_x])\n",
        "\n",
        "    output = ScalingLayer(units=output_dim, initial_scale=initial_log_scale, kernel_initializer='ones', bias_initializer='zeros', name=\"scaling_layer\")(merged)\n",
        "    output = LeakyReLU(negative_slope=0.1)(output)\n",
        "    output = DiagonalLayer(units=output_dim, trainable=False, kernel_initializer='ones', bias_initializer='zeros', name=\"output_layer\")(output)\n",
        "    output = Activation('linear')(output)\n",
        "\n",
        "    model = Model(inputs=[real_input, imag_input], outputs=output)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss=custom_mse, metrics=[custom_mse, custom_accuracy_without_padding])\n",
        "\n",
        "    return model\n",
        "\n",
        "input_dim = X_real_train.shape[1]\n",
        "output_dim = y_train.shape[1]\n",
        "model = structured_NN(input_dim, output_dim)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6uKLzpY7MRQ"
      },
      "source": [
        "Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "ITd5fVNW7M-3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "adjust_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=5,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJU4uyCJ7NoL",
        "outputId": "61611bc7-1baf-4355-ac83-d175803fd702"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - custom_accuracy_without_padding: 0.1429 - custom_mse: 0.2951 - loss: 0.2983 - val_custom_accuracy_without_padding: 0.1501 - val_custom_mse: 0.2679 - val_loss: 0.2716 - learning_rate: 0.0010\n",
            "Epoch 2/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.1419 - custom_mse: 0.2710 - loss: 0.2741 - val_custom_accuracy_without_padding: 0.1500 - val_custom_mse: 0.2400 - val_loss: 0.2437 - learning_rate: 0.0010\n",
            "Epoch 3/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.1421 - custom_mse: 0.2416 - loss: 0.2447 - val_custom_accuracy_without_padding: 0.1485 - val_custom_mse: 0.2116 - val_loss: 0.2155 - learning_rate: 0.0010\n",
            "Epoch 4/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.1418 - custom_mse: 0.2129 - loss: 0.2160 - val_custom_accuracy_without_padding: 0.1538 - val_custom_mse: 0.1811 - val_loss: 0.1851 - learning_rate: 0.0010\n",
            "Epoch 5/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.1426 - custom_mse: 0.1813 - loss: 0.1845 - val_custom_accuracy_without_padding: 0.1481 - val_custom_mse: 0.1461 - val_loss: 0.1503 - learning_rate: 0.0010\n",
            "Epoch 6/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.1426 - custom_mse: 0.1403 - loss: 0.1437 - val_custom_accuracy_without_padding: 0.1417 - val_custom_mse: 0.1116 - val_loss: 0.1156 - learning_rate: 0.0010\n",
            "Epoch 7/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.1397 - custom_mse: 0.1074 - loss: 0.1110 - val_custom_accuracy_without_padding: 0.1396 - val_custom_mse: 0.0991 - val_loss: 0.1028 - learning_rate: 0.0010\n",
            "Epoch 8/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.1437 - custom_mse: 0.0969 - loss: 0.1005 - val_custom_accuracy_without_padding: 0.1338 - val_custom_mse: 0.0944 - val_loss: 0.0981 - learning_rate: 0.0010\n",
            "Epoch 9/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - custom_accuracy_without_padding: 0.1462 - custom_mse: 0.0937 - loss: 0.0972 - val_custom_accuracy_without_padding: 0.1329 - val_custom_mse: 0.0929 - val_loss: 0.0965 - learning_rate: 0.0010\n",
            "Epoch 10/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.1433 - custom_mse: 0.0921 - loss: 0.0956 - val_custom_accuracy_without_padding: 0.1310 - val_custom_mse: 0.0919 - val_loss: 0.0955 - learning_rate: 0.0010\n",
            "Epoch 11/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.1479 - custom_mse: 0.0911 - loss: 0.0946 - val_custom_accuracy_without_padding: 0.1306 - val_custom_mse: 0.0910 - val_loss: 0.0945 - learning_rate: 0.0010\n",
            "Epoch 12/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - custom_accuracy_without_padding: 0.1475 - custom_mse: 0.0901 - loss: 0.0935 - val_custom_accuracy_without_padding: 0.1359 - val_custom_mse: 0.0903 - val_loss: 0.0936 - learning_rate: 0.0010\n",
            "Epoch 13/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - custom_accuracy_without_padding: 0.1464 - custom_mse: 0.0903 - loss: 0.0936 - val_custom_accuracy_without_padding: 0.1396 - val_custom_mse: 0.0894 - val_loss: 0.0928 - learning_rate: 0.0010\n",
            "Epoch 14/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - custom_accuracy_without_padding: 0.1571 - custom_mse: 0.0886 - loss: 0.0919 - val_custom_accuracy_without_padding: 0.1488 - val_custom_mse: 0.0887 - val_loss: 0.0920 - learning_rate: 0.0010\n",
            "Epoch 15/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - custom_accuracy_without_padding: 0.1591 - custom_mse: 0.0877 - loss: 0.0910 - val_custom_accuracy_without_padding: 0.1551 - val_custom_mse: 0.0877 - val_loss: 0.0909 - learning_rate: 0.0010\n",
            "Epoch 16/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.1630 - custom_mse: 0.0869 - loss: 0.0901 - val_custom_accuracy_without_padding: 0.1574 - val_custom_mse: 0.0867 - val_loss: 0.0899 - learning_rate: 0.0010\n",
            "Epoch 17/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - custom_accuracy_without_padding: 0.1628 - custom_mse: 0.0860 - loss: 0.0892 - val_custom_accuracy_without_padding: 0.1589 - val_custom_mse: 0.0857 - val_loss: 0.0888 - learning_rate: 0.0010\n",
            "Epoch 18/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.1672 - custom_mse: 0.0851 - loss: 0.0883 - val_custom_accuracy_without_padding: 0.1662 - val_custom_mse: 0.0848 - val_loss: 0.0879 - learning_rate: 0.0010\n",
            "Epoch 19/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.1763 - custom_mse: 0.0842 - loss: 0.0874 - val_custom_accuracy_without_padding: 0.1670 - val_custom_mse: 0.0838 - val_loss: 0.0868 - learning_rate: 0.0010\n",
            "Epoch 20/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.1811 - custom_mse: 0.0839 - loss: 0.0869 - val_custom_accuracy_without_padding: 0.1835 - val_custom_mse: 0.0830 - val_loss: 0.0859 - learning_rate: 0.0010\n",
            "Epoch 21/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.1926 - custom_mse: 0.0826 - loss: 0.0856 - val_custom_accuracy_without_padding: 0.1887 - val_custom_mse: 0.0821 - val_loss: 0.0850 - learning_rate: 0.0010\n",
            "Epoch 22/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.1913 - custom_mse: 0.0815 - loss: 0.0845 - val_custom_accuracy_without_padding: 0.1923 - val_custom_mse: 0.0812 - val_loss: 0.0841 - learning_rate: 0.0010\n",
            "Epoch 23/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.1988 - custom_mse: 0.0800 - loss: 0.0830 - val_custom_accuracy_without_padding: 0.1928 - val_custom_mse: 0.0802 - val_loss: 0.0830 - learning_rate: 0.0010\n",
            "Epoch 24/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.2028 - custom_mse: 0.0804 - loss: 0.0833 - val_custom_accuracy_without_padding: 0.1963 - val_custom_mse: 0.0791 - val_loss: 0.0819 - learning_rate: 0.0010\n",
            "Epoch 25/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.2110 - custom_mse: 0.0774 - loss: 0.0803 - val_custom_accuracy_without_padding: 0.1986 - val_custom_mse: 0.0779 - val_loss: 0.0808 - learning_rate: 0.0010\n",
            "Epoch 26/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - custom_accuracy_without_padding: 0.2127 - custom_mse: 0.0768 - loss: 0.0797 - val_custom_accuracy_without_padding: 0.2059 - val_custom_mse: 0.0767 - val_loss: 0.0796 - learning_rate: 0.0010\n",
            "Epoch 27/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.2223 - custom_mse: 0.0757 - loss: 0.0785 - val_custom_accuracy_without_padding: 0.2113 - val_custom_mse: 0.0758 - val_loss: 0.0786 - learning_rate: 0.0010\n",
            "Epoch 28/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.2248 - custom_mse: 0.0748 - loss: 0.0776 - val_custom_accuracy_without_padding: 0.2202 - val_custom_mse: 0.0750 - val_loss: 0.0778 - learning_rate: 0.0010\n",
            "Epoch 29/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.2392 - custom_mse: 0.0729 - loss: 0.0757 - val_custom_accuracy_without_padding: 0.2292 - val_custom_mse: 0.0740 - val_loss: 0.0768 - learning_rate: 0.0010\n",
            "Epoch 30/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.2396 - custom_mse: 0.0737 - loss: 0.0764 - val_custom_accuracy_without_padding: 0.2356 - val_custom_mse: 0.0733 - val_loss: 0.0760 - learning_rate: 0.0010\n",
            "Epoch 31/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.2472 - custom_mse: 0.0723 - loss: 0.0750 - val_custom_accuracy_without_padding: 0.2404 - val_custom_mse: 0.0723 - val_loss: 0.0750 - learning_rate: 0.0010\n",
            "Epoch 32/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.2554 - custom_mse: 0.0719 - loss: 0.0746 - val_custom_accuracy_without_padding: 0.2464 - val_custom_mse: 0.0714 - val_loss: 0.0741 - learning_rate: 0.0010\n",
            "Epoch 33/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.2581 - custom_mse: 0.0711 - loss: 0.0738 - val_custom_accuracy_without_padding: 0.2485 - val_custom_mse: 0.0706 - val_loss: 0.0733 - learning_rate: 0.0010\n",
            "Epoch 34/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.2669 - custom_mse: 0.0693 - loss: 0.0720 - val_custom_accuracy_without_padding: 0.2564 - val_custom_mse: 0.0698 - val_loss: 0.0725 - learning_rate: 0.0010\n",
            "Epoch 35/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.2716 - custom_mse: 0.0691 - loss: 0.0717 - val_custom_accuracy_without_padding: 0.2622 - val_custom_mse: 0.0693 - val_loss: 0.0720 - learning_rate: 0.0010\n",
            "Epoch 36/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.2770 - custom_mse: 0.0694 - loss: 0.0720 - val_custom_accuracy_without_padding: 0.2677 - val_custom_mse: 0.0688 - val_loss: 0.0714 - learning_rate: 0.0010\n",
            "Epoch 37/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.2827 - custom_mse: 0.0683 - loss: 0.0709 - val_custom_accuracy_without_padding: 0.2745 - val_custom_mse: 0.0683 - val_loss: 0.0709 - learning_rate: 0.0010\n",
            "Epoch 38/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.2849 - custom_mse: 0.0673 - loss: 0.0698 - val_custom_accuracy_without_padding: 0.2753 - val_custom_mse: 0.0680 - val_loss: 0.0705 - learning_rate: 0.0010\n",
            "Epoch 39/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - custom_accuracy_without_padding: 0.2932 - custom_mse: 0.0666 - loss: 0.0691 - val_custom_accuracy_without_padding: 0.2817 - val_custom_mse: 0.0678 - val_loss: 0.0703 - learning_rate: 0.0010\n",
            "Epoch 40/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - custom_accuracy_without_padding: 0.2982 - custom_mse: 0.0667 - loss: 0.0692 - val_custom_accuracy_without_padding: 0.2865 - val_custom_mse: 0.0674 - val_loss: 0.0698 - learning_rate: 0.0010\n",
            "Epoch 41/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - custom_accuracy_without_padding: 0.2975 - custom_mse: 0.0670 - loss: 0.0695 - val_custom_accuracy_without_padding: 0.2880 - val_custom_mse: 0.0673 - val_loss: 0.0697 - learning_rate: 0.0010\n",
            "Epoch 42/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - custom_accuracy_without_padding: 0.3050 - custom_mse: 0.0663 - loss: 0.0687 - val_custom_accuracy_without_padding: 0.2978 - val_custom_mse: 0.0669 - val_loss: 0.0694 - learning_rate: 0.0010\n",
            "Epoch 43/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - custom_accuracy_without_padding: 0.3080 - custom_mse: 0.0657 - loss: 0.0681 - val_custom_accuracy_without_padding: 0.3042 - val_custom_mse: 0.0667 - val_loss: 0.0691 - learning_rate: 0.0010\n",
            "Epoch 44/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.3140 - custom_mse: 0.0661 - loss: 0.0685 - val_custom_accuracy_without_padding: 0.3052 - val_custom_mse: 0.0666 - val_loss: 0.0690 - learning_rate: 0.0010\n",
            "Epoch 45/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.3150 - custom_mse: 0.0659 - loss: 0.0683 - val_custom_accuracy_without_padding: 0.3113 - val_custom_mse: 0.0664 - val_loss: 0.0687 - learning_rate: 0.0010\n",
            "Epoch 46/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.3257 - custom_mse: 0.0656 - loss: 0.0679 - val_custom_accuracy_without_padding: 0.3102 - val_custom_mse: 0.0662 - val_loss: 0.0685 - learning_rate: 0.0010\n",
            "Epoch 47/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.3193 - custom_mse: 0.0644 - loss: 0.0667 - val_custom_accuracy_without_padding: 0.3173 - val_custom_mse: 0.0660 - val_loss: 0.0683 - learning_rate: 0.0010\n",
            "Epoch 48/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.3275 - custom_mse: 0.0642 - loss: 0.0665 - val_custom_accuracy_without_padding: 0.3218 - val_custom_mse: 0.0658 - val_loss: 0.0681 - learning_rate: 0.0010\n",
            "Epoch 49/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.3234 - custom_mse: 0.0653 - loss: 0.0676 - val_custom_accuracy_without_padding: 0.3249 - val_custom_mse: 0.0656 - val_loss: 0.0679 - learning_rate: 0.0010\n",
            "Epoch 50/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.3311 - custom_mse: 0.0653 - loss: 0.0675 - val_custom_accuracy_without_padding: 0.3257 - val_custom_mse: 0.0654 - val_loss: 0.0677 - learning_rate: 0.0010\n",
            "Epoch 51/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.3332 - custom_mse: 0.0642 - loss: 0.0665 - val_custom_accuracy_without_padding: 0.3292 - val_custom_mse: 0.0652 - val_loss: 0.0673 - learning_rate: 0.0010\n",
            "Epoch 52/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.3361 - custom_mse: 0.0644 - loss: 0.0666 - val_custom_accuracy_without_padding: 0.3299 - val_custom_mse: 0.0649 - val_loss: 0.0670 - learning_rate: 0.0010\n",
            "Epoch 53/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.3388 - custom_mse: 0.0641 - loss: 0.0663 - val_custom_accuracy_without_padding: 0.3335 - val_custom_mse: 0.0645 - val_loss: 0.0666 - learning_rate: 0.0010\n",
            "Epoch 54/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.3394 - custom_mse: 0.0636 - loss: 0.0658 - val_custom_accuracy_without_padding: 0.3353 - val_custom_mse: 0.0643 - val_loss: 0.0663 - learning_rate: 0.0010\n",
            "Epoch 55/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.3429 - custom_mse: 0.0628 - loss: 0.0649 - val_custom_accuracy_without_padding: 0.3376 - val_custom_mse: 0.0640 - val_loss: 0.0660 - learning_rate: 0.0010\n",
            "Epoch 56/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.3475 - custom_mse: 0.0623 - loss: 0.0645 - val_custom_accuracy_without_padding: 0.3396 - val_custom_mse: 0.0637 - val_loss: 0.0657 - learning_rate: 0.0010\n",
            "Epoch 57/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.3470 - custom_mse: 0.0621 - loss: 0.0642 - val_custom_accuracy_without_padding: 0.3421 - val_custom_mse: 0.0634 - val_loss: 0.0654 - learning_rate: 0.0010\n",
            "Epoch 58/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.3469 - custom_mse: 0.0621 - loss: 0.0642 - val_custom_accuracy_without_padding: 0.3438 - val_custom_mse: 0.0632 - val_loss: 0.0651 - learning_rate: 0.0010\n",
            "Epoch 59/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.3542 - custom_mse: 0.0613 - loss: 0.0633 - val_custom_accuracy_without_padding: 0.3451 - val_custom_mse: 0.0629 - val_loss: 0.0649 - learning_rate: 0.0010\n",
            "Epoch 60/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.3514 - custom_mse: 0.0618 - loss: 0.0638 - val_custom_accuracy_without_padding: 0.3482 - val_custom_mse: 0.0627 - val_loss: 0.0646 - learning_rate: 0.0010\n",
            "Epoch 61/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.3542 - custom_mse: 0.0619 - loss: 0.0640 - val_custom_accuracy_without_padding: 0.3507 - val_custom_mse: 0.0624 - val_loss: 0.0643 - learning_rate: 0.0010\n",
            "Epoch 62/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.3579 - custom_mse: 0.0613 - loss: 0.0633 - val_custom_accuracy_without_padding: 0.3510 - val_custom_mse: 0.0622 - val_loss: 0.0641 - learning_rate: 0.0010\n",
            "Epoch 63/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.3618 - custom_mse: 0.0604 - loss: 0.0624 - val_custom_accuracy_without_padding: 0.3527 - val_custom_mse: 0.0621 - val_loss: 0.0639 - learning_rate: 0.0010\n",
            "Epoch 64/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.3625 - custom_mse: 0.0608 - loss: 0.0628 - val_custom_accuracy_without_padding: 0.3543 - val_custom_mse: 0.0619 - val_loss: 0.0637 - learning_rate: 0.0010\n",
            "Epoch 65/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.3608 - custom_mse: 0.0605 - loss: 0.0625 - val_custom_accuracy_without_padding: 0.3603 - val_custom_mse: 0.0616 - val_loss: 0.0633 - learning_rate: 0.0010\n",
            "Epoch 66/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.3662 - custom_mse: 0.0604 - loss: 0.0623 - val_custom_accuracy_without_padding: 0.3634 - val_custom_mse: 0.0614 - val_loss: 0.0632 - learning_rate: 0.0010\n",
            "Epoch 67/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.3696 - custom_mse: 0.0601 - loss: 0.0620 - val_custom_accuracy_without_padding: 0.3633 - val_custom_mse: 0.0612 - val_loss: 0.0629 - learning_rate: 0.0010\n",
            "Epoch 68/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.3738 - custom_mse: 0.0601 - loss: 0.0620 - val_custom_accuracy_without_padding: 0.3661 - val_custom_mse: 0.0610 - val_loss: 0.0627 - learning_rate: 0.0010\n",
            "Epoch 69/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.3708 - custom_mse: 0.0603 - loss: 0.0622 - val_custom_accuracy_without_padding: 0.3714 - val_custom_mse: 0.0609 - val_loss: 0.0625 - learning_rate: 0.0010\n",
            "Epoch 70/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.3766 - custom_mse: 0.0596 - loss: 0.0615 - val_custom_accuracy_without_padding: 0.3729 - val_custom_mse: 0.0606 - val_loss: 0.0623 - learning_rate: 0.0010\n",
            "Epoch 71/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.3799 - custom_mse: 0.0596 - loss: 0.0614 - val_custom_accuracy_without_padding: 0.3742 - val_custom_mse: 0.0605 - val_loss: 0.0621 - learning_rate: 0.0010\n",
            "Epoch 72/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.3790 - custom_mse: 0.0591 - loss: 0.0609 - val_custom_accuracy_without_padding: 0.3770 - val_custom_mse: 0.0602 - val_loss: 0.0618 - learning_rate: 0.0010\n",
            "Epoch 73/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - custom_accuracy_without_padding: 0.3781 - custom_mse: 0.0588 - loss: 0.0606 - val_custom_accuracy_without_padding: 0.3791 - val_custom_mse: 0.0600 - val_loss: 0.0616 - learning_rate: 0.0010\n",
            "Epoch 74/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - custom_accuracy_without_padding: 0.3837 - custom_mse: 0.0586 - loss: 0.0604 - val_custom_accuracy_without_padding: 0.3791 - val_custom_mse: 0.0599 - val_loss: 0.0614 - learning_rate: 0.0010\n",
            "Epoch 75/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - custom_accuracy_without_padding: 0.3870 - custom_mse: 0.0586 - loss: 0.0604 - val_custom_accuracy_without_padding: 0.3816 - val_custom_mse: 0.0597 - val_loss: 0.0612 - learning_rate: 0.0010\n",
            "Epoch 76/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - custom_accuracy_without_padding: 0.3851 - custom_mse: 0.0587 - loss: 0.0604 - val_custom_accuracy_without_padding: 0.3824 - val_custom_mse: 0.0594 - val_loss: 0.0608 - learning_rate: 0.0010\n",
            "Epoch 77/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.3815 - custom_mse: 0.0592 - loss: 0.0609 - val_custom_accuracy_without_padding: 0.3862 - val_custom_mse: 0.0592 - val_loss: 0.0606 - learning_rate: 0.0010\n",
            "Epoch 78/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.3886 - custom_mse: 0.0572 - loss: 0.0589 - val_custom_accuracy_without_padding: 0.3867 - val_custom_mse: 0.0590 - val_loss: 0.0604 - learning_rate: 0.0010\n",
            "Epoch 79/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.3905 - custom_mse: 0.0578 - loss: 0.0595 - val_custom_accuracy_without_padding: 0.3867 - val_custom_mse: 0.0588 - val_loss: 0.0601 - learning_rate: 0.0010\n",
            "Epoch 80/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.3911 - custom_mse: 0.0565 - loss: 0.0582 - val_custom_accuracy_without_padding: 0.3836 - val_custom_mse: 0.0587 - val_loss: 0.0600 - learning_rate: 0.0010\n",
            "Epoch 81/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.3887 - custom_mse: 0.0572 - loss: 0.0589 - val_custom_accuracy_without_padding: 0.3859 - val_custom_mse: 0.0584 - val_loss: 0.0597 - learning_rate: 0.0010\n",
            "Epoch 82/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.3903 - custom_mse: 0.0571 - loss: 0.0587 - val_custom_accuracy_without_padding: 0.3897 - val_custom_mse: 0.0581 - val_loss: 0.0593 - learning_rate: 0.0010\n",
            "Epoch 83/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.3931 - custom_mse: 0.0562 - loss: 0.0578 - val_custom_accuracy_without_padding: 0.3894 - val_custom_mse: 0.0578 - val_loss: 0.0591 - learning_rate: 0.0010\n",
            "Epoch 84/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.3966 - custom_mse: 0.0555 - loss: 0.0571 - val_custom_accuracy_without_padding: 0.3902 - val_custom_mse: 0.0576 - val_loss: 0.0588 - learning_rate: 0.0010\n",
            "Epoch 85/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - custom_accuracy_without_padding: 0.4014 - custom_mse: 0.0559 - loss: 0.0575 - val_custom_accuracy_without_padding: 0.3934 - val_custom_mse: 0.0574 - val_loss: 0.0586 - learning_rate: 0.0010\n",
            "Epoch 86/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4017 - custom_mse: 0.0563 - loss: 0.0579 - val_custom_accuracy_without_padding: 0.3965 - val_custom_mse: 0.0572 - val_loss: 0.0584 - learning_rate: 0.0010\n",
            "Epoch 87/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4019 - custom_mse: 0.0560 - loss: 0.0576 - val_custom_accuracy_without_padding: 0.3945 - val_custom_mse: 0.0569 - val_loss: 0.0580 - learning_rate: 0.0010\n",
            "Epoch 88/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4023 - custom_mse: 0.0555 - loss: 0.0571 - val_custom_accuracy_without_padding: 0.3985 - val_custom_mse: 0.0567 - val_loss: 0.0579 - learning_rate: 0.0010\n",
            "Epoch 89/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - custom_accuracy_without_padding: 0.4065 - custom_mse: 0.0547 - loss: 0.0563 - val_custom_accuracy_without_padding: 0.3993 - val_custom_mse: 0.0567 - val_loss: 0.0578 - learning_rate: 0.0010\n",
            "Epoch 90/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4113 - custom_mse: 0.0549 - loss: 0.0565 - val_custom_accuracy_without_padding: 0.4041 - val_custom_mse: 0.0564 - val_loss: 0.0575 - learning_rate: 0.0010\n",
            "Epoch 91/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4113 - custom_mse: 0.0544 - loss: 0.0560 - val_custom_accuracy_without_padding: 0.4038 - val_custom_mse: 0.0565 - val_loss: 0.0575 - learning_rate: 0.0010\n",
            "Epoch 92/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4118 - custom_mse: 0.0556 - loss: 0.0571 - val_custom_accuracy_without_padding: 0.4079 - val_custom_mse: 0.0563 - val_loss: 0.0574 - learning_rate: 0.0010\n",
            "Epoch 93/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4172 - custom_mse: 0.0544 - loss: 0.0559 - val_custom_accuracy_without_padding: 0.4074 - val_custom_mse: 0.0561 - val_loss: 0.0572 - learning_rate: 0.0010\n",
            "Epoch 94/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4172 - custom_mse: 0.0551 - loss: 0.0566 - val_custom_accuracy_without_padding: 0.4150 - val_custom_mse: 0.0560 - val_loss: 0.0571 - learning_rate: 0.0010\n",
            "Epoch 95/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - custom_accuracy_without_padding: 0.4198 - custom_mse: 0.0551 - loss: 0.0565 - val_custom_accuracy_without_padding: 0.4147 - val_custom_mse: 0.0560 - val_loss: 0.0570 - learning_rate: 0.0010\n",
            "Epoch 96/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4263 - custom_mse: 0.0540 - loss: 0.0555 - val_custom_accuracy_without_padding: 0.4203 - val_custom_mse: 0.0561 - val_loss: 0.0571 - learning_rate: 0.0010\n",
            "Epoch 97/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - custom_accuracy_without_padding: 0.4282 - custom_mse: 0.0540 - loss: 0.0555 - val_custom_accuracy_without_padding: 0.4244 - val_custom_mse: 0.0560 - val_loss: 0.0570 - learning_rate: 0.0010\n",
            "Epoch 98/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - custom_accuracy_without_padding: 0.4291 - custom_mse: 0.0547 - loss: 0.0561 - val_custom_accuracy_without_padding: 0.4256 - val_custom_mse: 0.0558 - val_loss: 0.0569 - learning_rate: 0.0010\n",
            "Epoch 99/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4264 - custom_mse: 0.0549 - loss: 0.0563 - val_custom_accuracy_without_padding: 0.4284 - val_custom_mse: 0.0558 - val_loss: 0.0568 - learning_rate: 0.0010\n",
            "Epoch 100/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - custom_accuracy_without_padding: 0.4322 - custom_mse: 0.0539 - loss: 0.0553 - val_custom_accuracy_without_padding: 0.4330 - val_custom_mse: 0.0557 - val_loss: 0.0567 - learning_rate: 0.0010\n",
            "Epoch 101/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - custom_accuracy_without_padding: 0.4316 - custom_mse: 0.0546 - loss: 0.0561 - val_custom_accuracy_without_padding: 0.4320 - val_custom_mse: 0.0557 - val_loss: 0.0567 - learning_rate: 0.0010\n",
            "Epoch 102/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - custom_accuracy_without_padding: 0.4365 - custom_mse: 0.0541 - loss: 0.0555 - val_custom_accuracy_without_padding: 0.4306 - val_custom_mse: 0.0557 - val_loss: 0.0567 - learning_rate: 0.0010\n",
            "Epoch 103/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - custom_accuracy_without_padding: 0.4349 - custom_mse: 0.0545 - loss: 0.0559 - val_custom_accuracy_without_padding: 0.4354 - val_custom_mse: 0.0557 - val_loss: 0.0566 - learning_rate: 0.0010\n",
            "Epoch 104/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4384 - custom_mse: 0.0538 - loss: 0.0552 - val_custom_accuracy_without_padding: 0.4314 - val_custom_mse: 0.0556 - val_loss: 0.0566 - learning_rate: 0.0010\n",
            "Epoch 105/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4388 - custom_mse: 0.0538 - loss: 0.0552 - val_custom_accuracy_without_padding: 0.4349 - val_custom_mse: 0.0555 - val_loss: 0.0565 - learning_rate: 0.0010\n",
            "Epoch 106/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4407 - custom_mse: 0.0539 - loss: 0.0553 - val_custom_accuracy_without_padding: 0.4349 - val_custom_mse: 0.0554 - val_loss: 0.0564 - learning_rate: 0.0010\n",
            "Epoch 107/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4409 - custom_mse: 0.0540 - loss: 0.0553 - val_custom_accuracy_without_padding: 0.4368 - val_custom_mse: 0.0554 - val_loss: 0.0563 - learning_rate: 0.0010\n",
            "Epoch 108/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4413 - custom_mse: 0.0540 - loss: 0.0554 - val_custom_accuracy_without_padding: 0.4408 - val_custom_mse: 0.0554 - val_loss: 0.0563 - learning_rate: 0.0010\n",
            "Epoch 109/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4421 - custom_mse: 0.0540 - loss: 0.0554 - val_custom_accuracy_without_padding: 0.4410 - val_custom_mse: 0.0554 - val_loss: 0.0563 - learning_rate: 0.0010\n",
            "Epoch 110/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4413 - custom_mse: 0.0544 - loss: 0.0557 - val_custom_accuracy_without_padding: 0.4401 - val_custom_mse: 0.0553 - val_loss: 0.0562 - learning_rate: 0.0010\n",
            "Epoch 111/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4428 - custom_mse: 0.0541 - loss: 0.0554 - val_custom_accuracy_without_padding: 0.4415 - val_custom_mse: 0.0552 - val_loss: 0.0561 - learning_rate: 0.0010\n",
            "Epoch 112/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4419 - custom_mse: 0.0535 - loss: 0.0548 - val_custom_accuracy_without_padding: 0.4408 - val_custom_mse: 0.0552 - val_loss: 0.0561 - learning_rate: 0.0010\n",
            "Epoch 113/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - custom_accuracy_without_padding: 0.4461 - custom_mse: 0.0533 - loss: 0.0546 - val_custom_accuracy_without_padding: 0.4398 - val_custom_mse: 0.0552 - val_loss: 0.0561 - learning_rate: 0.0010\n",
            "Epoch 114/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4498 - custom_mse: 0.0538 - loss: 0.0551 - val_custom_accuracy_without_padding: 0.4416 - val_custom_mse: 0.0551 - val_loss: 0.0560 - learning_rate: 0.0010\n",
            "Epoch 115/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4441 - custom_mse: 0.0542 - loss: 0.0555 - val_custom_accuracy_without_padding: 0.4453 - val_custom_mse: 0.0551 - val_loss: 0.0560 - learning_rate: 0.0010\n",
            "Epoch 116/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4471 - custom_mse: 0.0540 - loss: 0.0552 - val_custom_accuracy_without_padding: 0.4411 - val_custom_mse: 0.0551 - val_loss: 0.0559 - learning_rate: 0.0010\n",
            "Epoch 117/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4456 - custom_mse: 0.0532 - loss: 0.0544 - val_custom_accuracy_without_padding: 0.4436 - val_custom_mse: 0.0551 - val_loss: 0.0560 - learning_rate: 0.0010\n",
            "Epoch 118/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - custom_accuracy_without_padding: 0.4503 - custom_mse: 0.0533 - loss: 0.0546 - val_custom_accuracy_without_padding: 0.4430 - val_custom_mse: 0.0549 - val_loss: 0.0558 - learning_rate: 0.0010\n",
            "Epoch 119/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4483 - custom_mse: 0.0536 - loss: 0.0548 - val_custom_accuracy_without_padding: 0.4466 - val_custom_mse: 0.0551 - val_loss: 0.0559 - learning_rate: 0.0010\n",
            "Epoch 120/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4537 - custom_mse: 0.0537 - loss: 0.0549 - val_custom_accuracy_without_padding: 0.4453 - val_custom_mse: 0.0550 - val_loss: 0.0558 - learning_rate: 0.0010\n",
            "Epoch 121/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4476 - custom_mse: 0.0541 - loss: 0.0553 - val_custom_accuracy_without_padding: 0.4444 - val_custom_mse: 0.0549 - val_loss: 0.0558 - learning_rate: 0.0010\n",
            "Epoch 122/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.4462 - custom_mse: 0.0541 - loss: 0.0553 - val_custom_accuracy_without_padding: 0.4463 - val_custom_mse: 0.0549 - val_loss: 0.0557 - learning_rate: 0.0010\n",
            "Epoch 123/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4509 - custom_mse: 0.0535 - loss: 0.0547 - val_custom_accuracy_without_padding: 0.4466 - val_custom_mse: 0.0548 - val_loss: 0.0556 - learning_rate: 0.0010\n",
            "Epoch 124/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - custom_accuracy_without_padding: 0.4517 - custom_mse: 0.0538 - loss: 0.0550 - val_custom_accuracy_without_padding: 0.4469 - val_custom_mse: 0.0549 - val_loss: 0.0557 - learning_rate: 0.0010\n",
            "Epoch 125/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - custom_accuracy_without_padding: 0.4552 - custom_mse: 0.0535 - loss: 0.0547 - val_custom_accuracy_without_padding: 0.4449 - val_custom_mse: 0.0548 - val_loss: 0.0556 - learning_rate: 0.0010\n",
            "Epoch 126/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4489 - custom_mse: 0.0529 - loss: 0.0541 - val_custom_accuracy_without_padding: 0.4492 - val_custom_mse: 0.0548 - val_loss: 0.0556 - learning_rate: 0.0010\n",
            "Epoch 127/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4549 - custom_mse: 0.0531 - loss: 0.0543 - val_custom_accuracy_without_padding: 0.4516 - val_custom_mse: 0.0546 - val_loss: 0.0554 - learning_rate: 0.0010\n",
            "Epoch 128/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4562 - custom_mse: 0.0532 - loss: 0.0544 - val_custom_accuracy_without_padding: 0.4517 - val_custom_mse: 0.0547 - val_loss: 0.0554 - learning_rate: 0.0010\n",
            "Epoch 129/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - custom_accuracy_without_padding: 0.4580 - custom_mse: 0.0533 - loss: 0.0544 - val_custom_accuracy_without_padding: 0.4491 - val_custom_mse: 0.0546 - val_loss: 0.0554 - learning_rate: 0.0010\n",
            "Epoch 130/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4530 - custom_mse: 0.0536 - loss: 0.0548 - val_custom_accuracy_without_padding: 0.4454 - val_custom_mse: 0.0545 - val_loss: 0.0553 - learning_rate: 0.0010\n",
            "Epoch 131/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - custom_accuracy_without_padding: 0.4557 - custom_mse: 0.0538 - loss: 0.0549 - val_custom_accuracy_without_padding: 0.4496 - val_custom_mse: 0.0546 - val_loss: 0.0553 - learning_rate: 0.0010\n",
            "Epoch 132/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4579 - custom_mse: 0.0531 - loss: 0.0542 - val_custom_accuracy_without_padding: 0.4517 - val_custom_mse: 0.0545 - val_loss: 0.0552 - learning_rate: 0.0010\n",
            "Epoch 133/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4601 - custom_mse: 0.0525 - loss: 0.0536 - val_custom_accuracy_without_padding: 0.4544 - val_custom_mse: 0.0544 - val_loss: 0.0551 - learning_rate: 0.0010\n",
            "Epoch 134/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4595 - custom_mse: 0.0529 - loss: 0.0541 - val_custom_accuracy_without_padding: 0.4549 - val_custom_mse: 0.0543 - val_loss: 0.0550 - learning_rate: 0.0010\n",
            "Epoch 135/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - custom_accuracy_without_padding: 0.4624 - custom_mse: 0.0533 - loss: 0.0544 - val_custom_accuracy_without_padding: 0.4562 - val_custom_mse: 0.0542 - val_loss: 0.0549 - learning_rate: 0.0010\n",
            "Epoch 136/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.4640 - custom_mse: 0.0530 - loss: 0.0541 - val_custom_accuracy_without_padding: 0.4563 - val_custom_mse: 0.0543 - val_loss: 0.0549 - learning_rate: 0.0010\n",
            "Epoch 137/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.4618 - custom_mse: 0.0524 - loss: 0.0535 - val_custom_accuracy_without_padding: 0.4595 - val_custom_mse: 0.0541 - val_loss: 0.0548 - learning_rate: 0.0010\n",
            "Epoch 138/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.4637 - custom_mse: 0.0528 - loss: 0.0539 - val_custom_accuracy_without_padding: 0.4582 - val_custom_mse: 0.0540 - val_loss: 0.0546 - learning_rate: 0.0010\n",
            "Epoch 139/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4586 - custom_mse: 0.0532 - loss: 0.0543 - val_custom_accuracy_without_padding: 0.4590 - val_custom_mse: 0.0539 - val_loss: 0.0546 - learning_rate: 0.0010\n",
            "Epoch 140/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4690 - custom_mse: 0.0517 - loss: 0.0528 - val_custom_accuracy_without_padding: 0.4592 - val_custom_mse: 0.0538 - val_loss: 0.0545 - learning_rate: 0.0010\n",
            "Epoch 141/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4643 - custom_mse: 0.0530 - loss: 0.0541 - val_custom_accuracy_without_padding: 0.4608 - val_custom_mse: 0.0539 - val_loss: 0.0545 - learning_rate: 0.0010\n",
            "Epoch 142/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4694 - custom_mse: 0.0527 - loss: 0.0537 - val_custom_accuracy_without_padding: 0.4605 - val_custom_mse: 0.0539 - val_loss: 0.0545 - learning_rate: 0.0010\n",
            "Epoch 143/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4660 - custom_mse: 0.0524 - loss: 0.0535 - val_custom_accuracy_without_padding: 0.4618 - val_custom_mse: 0.0537 - val_loss: 0.0543 - learning_rate: 0.0010\n",
            "Epoch 144/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4706 - custom_mse: 0.0526 - loss: 0.0536 - val_custom_accuracy_without_padding: 0.4628 - val_custom_mse: 0.0535 - val_loss: 0.0541 - learning_rate: 0.0010\n",
            "Epoch 145/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.4672 - custom_mse: 0.0526 - loss: 0.0536 - val_custom_accuracy_without_padding: 0.4640 - val_custom_mse: 0.0535 - val_loss: 0.0540 - learning_rate: 0.0010\n",
            "Epoch 146/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.4668 - custom_mse: 0.0519 - loss: 0.0529 - val_custom_accuracy_without_padding: 0.4623 - val_custom_mse: 0.0534 - val_loss: 0.0540 - learning_rate: 0.0010\n",
            "Epoch 147/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - custom_accuracy_without_padding: 0.4677 - custom_mse: 0.0523 - loss: 0.0533 - val_custom_accuracy_without_padding: 0.4625 - val_custom_mse: 0.0534 - val_loss: 0.0540 - learning_rate: 0.0010\n",
            "Epoch 148/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - custom_accuracy_without_padding: 0.4637 - custom_mse: 0.0528 - loss: 0.0538 - val_custom_accuracy_without_padding: 0.4646 - val_custom_mse: 0.0533 - val_loss: 0.0539 - learning_rate: 0.0010\n",
            "Epoch 149/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - custom_accuracy_without_padding: 0.4670 - custom_mse: 0.0519 - loss: 0.0529 - val_custom_accuracy_without_padding: 0.4628 - val_custom_mse: 0.0532 - val_loss: 0.0538 - learning_rate: 0.0010\n",
            "Epoch 150/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - custom_accuracy_without_padding: 0.4682 - custom_mse: 0.0524 - loss: 0.0534 - val_custom_accuracy_without_padding: 0.4658 - val_custom_mse: 0.0531 - val_loss: 0.0537 - learning_rate: 0.0010\n",
            "Epoch 151/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4696 - custom_mse: 0.0517 - loss: 0.0526 - val_custom_accuracy_without_padding: 0.4621 - val_custom_mse: 0.0532 - val_loss: 0.0537 - learning_rate: 0.0010\n",
            "Epoch 152/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - custom_accuracy_without_padding: 0.4698 - custom_mse: 0.0519 - loss: 0.0529 - val_custom_accuracy_without_padding: 0.4635 - val_custom_mse: 0.0530 - val_loss: 0.0535 - learning_rate: 0.0010\n",
            "Epoch 153/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.4682 - custom_mse: 0.0522 - loss: 0.0531 - val_custom_accuracy_without_padding: 0.4645 - val_custom_mse: 0.0529 - val_loss: 0.0535 - learning_rate: 0.0010\n",
            "Epoch 154/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.4688 - custom_mse: 0.0515 - loss: 0.0525 - val_custom_accuracy_without_padding: 0.4658 - val_custom_mse: 0.0530 - val_loss: 0.0535 - learning_rate: 0.0010\n",
            "Epoch 155/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4717 - custom_mse: 0.0515 - loss: 0.0525 - val_custom_accuracy_without_padding: 0.4661 - val_custom_mse: 0.0529 - val_loss: 0.0534 - learning_rate: 0.0010\n",
            "Epoch 156/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - custom_accuracy_without_padding: 0.4696 - custom_mse: 0.0520 - loss: 0.0530 - val_custom_accuracy_without_padding: 0.4654 - val_custom_mse: 0.0528 - val_loss: 0.0534 - learning_rate: 0.0010\n",
            "Epoch 157/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - custom_accuracy_without_padding: 0.4703 - custom_mse: 0.0520 - loss: 0.0529 - val_custom_accuracy_without_padding: 0.4678 - val_custom_mse: 0.0527 - val_loss: 0.0532 - learning_rate: 0.0010\n",
            "Epoch 158/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.4681 - custom_mse: 0.0519 - loss: 0.0528 - val_custom_accuracy_without_padding: 0.4635 - val_custom_mse: 0.0527 - val_loss: 0.0533 - learning_rate: 0.0010\n",
            "Epoch 159/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4699 - custom_mse: 0.0517 - loss: 0.0526 - val_custom_accuracy_without_padding: 0.4666 - val_custom_mse: 0.0529 - val_loss: 0.0534 - learning_rate: 0.0010\n",
            "Epoch 160/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4697 - custom_mse: 0.0519 - loss: 0.0528 - val_custom_accuracy_without_padding: 0.4683 - val_custom_mse: 0.0526 - val_loss: 0.0531 - learning_rate: 0.0010\n",
            "Epoch 161/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.4703 - custom_mse: 0.0522 - loss: 0.0531 - val_custom_accuracy_without_padding: 0.4674 - val_custom_mse: 0.0527 - val_loss: 0.0532 - learning_rate: 0.0010\n",
            "Epoch 162/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.4693 - custom_mse: 0.0518 - loss: 0.0528 - val_custom_accuracy_without_padding: 0.4688 - val_custom_mse: 0.0525 - val_loss: 0.0530 - learning_rate: 0.0010\n",
            "Epoch 163/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4696 - custom_mse: 0.0517 - loss: 0.0526 - val_custom_accuracy_without_padding: 0.4694 - val_custom_mse: 0.0524 - val_loss: 0.0529 - learning_rate: 0.0010\n",
            "Epoch 164/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.4694 - custom_mse: 0.0519 - loss: 0.0528 - val_custom_accuracy_without_padding: 0.4689 - val_custom_mse: 0.0526 - val_loss: 0.0530 - learning_rate: 0.0010\n",
            "Epoch 165/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.4720 - custom_mse: 0.0513 - loss: 0.0522 - val_custom_accuracy_without_padding: 0.4669 - val_custom_mse: 0.0523 - val_loss: 0.0528 - learning_rate: 0.0010\n",
            "Epoch 166/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4689 - custom_mse: 0.0519 - loss: 0.0528 - val_custom_accuracy_without_padding: 0.4663 - val_custom_mse: 0.0523 - val_loss: 0.0528 - learning_rate: 0.0010\n",
            "Epoch 167/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.4729 - custom_mse: 0.0510 - loss: 0.0519 - val_custom_accuracy_without_padding: 0.4668 - val_custom_mse: 0.0524 - val_loss: 0.0528 - learning_rate: 0.0010\n",
            "Epoch 168/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.4706 - custom_mse: 0.0512 - loss: 0.0521 - val_custom_accuracy_without_padding: 0.4678 - val_custom_mse: 0.0523 - val_loss: 0.0528 - learning_rate: 0.0010\n",
            "Epoch 169/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4714 - custom_mse: 0.0514 - loss: 0.0523 - val_custom_accuracy_without_padding: 0.4714 - val_custom_mse: 0.0522 - val_loss: 0.0527 - learning_rate: 0.0010\n",
            "Epoch 170/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4715 - custom_mse: 0.0512 - loss: 0.0521 - val_custom_accuracy_without_padding: 0.4717 - val_custom_mse: 0.0522 - val_loss: 0.0527 - learning_rate: 0.0010\n",
            "Epoch 171/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4760 - custom_mse: 0.0509 - loss: 0.0518 - val_custom_accuracy_without_padding: 0.4714 - val_custom_mse: 0.0523 - val_loss: 0.0528 - learning_rate: 0.0010\n",
            "Epoch 172/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4710 - custom_mse: 0.0515 - loss: 0.0524 - val_custom_accuracy_without_padding: 0.4735 - val_custom_mse: 0.0521 - val_loss: 0.0526 - learning_rate: 0.0010\n",
            "Epoch 173/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4775 - custom_mse: 0.0513 - loss: 0.0522 - val_custom_accuracy_without_padding: 0.4691 - val_custom_mse: 0.0521 - val_loss: 0.0526 - learning_rate: 0.0010\n",
            "Epoch 174/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.4694 - custom_mse: 0.0511 - loss: 0.0519 - val_custom_accuracy_without_padding: 0.4716 - val_custom_mse: 0.0521 - val_loss: 0.0526 - learning_rate: 0.0010\n",
            "Epoch 175/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.4744 - custom_mse: 0.0509 - loss: 0.0518 - val_custom_accuracy_without_padding: 0.4727 - val_custom_mse: 0.0519 - val_loss: 0.0524 - learning_rate: 0.0010\n",
            "Epoch 176/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.4751 - custom_mse: 0.0507 - loss: 0.0516 - val_custom_accuracy_without_padding: 0.4719 - val_custom_mse: 0.0520 - val_loss: 0.0525 - learning_rate: 0.0010\n",
            "Epoch 177/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - custom_accuracy_without_padding: 0.4750 - custom_mse: 0.0512 - loss: 0.0520 - val_custom_accuracy_without_padding: 0.4711 - val_custom_mse: 0.0522 - val_loss: 0.0527 - learning_rate: 0.0010\n",
            "Epoch 178/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - custom_accuracy_without_padding: 0.4758 - custom_mse: 0.0515 - loss: 0.0523 - val_custom_accuracy_without_padding: 0.4732 - val_custom_mse: 0.0520 - val_loss: 0.0525 - learning_rate: 0.0010\n",
            "Epoch 179/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - custom_accuracy_without_padding: 0.4742 - custom_mse: 0.0513 - loss: 0.0521 - val_custom_accuracy_without_padding: 0.4717 - val_custom_mse: 0.0519 - val_loss: 0.0524 - learning_rate: 0.0010\n",
            "Epoch 180/500\n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.4737 - custom_mse: 0.0511 - loss: 0.0519\n",
            "Epoch 180: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - custom_accuracy_without_padding: 0.4738 - custom_mse: 0.0511 - loss: 0.0519 - val_custom_accuracy_without_padding: 0.4754 - val_custom_mse: 0.0520 - val_loss: 0.0525 - learning_rate: 0.0010\n",
            "Epoch 181/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - custom_accuracy_without_padding: 0.4764 - custom_mse: 0.0508 - loss: 0.0516 - val_custom_accuracy_without_padding: 0.4711 - val_custom_mse: 0.0518 - val_loss: 0.0523 - learning_rate: 5.0000e-04\n",
            "Epoch 182/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - custom_accuracy_without_padding: 0.4775 - custom_mse: 0.0506 - loss: 0.0514 - val_custom_accuracy_without_padding: 0.4749 - val_custom_mse: 0.0518 - val_loss: 0.0523 - learning_rate: 5.0000e-04\n",
            "Epoch 183/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4750 - custom_mse: 0.0509 - loss: 0.0517 - val_custom_accuracy_without_padding: 0.4721 - val_custom_mse: 0.0518 - val_loss: 0.0523 - learning_rate: 5.0000e-04\n",
            "Epoch 184/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - custom_accuracy_without_padding: 0.4758 - custom_mse: 0.0509 - loss: 0.0517 - val_custom_accuracy_without_padding: 0.4724 - val_custom_mse: 0.0518 - val_loss: 0.0523 - learning_rate: 5.0000e-04\n",
            "Epoch 185/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4770 - custom_mse: 0.0506 - loss: 0.0514 - val_custom_accuracy_without_padding: 0.4739 - val_custom_mse: 0.0518 - val_loss: 0.0523 - learning_rate: 5.0000e-04\n",
            "Epoch 186/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.4729 - custom_mse: 0.0507 - loss: 0.0515 - val_custom_accuracy_without_padding: 0.4737 - val_custom_mse: 0.0517 - val_loss: 0.0522 - learning_rate: 5.0000e-04\n",
            "Epoch 187/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.4785 - custom_mse: 0.0507 - loss: 0.0515 - val_custom_accuracy_without_padding: 0.4757 - val_custom_mse: 0.0517 - val_loss: 0.0522 - learning_rate: 5.0000e-04\n",
            "Epoch 188/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4787 - custom_mse: 0.0507 - loss: 0.0515 - val_custom_accuracy_without_padding: 0.4759 - val_custom_mse: 0.0517 - val_loss: 0.0522 - learning_rate: 5.0000e-04\n",
            "Epoch 189/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - custom_accuracy_without_padding: 0.4769 - custom_mse: 0.0508 - loss: 0.0516 - val_custom_accuracy_without_padding: 0.4754 - val_custom_mse: 0.0517 - val_loss: 0.0522 - learning_rate: 5.0000e-04\n",
            "Epoch 190/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4774 - custom_mse: 0.0504 - loss: 0.0512 - val_custom_accuracy_without_padding: 0.4737 - val_custom_mse: 0.0517 - val_loss: 0.0522 - learning_rate: 5.0000e-04\n",
            "Epoch 191/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.4778 - custom_mse: 0.0512 - loss: 0.0520\n",
            "Epoch 191: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4778 - custom_mse: 0.0512 - loss: 0.0520 - val_custom_accuracy_without_padding: 0.4777 - val_custom_mse: 0.0517 - val_loss: 0.0521 - learning_rate: 5.0000e-04\n",
            "Epoch 192/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - custom_accuracy_without_padding: 0.4777 - custom_mse: 0.0505 - loss: 0.0512 - val_custom_accuracy_without_padding: 0.4765 - val_custom_mse: 0.0517 - val_loss: 0.0522 - learning_rate: 2.5000e-04\n",
            "Epoch 193/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - custom_accuracy_without_padding: 0.4770 - custom_mse: 0.0511 - loss: 0.0519 - val_custom_accuracy_without_padding: 0.4770 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 2.5000e-04\n",
            "Epoch 194/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4769 - custom_mse: 0.0503 - loss: 0.0511 - val_custom_accuracy_without_padding: 0.4769 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 2.5000e-04\n",
            "Epoch 195/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.4782 - custom_mse: 0.0511 - loss: 0.0518 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0517 - val_loss: 0.0521 - learning_rate: 2.5000e-04\n",
            "Epoch 196/500\n",
            "\u001b[1m20/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.4789 - custom_mse: 0.0507 - loss: 0.0515\n",
            "Epoch 196: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4787 - custom_mse: 0.0507 - loss: 0.0515 - val_custom_accuracy_without_padding: 0.4772 - val_custom_mse: 0.0517 - val_loss: 0.0521 - learning_rate: 2.5000e-04\n",
            "Epoch 197/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4767 - custom_mse: 0.0512 - loss: 0.0519 - val_custom_accuracy_without_padding: 0.4759 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 1.2500e-04\n",
            "Epoch 198/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4791 - custom_mse: 0.0505 - loss: 0.0513 - val_custom_accuracy_without_padding: 0.4755 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 1.2500e-04\n",
            "Epoch 199/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4812 - custom_mse: 0.0506 - loss: 0.0514 - val_custom_accuracy_without_padding: 0.4767 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 1.2500e-04\n",
            "Epoch 200/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4812 - custom_mse: 0.0506 - loss: 0.0514 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 1.2500e-04\n",
            "Epoch 201/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4797 - custom_mse: 0.0507 - loss: 0.0514 - val_custom_accuracy_without_padding: 0.4765 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 1.2500e-04\n",
            "Epoch 202/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4782 - custom_mse: 0.0502 - loss: 0.0510 - val_custom_accuracy_without_padding: 0.4754 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 1.2500e-04\n",
            "Epoch 203/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - custom_accuracy_without_padding: 0.4766 - custom_mse: 0.0508 - loss: 0.0515 - val_custom_accuracy_without_padding: 0.4773 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 1.2500e-04\n",
            "Epoch 204/500\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - custom_accuracy_without_padding: 0.4769 - custom_mse: 0.0512 - loss: 0.0520\n",
            "Epoch 204: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - custom_accuracy_without_padding: 0.4770 - custom_mse: 0.0512 - loss: 0.0520 - val_custom_accuracy_without_padding: 0.4765 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 1.2500e-04\n",
            "Epoch 205/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - custom_accuracy_without_padding: 0.4822 - custom_mse: 0.0507 - loss: 0.0514 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 6.2500e-05\n",
            "Epoch 206/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - custom_accuracy_without_padding: 0.4770 - custom_mse: 0.0509 - loss: 0.0516 - val_custom_accuracy_without_padding: 0.4765 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 6.2500e-05\n",
            "Epoch 207/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - custom_accuracy_without_padding: 0.4755 - custom_mse: 0.0509 - loss: 0.0517 - val_custom_accuracy_without_padding: 0.4765 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 6.2500e-05\n",
            "Epoch 208/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4776 - custom_mse: 0.0504 - loss: 0.0512 - val_custom_accuracy_without_padding: 0.4754 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 6.2500e-05\n",
            "Epoch 209/500\n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.4764 - custom_mse: 0.0513 - loss: 0.0521\n",
            "Epoch 209: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4768 - custom_mse: 0.0512 - loss: 0.0520 - val_custom_accuracy_without_padding: 0.4757 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 6.2500e-05\n",
            "Epoch 210/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - custom_accuracy_without_padding: 0.4775 - custom_mse: 0.0509 - loss: 0.0517 - val_custom_accuracy_without_padding: 0.4760 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 3.1250e-05\n",
            "Epoch 211/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - custom_accuracy_without_padding: 0.4809 - custom_mse: 0.0501 - loss: 0.0509 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 3.1250e-05\n",
            "Epoch 212/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4817 - custom_mse: 0.0497 - loss: 0.0505 - val_custom_accuracy_without_padding: 0.4760 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 3.1250e-05\n",
            "Epoch 213/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4776 - custom_mse: 0.0504 - loss: 0.0512 - val_custom_accuracy_without_padding: 0.4760 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 3.1250e-05\n",
            "Epoch 214/500\n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.4853 - custom_mse: 0.0494 - loss: 0.0501\n",
            "Epoch 214: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - custom_accuracy_without_padding: 0.4840 - custom_mse: 0.0496 - loss: 0.0504 - val_custom_accuracy_without_padding: 0.4759 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 3.1250e-05\n",
            "Epoch 215/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4800 - custom_mse: 0.0501 - loss: 0.0508 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 1.5625e-05\n",
            "Epoch 216/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4786 - custom_mse: 0.0505 - loss: 0.0513 - val_custom_accuracy_without_padding: 0.4760 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 1.5625e-05\n",
            "Epoch 217/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.4772 - custom_mse: 0.0511 - loss: 0.0518 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 1.5625e-05\n",
            "Epoch 218/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4821 - custom_mse: 0.0501 - loss: 0.0509 - val_custom_accuracy_without_padding: 0.4764 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 1.5625e-05\n",
            "Epoch 219/500\n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.4806 - custom_mse: 0.0505 - loss: 0.0512\n",
            "Epoch 219: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - custom_accuracy_without_padding: 0.4803 - custom_mse: 0.0505 - loss: 0.0513 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 1.5625e-05\n",
            "Epoch 220/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4777 - custom_mse: 0.0513 - loss: 0.0521 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 7.8125e-06\n",
            "Epoch 221/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4766 - custom_mse: 0.0510 - loss: 0.0517 - val_custom_accuracy_without_padding: 0.4760 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 7.8125e-06\n",
            "Epoch 222/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4796 - custom_mse: 0.0506 - loss: 0.0513 - val_custom_accuracy_without_padding: 0.4760 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 7.8125e-06\n",
            "Epoch 223/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4792 - custom_mse: 0.0506 - loss: 0.0514 - val_custom_accuracy_without_padding: 0.4760 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 7.8125e-06\n",
            "Epoch 224/500\n",
            "\u001b[1m20/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.4816 - custom_mse: 0.0497 - loss: 0.0505\n",
            "Epoch 224: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.4809 - custom_mse: 0.0499 - loss: 0.0507 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 7.8125e-06\n",
            "Epoch 225/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - custom_accuracy_without_padding: 0.4771 - custom_mse: 0.0509 - loss: 0.0517 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 3.9063e-06\n",
            "Epoch 226/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - custom_accuracy_without_padding: 0.4776 - custom_mse: 0.0506 - loss: 0.0514 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 3.9063e-06\n",
            "Epoch 227/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - custom_accuracy_without_padding: 0.4809 - custom_mse: 0.0507 - loss: 0.0514 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 3.9063e-06\n",
            "Epoch 228/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - custom_accuracy_without_padding: 0.4786 - custom_mse: 0.0506 - loss: 0.0514 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 3.9063e-06\n",
            "Epoch 229/500\n",
            "\u001b[1m20/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4838 - custom_mse: 0.0505 - loss: 0.0513\n",
            "Epoch 229: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - custom_accuracy_without_padding: 0.4826 - custom_mse: 0.0505 - loss: 0.0513 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 3.9063e-06\n",
            "Epoch 230/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - custom_accuracy_without_padding: 0.4796 - custom_mse: 0.0508 - loss: 0.0516 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 1.9531e-06\n",
            "Epoch 231/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - custom_accuracy_without_padding: 0.4773 - custom_mse: 0.0506 - loss: 0.0514 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 1.9531e-06\n",
            "Epoch 232/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - custom_accuracy_without_padding: 0.4796 - custom_mse: 0.0503 - loss: 0.0511 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 1.9531e-06\n",
            "Epoch 233/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4782 - custom_mse: 0.0505 - loss: 0.0513 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 1.9531e-06\n",
            "Epoch 234/500\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.4804 - custom_mse: 0.0503 - loss: 0.0510\n",
            "Epoch 234: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4803 - custom_mse: 0.0503 - loss: 0.0511 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 1.9531e-06\n",
            "Epoch 235/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.4757 - custom_mse: 0.0511 - loss: 0.0519 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 9.7656e-07\n",
            "Epoch 236/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4751 - custom_mse: 0.0509 - loss: 0.0517 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 9.7656e-07\n",
            "Epoch 237/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - custom_accuracy_without_padding: 0.4828 - custom_mse: 0.0504 - loss: 0.0512 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 9.7656e-07\n",
            "Epoch 238/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4769 - custom_mse: 0.0507 - loss: 0.0514 - val_custom_accuracy_without_padding: 0.4762 - val_custom_mse: 0.0516 - val_loss: 0.0521 - learning_rate: 9.7656e-07\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    [X_real_train, X_imag_train],\n",
        "    y_train,\n",
        "    epochs=500,\n",
        "    batch_size=32,\n",
        "    validation_data=([X_real_test, X_imag_test], y_test),\n",
        "    callbacks=[adjust_lr, early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdTEAalW7iId"
      },
      "source": [
        "Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTR1e_VB7jSD",
        "outputId": "42a7e656-eaf1-4023-973c-6cab2a739856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.4788 - custom_mse: 0.0503 - loss: 0.0510 \n",
            "Test results - Loss: 0.05205358564853668, MSE: 0.05160055682063103, Accuracy: 0.4761905074119568\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "eval_results = model.evaluate([X_real_test, X_imag_test], y_test)\n",
        "print(f\"Test results - Loss: {eval_results[0]}, MSE: {eval_results[1]}, Accuracy: {eval_results[2]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "KUzLnrru7j8g",
        "outputId": "7c42e2e9-458a-4a41-dc6b-5d482d603b6a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['custom_accuracy_without_padding'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_custom_accuracy_without_padding'], label='Validation Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oE06hol7ldu",
        "outputId": "6570dc97-ec40-418e-e073-aad5b4a008ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step\n",
            "R² Score: 0.3815\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "y_pred = model.predict([X_real_test, X_imag_test])\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"R² Score: {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzFpgUhX7m-u",
        "outputId": "5e361702-0d3b-49b7-825c-eb9eba818efa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
            "Comparison of predictions and ground truth:\n",
            "Sample 1:\n",
            "  Predicted:    [3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 2 5 1 4 3 4 4 6 5 2 3 1 0 0 0 0 0]\n",
            "  Ground Truth: [5 6 5 1 3 4 1 1 6 2 3 1 4 0 3 2 5 1 4 3 4 4 6 5 2 3 1 0 0 0 0 0]\n",
            "----------------------------------------\n",
            "Sample 2:\n",
            "  Predicted:    [3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 1 1 1 0 1 1 5 2 1 4 0 4 0 0 0 0 0]\n",
            "  Ground Truth: [1 4 1 3 3 3 0 5 5 2 4 3 3 1 3 1 1 2 0 1 1 5 2 1 4 0 4 0 0 0 0 0]\n",
            "----------------------------------------\n",
            "Sample 3:\n",
            "  Predicted:    [3 3 3 3 3 3 3 3 3 3 3 3 3 4 2 3 5 1 4 6 0 4 3 2 3 4 4 0 0 0 0 0]\n",
            "  Ground Truth: [2 6 0 2 2 1 3 4 2 6 4 1 0 5 2 3 5 1 4 6 0 4 3 2 3 4 4 0 0 0 0 0]\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict([X_real_test, X_imag_test])\n",
        "y_test_rescaled = y_test * (q - 1)\n",
        "y_pred_rescaled = y_pred * (q - 1)\n",
        "\n",
        "print(\"Comparison of predictions and ground truth:\")\n",
        "for i in range(3):\n",
        "    print(f\"Sample {i+1}:\")\n",
        "    print(f\"  Predicted:    {np.round(y_pred_rescaled[i]).astype(int)}\")\n",
        "    print(f\"  Ground Truth: {np.round(y_test_rescaled[i]).astype(int)}\")\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVHVWjrd7v7N"
      },
      "source": [
        "Test on Unseen Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "qUUlrNBb7xqG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
