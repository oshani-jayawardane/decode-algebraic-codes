{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXAJCz9v39RU"
      },
      "source": [
        "### ANN - Gen Matrix Encoded Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "itaY18VK39Re"
      },
      "outputs": [],
      "source": [
        "# (r + 1) | (q - 1)\n",
        "# (r + 1) | n\n",
        "# q is a prime number\n",
        "# n = 2^t\n",
        "# r < n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yry-yis39Ri",
        "outputId": "f141439b-fdc1-41e0-b5d8-eb9c86870c40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "%reset -f\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VC4-bslz39Rj"
      },
      "outputs": [],
      "source": [
        "w0 = 4\n",
        "z0 = 3\n",
        "\n",
        "n = 27\n",
        "q = 7\n",
        "num_samples = 1000\n",
        "\n",
        "num_unseen_samples = 20"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import Huber\n",
        "\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "QkEBVFQR4SEY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnINb41e39Rk",
        "outputId": "910d8a00-aea1-4aa2-dac5-2cbf48237200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original n: 27\n",
            "Padded n: 32\n",
            "Generated dataset shape: (1000, 32)\n"
          ]
        }
      ],
      "source": [
        "def next_power_of_two(x):\n",
        "    return 1 if x == 0 else 2**(x - 1).bit_length()\n",
        "\n",
        "n_padded = next_power_of_two(n)\n",
        "\n",
        "dataset = np.random.randint(0, q, size=(num_samples, n))\n",
        "\n",
        "if n_padded > n:\n",
        "    pad_width = n_padded - n\n",
        "    dataset = np.pad(dataset, ((0, 0), (0, pad_width)), mode='constant', constant_values=0)\n",
        "\n",
        "print(\"Original n:\", n)\n",
        "print(\"Padded n:\", n_padded)\n",
        "print(\"Generated dataset shape:\", dataset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwQZ3E8o39Rm",
        "outputId": "520d29cb-f303-4bef-d19f-7132b89e4677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6 3 4 ... 0 0 0]\n",
            " [1 5 4 ... 0 0 0]\n",
            " [0 6 1 ... 0 0 0]\n",
            " ...\n",
            " [4 1 1 ... 0 0 0]\n",
            " [6 1 2 ... 0 0 0]\n",
            " [1 5 4 ... 0 0 0]]\n",
            "(1000, 32)\n",
            "(32,)\n"
          ]
        }
      ],
      "source": [
        "print(dataset)\n",
        "print(dataset.shape)\n",
        "print(dataset[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH_I3jW739Ro"
      },
      "source": [
        "$$\n",
        "\\tilde{M}_{kj} = \\left[ \\left( \\frac{w_0}{z_0} \\right)^j \\zeta^{kj} \\right]_{k,j=0}^{n-1}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "d37Ydmgw39Rp"
      },
      "outputs": [],
      "source": [
        "def padded_generator_matrix(N, w0, z0):\n",
        "    n = np.arange(N)\n",
        "    k = n.reshape((N, 1))\n",
        "    zeta = np.exp(-2j * np.pi / N)\n",
        "    M_tilde = ((w0 / z0) ** n) * (zeta ** (k * n))\n",
        "    return M_tilde"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnbsILy_39Rp",
        "outputId": "67b2a233-efc7-4ee8-fc14-40eb9a63f58b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 32)\n"
          ]
        }
      ],
      "source": [
        "M_tilde = padded_generator_matrix(n_padded, w0, z0)\n",
        "print(M_tilde.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gL9uV1SM39Rq",
        "outputId": "db08fdff-b47e-426e-c5d3-f29d8fbbc901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 18563.60052945    +0.j          -3175.07412411+14542.65392496j\n",
            "   -9480.13851167 -1549.89213738j ...   -850.18419129 +5788.51248279j\n",
            "   -9480.13851167 +1549.89213738j  -3175.07412411-14542.65392496j]\n",
            " [ 26201.57565547    +0.j           -888.79870167+21381.54383229j\n",
            "  -15711.89592314 +4225.02464251j ...  -8448.43948841+12321.54894128j\n",
            "  -15711.89592314 -4225.02464251j   -888.79870167-21381.54383229j]\n",
            " [ 18708.3418798     +0.j          -3692.76914231+14315.81246485j\n",
            "   -8001.63897938 -1445.78154582j ...  -2196.87866369 +4388.0650906j\n",
            "   -8001.63897938 +1445.78154582j  -3692.76914231-14315.81246485j]\n",
            " ...\n",
            " [ 23026.93389135    +0.j          -1109.76273792+19062.65254237j\n",
            "  -13040.7009937  +1311.43274328j ...  -3589.38928495 +6599.51636282j\n",
            "  -13040.7009937  -1311.43274328j  -1109.76273792-19062.65254237j]\n",
            " [ 13466.17623911    +0.j          -3519.32538663 +9603.71035865j\n",
            "   -6399.29947006 -1233.3778371j  ...  -1243.67319172 +6320.28545061j\n",
            "   -6399.29947006 +1233.3778371j   -3519.32538663 -9603.71035865j]\n",
            " [ 14588.02290132    +0.j          -1642.56444197+11272.19910547j\n",
            "   -6953.08933372  +889.35665809j ...  -4636.08674653 +4233.01026956j\n",
            "   -6953.08933372  -889.35665809j  -1642.56444197-11272.19910547j]]\n"
          ]
        }
      ],
      "source": [
        "encoded_dataset = np.array([np.dot(M_tilde, x) for x in dataset])\n",
        "encoded_dataset[np.abs(encoded_dataset) < 1e-10] = 0\n",
        "encoded_dataset = np.round(encoded_dataset, decimals=10)\n",
        "print(encoded_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1t98OtS39Rr",
        "outputId": "4271331c-515f-4756-f8c4-1ba260288107"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "encoded_dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqymbNzP39Rs",
        "outputId": "ce866756-abe9-42a1-da62-30ad9c01b271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6 3 4 6 2 4 4 6 1 2 6 2 2 4 3 2 5 4 1 3 5 5 1 3 4 0 3 0 0 0 0 0]\n",
            "[18563.60052945    +0.j         -3175.07412411+14542.65392496j\n",
            " -9480.13851167 -1549.89213738j  -850.18419129 -5788.51248279j\n",
            "  2813.63372348 -2457.36436449j  3312.0476391   +337.88077825j\n",
            "  1059.2907911  +3489.68169028j -2366.82367016  +909.74502726j\n",
            "  -210.29906943  +357.85181443j -3878.07651347  +373.95548592j\n",
            "   -49.25036994 -6370.32567308j  6901.71964373 -1088.5938127j\n",
            "  2896.76301761 +7252.43377368j -6714.83312544 +4427.90575271j\n",
            " -5496.28870703 -5330.43278044j  2828.24226801 -6162.17891893j\n",
            "  6446.94186958    -0.j          2828.24226801 +6162.17891893j\n",
            " -5496.28870703 +5330.43278044j -6714.83312544 -4427.90575271j\n",
            "  2896.76301761 -7252.43377368j  6901.71964373 +1088.5938127j\n",
            "   -49.25036994 +6370.32567308j -3878.07651347  -373.95548592j\n",
            "  -210.29906943  -357.85181443j -2366.82367016  -909.74502726j\n",
            "  1059.2907911  -3489.68169028j  3312.0476391   -337.88077825j\n",
            "  2813.63372348 +2457.36436449j  -850.18419129 +5788.51248279j\n",
            " -9480.13851167 +1549.89213738j -3175.07412411-14542.65392496j]\n"
          ]
        }
      ],
      "source": [
        "print(dataset[0])\n",
        "print(encoded_dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QPJOcCXk39Rs"
      },
      "outputs": [],
      "source": [
        "X_real = np.real(encoded_dataset).astype(np.float32)\n",
        "X_imag = np.imag(encoded_dataset).astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23brJMGr39Rt",
        "outputId": "dd56030a-6283-4159-c837-fcf188429aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_real_min:   -25398.395\n",
            "x_real_max:   37088.72\n",
            "x_imag_min:   -32553.318\n",
            "x_imag_max:   32553.318\n"
          ]
        }
      ],
      "source": [
        "print(\"x_real_min:  \", np.min(X_real))\n",
        "print(\"x_real_max:  \", np.max(X_real))\n",
        "print(\"x_imag_min:  \", np.min(X_imag))\n",
        "print(\"x_imag_max:  \", np.max(X_imag))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "E5goI5TM39Rt"
      },
      "outputs": [],
      "source": [
        "# mean_real = np.mean(X_real, axis=0)\n",
        "# std_real = np.std(X_real, axis=0) + 1e-8  # Avoid division by zero\n",
        "# X_real = (X_real - mean_real) / std_real\n",
        "\n",
        "# mean_imag = np.mean(X_imag, axis=0)\n",
        "# std_imag = np.std(X_imag, axis=0) + 1e-8\n",
        "# X_imag = (X_imag - mean_imag) / std_imag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT2gZEvW39Ru",
        "outputId": "e3fce7d5-3dfc-4132-c8bd-4d726f789805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_real_min:   -25398.395\n",
            "x_real_max:   37088.72\n",
            "x_imag_min:   -32553.318\n",
            "x_imag_max:   32553.318\n"
          ]
        }
      ],
      "source": [
        "print(\"x_real_min:  \", np.min(X_real))\n",
        "print(\"x_real_max:  \", np.max(X_real))\n",
        "print(\"x_imag_min:  \", np.min(X_imag))\n",
        "print(\"x_imag_max:  \", np.max(X_imag))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lVbrpj839Ru",
        "outputId": "a4a43f5b-2b66-47e9-a54c-39bb5865e43f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "X_train : (1000, 64)\n",
            "[ 18563.6      -3175.0742   -9480.139     -850.1842    2813.6338\n",
            "   3312.0476    1059.2908   -2366.8237    -210.29907  -3878.0764\n",
            "    -49.25037   6901.7197    2896.763    -6714.833    -5496.2886\n",
            "   2828.2422    6446.942     2828.2422   -5496.2886   -6714.833\n",
            "   2896.763     6901.7197     -49.25037  -3878.0764    -210.29907\n",
            "  -2366.8237    1059.2908    3312.0476    2813.6338    -850.1842\n",
            "  -9480.139    -3175.0742       0.       14542.654    -1549.8921\n",
            "  -5788.5127   -2457.3643     337.88077   3489.6816     909.74506\n",
            "    357.8518     373.95547  -6370.3257   -1088.5939    7252.4336\n",
            "   4427.906    -5330.4326   -6162.1787      -0.        6162.1787\n",
            "   5330.4326   -4427.906    -7252.4336    1088.5939    6370.3257\n",
            "   -373.95547   -357.8518    -909.74506  -3489.6816    -337.88077\n",
            "   2457.3643    5788.5127    1549.8921  -14542.654  ]\n"
          ]
        }
      ],
      "source": [
        "X_real_imag = np.hstack([X_real, X_imag])\n",
        "\n",
        "print(\"\\nX_train :\", X_real_imag.shape)\n",
        "print(X_real_imag[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nU7yUWL39Rv",
        "outputId": "31197550-d24d-48f5-ee76-ef6bb95eac96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y: \n",
            "[6. 3. 4. 6. 2. 4. 4. 6. 1. 2. 6. 2. 2. 4. 3. 2. 5. 4. 1. 3. 5. 5. 1. 3.\n",
            " 4. 0. 3. 0. 0. 0. 0. 0.]\n",
            "\n",
            "y_normalized: \n",
            "[1.         0.5        0.6666667  1.         0.33333334 0.6666667\n",
            " 0.6666667  1.         0.16666667 0.33333334 1.         0.33333334\n",
            " 0.33333334 0.6666667  0.5        0.33333334 0.8333333  0.6666667\n",
            " 0.16666667 0.5        0.8333333  0.8333333  0.16666667 0.5\n",
            " 0.6666667  0.         0.5        0.         0.         0.\n",
            " 0.         0.        ]\n"
          ]
        }
      ],
      "source": [
        "# normalize target data (integers 0-q to [0, 1])\n",
        "y = dataset.astype(np.float32)\n",
        "# y[:, :r] = 0\n",
        "y_normalized = y / (q - 1)  # Scale to [0, 1]\n",
        "\n",
        "labels = y_normalized\n",
        "\n",
        "\n",
        "print(\"y: \")\n",
        "print(y[0])\n",
        "print(\"\\ny_normalized: \")\n",
        "print(y_normalized[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PbiB8Mja39Rv"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    X_real_imag, labels, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwlQQc2e4dpU",
        "outputId": "4c921cf5-96ef-4262-8dd8-d2553f362cc8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (800, 64), y_train shape: (800, 32)\n",
            "x_test shape: (200, 64), y_test shape: (200, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = (x_train - x_train.mean()) / x_train.std()\n",
        "x_test = (x_test - x_test.mean()) / x_test.std()"
      ],
      "metadata": {
        "id": "uCGdGit64gyc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SemgHF5b39Rv",
        "outputId": "88e43bbc-d167-48b1-b035-b55cb7064efa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n",
            "32\n"
          ]
        }
      ],
      "source": [
        "input_dim = x_train.shape[1]\n",
        "output_dim = y_train.shape[1]\n",
        "print(input_dim)\n",
        "print(output_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6pk994M39Rw"
      },
      "source": [
        "Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_accuracy(y_true, y_pred):\n",
        "    y_true_int = tf.cast(y_true*(q-1), tf.int32)\n",
        "    y_pred_int = tf.cast(tf.round(y_pred*(q-1)), tf.int32)\n",
        "    correct = tf.cast(tf.equal(y_true_int, y_pred_int), tf.float32)\n",
        "    return tf.reduce_mean(correct)\n",
        "\n",
        "# accuracy function that does not consider the padding\n",
        "def custom_accuracy_without_padding(y_true, y_pred):\n",
        "    y_true_int = tf.cast(y_true * (q - 1), tf.int32)\n",
        "    y_pred_int = tf.cast(tf.round(y_pred * (q - 1)), tf.int32)\n",
        "    mask = tf.concat(\n",
        "        [tf.ones((tf.shape(y_true)[0], n), dtype=tf.float32),\n",
        "         tf.zeros((tf.shape(y_true)[0], n_padded - n), dtype=tf.float32)],\n",
        "        axis=1\n",
        "    )\n",
        "    correct = tf.cast(tf.equal(y_true_int, y_pred_int), tf.float32) * mask\n",
        "    return tf.reduce_sum(correct) / tf.reduce_sum(mask)\n",
        "\n",
        "def custom_mse(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    return tf.reduce_mean(tf.square(tf.cast(y_true - y_pred, tf.float32)))"
      ],
      "metadata": {
        "id": "kCbO2XUz4sjf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "_u1Z1KLg39Rw",
        "outputId": "6f2e2c74-6bce-41d0-9a3d-76a4c6a1a2bf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,248\u001b[0m (20.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,248</span> (20.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,248\u001b[0m (20.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,248</span> (20.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def simple_NN(input_dim, output_dim, activation='relu'):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_dim,)),\n",
        "        Dense(n_padded, activation=activation),\n",
        "        Dense(n_padded, activation=activation),\n",
        "        Dense(n_padded, activation=activation),\n",
        "        Dense(output_dim, activation='linear')  # Linear activation for regression\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss=custom_mse,\n",
        "        metrics=[custom_mse, custom_accuracy_without_padding]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "input_dim = x_train.shape[1]\n",
        "output_dim = y_train.shape[1]\n",
        "activation = LeakyReLU(negative_slope=0.1) #leaky_relu #relu\n",
        "model = simple_NN(input_dim, output_dim, activation=activation)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------- FLOP counts ---------------\n",
        "\n",
        "# Create a concrete function\n",
        "input_shape = (1, input_dim)  # batch size 1\n",
        "concrete_func = tf.function(model).get_concrete_function(tf.TensorSpec(input_shape, tf.float32))\n",
        "\n",
        "from tensorflow.python.profiler import model_analyzer\n",
        "from tensorflow.python.profiler.option_builder import ProfileOptionBuilder\n",
        "\n",
        "profile_opts = ProfileOptionBuilder.float_operation()\n",
        "flops = model_analyzer.profile(concrete_func.graph, options=profile_opts)\n",
        "\n",
        "print('FLOPs:', flops.total_float_ops)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34ExlsCLVPP2",
        "outputId": "dc9ca6eb-b765-43af-8a61-0840c19dcb18"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/tensorflow/python/profiler/internal/flops_registry.py:453: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLOPs: 10368\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6g-bbZY39Rw"
      },
      "source": [
        "Training the NN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gMycoGP8BPpr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHoxqzWu39Rx",
        "outputId": "31d972d3-ecbb-4883-eda7-a73227696578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m15/25\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - custom_accuracy_without_padding: 0.1076 - custom_mse: 0.3840 - loss: 0.3840\n",
            "Epoch 1: val_loss improved from inf to 0.15946, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - custom_accuracy_without_padding: 0.1151 - custom_mse: 0.3382 - loss: 0.3382 - val_custom_accuracy_without_padding: 0.1486 - val_custom_mse: 0.1588 - val_loss: 0.1595 - learning_rate: 0.0010\n",
            "Epoch 2/500\n",
            "\u001b[1m14/25\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - custom_accuracy_without_padding: 0.1411 - custom_mse: 0.1513 - loss: 0.1513   \n",
            "Epoch 2: val_loss improved from 0.15946 to 0.10459, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.1450 - custom_mse: 0.1433 - loss: 0.1433 - val_custom_accuracy_without_padding: 0.1501 - val_custom_mse: 0.1041 - val_loss: 0.1046 - learning_rate: 0.0010\n",
            "Epoch 3/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.1596 - custom_mse: 0.0983 - loss: 0.0983  \n",
            "Epoch 3: val_loss improved from 0.10459 to 0.09163, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.1596 - custom_mse: 0.0982 - loss: 0.0982 - val_custom_accuracy_without_padding: 0.1541 - val_custom_mse: 0.0917 - val_loss: 0.0916 - learning_rate: 0.0010\n",
            "Epoch 4/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - custom_accuracy_without_padding: 0.1435 - custom_mse: 0.0984 - loss: 0.0984\n",
            "Epoch 4: val_loss improved from 0.09163 to 0.08749, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.1632 - custom_mse: 0.0904 - loss: 0.0904 - val_custom_accuracy_without_padding: 0.1594 - val_custom_mse: 0.0876 - val_loss: 0.0875 - learning_rate: 0.0010\n",
            "Epoch 5/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - custom_accuracy_without_padding: 0.1701 - custom_mse: 0.0856 - loss: 0.0856\n",
            "Epoch 5: val_loss improved from 0.08749 to 0.08540, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.1690 - custom_mse: 0.0861 - loss: 0.0861 - val_custom_accuracy_without_padding: 0.1622 - val_custom_mse: 0.0855 - val_loss: 0.0854 - learning_rate: 0.0010\n",
            "Epoch 6/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - custom_accuracy_without_padding: 0.1910 - custom_mse: 0.0814 - loss: 0.0814\n",
            "Epoch 6: val_loss improved from 0.08540 to 0.08371, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.1782 - custom_mse: 0.0841 - loss: 0.0841 - val_custom_accuracy_without_padding: 0.1758 - val_custom_mse: 0.0839 - val_loss: 0.0837 - learning_rate: 0.0010\n",
            "Epoch 7/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - custom_accuracy_without_padding: 0.1794 - custom_mse: 0.0846 - loss: 0.0846\n",
            "Epoch 7: val_loss improved from 0.08371 to 0.08178, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.1830 - custom_mse: 0.0826 - loss: 0.0826 - val_custom_accuracy_without_padding: 0.1782 - val_custom_mse: 0.0820 - val_loss: 0.0818 - learning_rate: 0.0010\n",
            "Epoch 8/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - custom_accuracy_without_padding: 0.1736 - custom_mse: 0.0784 - loss: 0.0784\n",
            "Epoch 8: val_loss improved from 0.08178 to 0.08028, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.1864 - custom_mse: 0.0807 - loss: 0.0807 - val_custom_accuracy_without_padding: 0.1839 - val_custom_mse: 0.0803 - val_loss: 0.0803 - learning_rate: 0.0010\n",
            "Epoch 9/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - custom_accuracy_without_padding: 0.1817 - custom_mse: 0.0776 - loss: 0.0776\n",
            "Epoch 9: val_loss improved from 0.08028 to 0.07888, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.1916 - custom_mse: 0.0791 - loss: 0.0791 - val_custom_accuracy_without_padding: 0.1920 - val_custom_mse: 0.0788 - val_loss: 0.0789 - learning_rate: 0.0010\n",
            "Epoch 10/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - custom_accuracy_without_padding: 0.2037 - custom_mse: 0.0721 - loss: 0.0721\n",
            "Epoch 10: val_loss improved from 0.07888 to 0.07761, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.2057 - custom_mse: 0.0764 - loss: 0.0764 - val_custom_accuracy_without_padding: 0.1989 - val_custom_mse: 0.0775 - val_loss: 0.0776 - learning_rate: 0.0010\n",
            "Epoch 11/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - custom_accuracy_without_padding: 0.1921 - custom_mse: 0.0786 - loss: 0.0786\n",
            "Epoch 11: val_loss improved from 0.07761 to 0.07585, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.2073 - custom_mse: 0.0760 - loss: 0.0760 - val_custom_accuracy_without_padding: 0.2065 - val_custom_mse: 0.0758 - val_loss: 0.0758 - learning_rate: 0.0010\n",
            "Epoch 12/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - custom_accuracy_without_padding: 0.2407 - custom_mse: 0.0708 - loss: 0.0708\n",
            "Epoch 12: val_loss improved from 0.07585 to 0.07449, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.2207 - custom_mse: 0.0745 - loss: 0.0745 - val_custom_accuracy_without_padding: 0.2151 - val_custom_mse: 0.0744 - val_loss: 0.0745 - learning_rate: 0.0010\n",
            "Epoch 13/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - custom_accuracy_without_padding: 0.2361 - custom_mse: 0.0730 - loss: 0.0730\n",
            "Epoch 13: val_loss improved from 0.07449 to 0.07417, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.2264 - custom_mse: 0.0735 - loss: 0.0735 - val_custom_accuracy_without_padding: 0.2333 - val_custom_mse: 0.0741 - val_loss: 0.0742 - learning_rate: 0.0010\n",
            "Epoch 14/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - custom_accuracy_without_padding: 0.2269 - custom_mse: 0.0740 - loss: 0.0740\n",
            "Epoch 14: val_loss improved from 0.07417 to 0.07222, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.2373 - custom_mse: 0.0717 - loss: 0.0717 - val_custom_accuracy_without_padding: 0.2325 - val_custom_mse: 0.0721 - val_loss: 0.0722 - learning_rate: 0.0010\n",
            "Epoch 15/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - custom_accuracy_without_padding: 0.2257 - custom_mse: 0.0712 - loss: 0.0712\n",
            "Epoch 15: val_loss improved from 0.07222 to 0.07090, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.2413 - custom_mse: 0.0706 - loss: 0.0706 - val_custom_accuracy_without_padding: 0.2507 - val_custom_mse: 0.0709 - val_loss: 0.0709 - learning_rate: 0.0010\n",
            "Epoch 16/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 148ms/step - custom_accuracy_without_padding: 0.2500 - custom_mse: 0.0672 - loss: 0.0672\n",
            "Epoch 16: val_loss improved from 0.07090 to 0.07026, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.2586 - custom_mse: 0.0688 - loss: 0.0688 - val_custom_accuracy_without_padding: 0.2654 - val_custom_mse: 0.0703 - val_loss: 0.0703 - learning_rate: 0.0010\n",
            "Epoch 17/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.2698 - custom_mse: 0.0685 - loss: 0.0685  \n",
            "Epoch 17: val_loss improved from 0.07026 to 0.06906, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.2699 - custom_mse: 0.0685 - loss: 0.0685 - val_custom_accuracy_without_padding: 0.2621 - val_custom_mse: 0.0691 - val_loss: 0.0691 - learning_rate: 0.0010\n",
            "Epoch 18/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - custom_accuracy_without_padding: 0.2639 - custom_mse: 0.0700 - loss: 0.0700\n",
            "Epoch 18: val_loss improved from 0.06906 to 0.06816, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.2751 - custom_mse: 0.0675 - loss: 0.0675 - val_custom_accuracy_without_padding: 0.2821 - val_custom_mse: 0.0682 - val_loss: 0.0682 - learning_rate: 0.0010\n",
            "Epoch 19/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - custom_accuracy_without_padding: 0.2928 - custom_mse: 0.0678 - loss: 0.0678\n",
            "Epoch 19: val_loss improved from 0.06816 to 0.06723, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.2925 - custom_mse: 0.0668 - loss: 0.0668 - val_custom_accuracy_without_padding: 0.2910 - val_custom_mse: 0.0673 - val_loss: 0.0672 - learning_rate: 0.0010\n",
            "Epoch 20/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - custom_accuracy_without_padding: 0.2789 - custom_mse: 0.0690 - loss: 0.0690\n",
            "Epoch 20: val_loss improved from 0.06723 to 0.06666, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.2939 - custom_mse: 0.0660 - loss: 0.0660 - val_custom_accuracy_without_padding: 0.2908 - val_custom_mse: 0.0668 - val_loss: 0.0667 - learning_rate: 0.0010\n",
            "Epoch 21/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - custom_accuracy_without_padding: 0.3009 - custom_mse: 0.0623 - loss: 0.0623\n",
            "Epoch 21: val_loss improved from 0.06666 to 0.06603, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.3036 - custom_mse: 0.0649 - loss: 0.0649 - val_custom_accuracy_without_padding: 0.3102 - val_custom_mse: 0.0659 - val_loss: 0.0660 - learning_rate: 0.0010\n",
            "Epoch 22/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - custom_accuracy_without_padding: 0.3252 - custom_mse: 0.0629 - loss: 0.0629\n",
            "Epoch 22: val_loss improved from 0.06603 to 0.06533, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.3194 - custom_mse: 0.0637 - loss: 0.0637 - val_custom_accuracy_without_padding: 0.3173 - val_custom_mse: 0.0654 - val_loss: 0.0653 - learning_rate: 0.0010\n",
            "Epoch 23/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - custom_accuracy_without_padding: 0.3264 - custom_mse: 0.0649 - loss: 0.0649\n",
            "Epoch 23: val_loss improved from 0.06533 to 0.06467, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.3259 - custom_mse: 0.0639 - loss: 0.0639 - val_custom_accuracy_without_padding: 0.3173 - val_custom_mse: 0.0647 - val_loss: 0.0647 - learning_rate: 0.0010\n",
            "Epoch 24/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - custom_accuracy_without_padding: 0.3519 - custom_mse: 0.0571 - loss: 0.0571\n",
            "Epoch 24: val_loss did not improve from 0.06467\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.3380 - custom_mse: 0.0622 - loss: 0.0622 - val_custom_accuracy_without_padding: 0.3224 - val_custom_mse: 0.0652 - val_loss: 0.0651 - learning_rate: 0.0010\n",
            "Epoch 25/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - custom_accuracy_without_padding: 0.3218 - custom_mse: 0.0682 - loss: 0.0682\n",
            "Epoch 25: val_loss improved from 0.06467 to 0.06407, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.3367 - custom_mse: 0.0631 - loss: 0.0631 - val_custom_accuracy_without_padding: 0.3416 - val_custom_mse: 0.0642 - val_loss: 0.0641 - learning_rate: 0.0010\n",
            "Epoch 26/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.3507 - custom_mse: 0.0614 - loss: 0.0614  \n",
            "Epoch 26: val_loss improved from 0.06407 to 0.06334, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.3506 - custom_mse: 0.0614 - loss: 0.0614 - val_custom_accuracy_without_padding: 0.3378 - val_custom_mse: 0.0634 - val_loss: 0.0633 - learning_rate: 0.0010\n",
            "Epoch 27/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - custom_accuracy_without_padding: 0.3414 - custom_mse: 0.0648 - loss: 0.0648\n",
            "Epoch 27: val_loss improved from 0.06334 to 0.06256, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.3530 - custom_mse: 0.0623 - loss: 0.0623 - val_custom_accuracy_without_padding: 0.3429 - val_custom_mse: 0.0626 - val_loss: 0.0626 - learning_rate: 0.0010\n",
            "Epoch 28/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - custom_accuracy_without_padding: 0.3634 - custom_mse: 0.0618 - loss: 0.0618\n",
            "Epoch 28: val_loss did not improve from 0.06256\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.3666 - custom_mse: 0.0608 - loss: 0.0608 - val_custom_accuracy_without_padding: 0.3542 - val_custom_mse: 0.0630 - val_loss: 0.0628 - learning_rate: 0.0010\n",
            "Epoch 29/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - custom_accuracy_without_padding: 0.3831 - custom_mse: 0.0560 - loss: 0.0560\n",
            "Epoch 29: val_loss improved from 0.06256 to 0.06226, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.3682 - custom_mse: 0.0600 - loss: 0.0600 - val_custom_accuracy_without_padding: 0.3598 - val_custom_mse: 0.0622 - val_loss: 0.0623 - learning_rate: 0.0010\n",
            "Epoch 30/500\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.3702 - custom_mse: 0.0601 - loss: 0.0601  \n",
            "Epoch 30: val_loss improved from 0.06226 to 0.06152, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.3706 - custom_mse: 0.0601 - loss: 0.0601 - val_custom_accuracy_without_padding: 0.3537 - val_custom_mse: 0.0617 - val_loss: 0.0615 - learning_rate: 0.0010\n",
            "Epoch 31/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - custom_accuracy_without_padding: 0.3900 - custom_mse: 0.0606 - loss: 0.0606\n",
            "Epoch 31: val_loss improved from 0.06152 to 0.06124, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.3785 - custom_mse: 0.0593 - loss: 0.0593 - val_custom_accuracy_without_padding: 0.3618 - val_custom_mse: 0.0613 - val_loss: 0.0612 - learning_rate: 0.0010\n",
            "Epoch 32/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - custom_accuracy_without_padding: 0.3843 - custom_mse: 0.0594 - loss: 0.0594\n",
            "Epoch 32: val_loss did not improve from 0.06124\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.3803 - custom_mse: 0.0595 - loss: 0.0595 - val_custom_accuracy_without_padding: 0.3679 - val_custom_mse: 0.0614 - val_loss: 0.0614 - learning_rate: 0.0010\n",
            "Epoch 33/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - custom_accuracy_without_padding: 0.3669 - custom_mse: 0.0593 - loss: 0.0593\n",
            "Epoch 33: val_loss improved from 0.06124 to 0.06086, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.3827 - custom_mse: 0.0592 - loss: 0.0592 - val_custom_accuracy_without_padding: 0.3724 - val_custom_mse: 0.0610 - val_loss: 0.0609 - learning_rate: 0.0010\n",
            "Epoch 34/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - custom_accuracy_without_padding: 0.3738 - custom_mse: 0.0571 - loss: 0.0571\n",
            "Epoch 34: val_loss improved from 0.06086 to 0.06031, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.3813 - custom_mse: 0.0590 - loss: 0.0590 - val_custom_accuracy_without_padding: 0.3743 - val_custom_mse: 0.0603 - val_loss: 0.0603 - learning_rate: 0.0010\n",
            "Epoch 35/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.3947 - custom_mse: 0.0586 - loss: 0.0586  \n",
            "Epoch 35: val_loss improved from 0.06031 to 0.05970, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.3945 - custom_mse: 0.0586 - loss: 0.0586 - val_custom_accuracy_without_padding: 0.3834 - val_custom_mse: 0.0598 - val_loss: 0.0597 - learning_rate: 0.0010\n",
            "Epoch 36/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.3877 - custom_mse: 0.0577 - loss: 0.0577  \n",
            "Epoch 36: val_loss did not improve from 0.05970\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.3876 - custom_mse: 0.0577 - loss: 0.0577 - val_custom_accuracy_without_padding: 0.3520 - val_custom_mse: 0.0606 - val_loss: 0.0605 - learning_rate: 0.0010\n",
            "Epoch 37/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - custom_accuracy_without_padding: 0.3854 - custom_mse: 0.0583 - loss: 0.0583\n",
            "Epoch 37: val_loss improved from 0.05970 to 0.05932, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.3902 - custom_mse: 0.0577 - loss: 0.0577 - val_custom_accuracy_without_padding: 0.3824 - val_custom_mse: 0.0593 - val_loss: 0.0593 - learning_rate: 0.0010\n",
            "Epoch 38/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - custom_accuracy_without_padding: 0.4005 - custom_mse: 0.0561 - loss: 0.0561\n",
            "Epoch 38: val_loss improved from 0.05932 to 0.05930, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.4052 - custom_mse: 0.0572 - loss: 0.0572 - val_custom_accuracy_without_padding: 0.3829 - val_custom_mse: 0.0593 - val_loss: 0.0593 - learning_rate: 0.0010\n",
            "Epoch 39/500\n",
            "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.4017 - custom_mse: 0.0579 - loss: 0.0579  \n",
            "Epoch 39: val_loss improved from 0.05930 to 0.05881, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.4025 - custom_mse: 0.0579 - loss: 0.0579 - val_custom_accuracy_without_padding: 0.3864 - val_custom_mse: 0.0589 - val_loss: 0.0588 - learning_rate: 0.0010\n",
            "Epoch 40/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - custom_accuracy_without_padding: 0.3912 - custom_mse: 0.0602 - loss: 0.0602\n",
            "Epoch 40: val_loss improved from 0.05881 to 0.05819, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.4030 - custom_mse: 0.0576 - loss: 0.0576 - val_custom_accuracy_without_padding: 0.3909 - val_custom_mse: 0.0584 - val_loss: 0.0582 - learning_rate: 0.0010\n",
            "Epoch 41/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - custom_accuracy_without_padding: 0.3912 - custom_mse: 0.0557 - loss: 0.0557\n",
            "Epoch 41: val_loss did not improve from 0.05819\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.4099 - custom_mse: 0.0565 - loss: 0.0565 - val_custom_accuracy_without_padding: 0.3937 - val_custom_mse: 0.0585 - val_loss: 0.0585 - learning_rate: 0.0010\n",
            "Epoch 42/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - custom_accuracy_without_padding: 0.4062 - custom_mse: 0.0548 - loss: 0.0548\n",
            "Epoch 42: val_loss improved from 0.05819 to 0.05798, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.4122 - custom_mse: 0.0563 - loss: 0.0563 - val_custom_accuracy_without_padding: 0.4041 - val_custom_mse: 0.0581 - val_loss: 0.0580 - learning_rate: 0.0010\n",
            "Epoch 43/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - custom_accuracy_without_padding: 0.4398 - custom_mse: 0.0501 - loss: 0.0501\n",
            "Epoch 43: val_loss improved from 0.05798 to 0.05783, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.4231 - custom_mse: 0.0551 - loss: 0.0551 - val_custom_accuracy_without_padding: 0.4069 - val_custom_mse: 0.0579 - val_loss: 0.0578 - learning_rate: 0.0010\n",
            "Epoch 44/500\n",
            "\u001b[1m17/25\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - custom_accuracy_without_padding: 0.4232 - custom_mse: 0.0570 - loss: 0.0570  \n",
            "Epoch 44: val_loss improved from 0.05783 to 0.05736, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.4230 - custom_mse: 0.0565 - loss: 0.0565 - val_custom_accuracy_without_padding: 0.4041 - val_custom_mse: 0.0576 - val_loss: 0.0574 - learning_rate: 0.0010\n",
            "Epoch 45/500\n",
            "\u001b[1m15/25\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - custom_accuracy_without_padding: 0.4204 - custom_mse: 0.0558 - loss: 0.0558 \n",
            "Epoch 45: val_loss improved from 0.05736 to 0.05727, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4188 - custom_mse: 0.0557 - loss: 0.0557 - val_custom_accuracy_without_padding: 0.3991 - val_custom_mse: 0.0574 - val_loss: 0.0573 - learning_rate: 0.0010\n",
            "Epoch 46/500\n",
            "\u001b[1m11/25\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.4240 - custom_mse: 0.0557 - loss: 0.0557  \n",
            "Epoch 46: val_loss improved from 0.05727 to 0.05695, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4233 - custom_mse: 0.0557 - loss: 0.0557 - val_custom_accuracy_without_padding: 0.4099 - val_custom_mse: 0.0571 - val_loss: 0.0570 - learning_rate: 0.0010\n",
            "Epoch 47/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.4194 - custom_mse: 0.0553 - loss: 0.0553\n",
            "Epoch 47: val_loss improved from 0.05695 to 0.05633, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - custom_accuracy_without_padding: 0.4197 - custom_mse: 0.0553 - loss: 0.0553 - val_custom_accuracy_without_padding: 0.4233 - val_custom_mse: 0.0564 - val_loss: 0.0563 - learning_rate: 0.0010\n",
            "Epoch 48/500\n",
            "\u001b[1m15/25\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - custom_accuracy_without_padding: 0.4315 - custom_mse: 0.0549 - loss: 0.0549 \n",
            "Epoch 48: val_loss improved from 0.05633 to 0.05617, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4325 - custom_mse: 0.0547 - loss: 0.0547 - val_custom_accuracy_without_padding: 0.4148 - val_custom_mse: 0.0563 - val_loss: 0.0562 - learning_rate: 0.0010\n",
            "Epoch 49/500\n",
            "\u001b[1m18/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.4411 - custom_mse: 0.0537 - loss: 0.0537 \n",
            "Epoch 49: val_loss improved from 0.05617 to 0.05593, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - custom_accuracy_without_padding: 0.4408 - custom_mse: 0.0538 - loss: 0.0538 - val_custom_accuracy_without_padding: 0.4304 - val_custom_mse: 0.0562 - val_loss: 0.0559 - learning_rate: 0.0010\n",
            "Epoch 50/500\n",
            "\u001b[1m20/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.4457 - custom_mse: 0.0538 - loss: 0.0538\n",
            "Epoch 50: val_loss improved from 0.05593 to 0.05547, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - custom_accuracy_without_padding: 0.4450 - custom_mse: 0.0538 - loss: 0.0538 - val_custom_accuracy_without_padding: 0.4292 - val_custom_mse: 0.0556 - val_loss: 0.0555 - learning_rate: 0.0010\n",
            "Epoch 51/500\n",
            "\u001b[1m18/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - custom_accuracy_without_padding: 0.4417 - custom_mse: 0.0532 - loss: 0.0532  \n",
            "Epoch 51: val_loss improved from 0.05547 to 0.05503, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4421 - custom_mse: 0.0533 - loss: 0.0533 - val_custom_accuracy_without_padding: 0.4294 - val_custom_mse: 0.0553 - val_loss: 0.0550 - learning_rate: 0.0010\n",
            "Epoch 52/500\n",
            "\u001b[1m19/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - custom_accuracy_without_padding: 0.4505 - custom_mse: 0.0535 - loss: 0.0535  \n",
            "Epoch 52: val_loss did not improve from 0.05503\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.4511 - custom_mse: 0.0534 - loss: 0.0534 - val_custom_accuracy_without_padding: 0.4327 - val_custom_mse: 0.0554 - val_loss: 0.0551 - learning_rate: 0.0010\n",
            "Epoch 53/500\n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.4520 - custom_mse: 0.0520 - loss: 0.0520\n",
            "Epoch 53: val_loss did not improve from 0.05503\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.4522 - custom_mse: 0.0522 - loss: 0.0522 - val_custom_accuracy_without_padding: 0.4320 - val_custom_mse: 0.0553 - val_loss: 0.0551 - learning_rate: 0.0010\n",
            "Epoch 54/500\n",
            "\u001b[1m18/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - custom_accuracy_without_padding: 0.4447 - custom_mse: 0.0533 - loss: 0.0533  \n",
            "Epoch 54: val_loss improved from 0.05503 to 0.05444, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4449 - custom_mse: 0.0533 - loss: 0.0533 - val_custom_accuracy_without_padding: 0.4372 - val_custom_mse: 0.0548 - val_loss: 0.0544 - learning_rate: 0.0010\n",
            "Epoch 55/500\n",
            "\u001b[1m18/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.4586 - custom_mse: 0.0520 - loss: 0.0520\n",
            "Epoch 55: val_loss improved from 0.05444 to 0.05431, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - custom_accuracy_without_padding: 0.4591 - custom_mse: 0.0522 - loss: 0.0522 - val_custom_accuracy_without_padding: 0.4489 - val_custom_mse: 0.0545 - val_loss: 0.0543 - learning_rate: 0.0010\n",
            "Epoch 56/500\n",
            "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4648 - custom_mse: 0.0522 - loss: 0.0522\n",
            "Epoch 56: val_loss improved from 0.05431 to 0.05417, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - custom_accuracy_without_padding: 0.4644 - custom_mse: 0.0523 - loss: 0.0523 - val_custom_accuracy_without_padding: 0.4557 - val_custom_mse: 0.0544 - val_loss: 0.0542 - learning_rate: 0.0010\n",
            "Epoch 57/500\n",
            "\u001b[1m18/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.4591 - custom_mse: 0.0536 - loss: 0.0536\n",
            "Epoch 57: val_loss did not improve from 0.05417\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - custom_accuracy_without_padding: 0.4597 - custom_mse: 0.0532 - loss: 0.0532 - val_custom_accuracy_without_padding: 0.4582 - val_custom_mse: 0.0546 - val_loss: 0.0543 - learning_rate: 0.0010\n",
            "Epoch 58/500\n",
            "\u001b[1m15/25\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.4584 - custom_mse: 0.0527 - loss: 0.0527\n",
            "Epoch 58: val_loss did not improve from 0.05417\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - custom_accuracy_without_padding: 0.4566 - custom_mse: 0.0526 - loss: 0.0526 - val_custom_accuracy_without_padding: 0.4468 - val_custom_mse: 0.0544 - val_loss: 0.0542 - learning_rate: 0.0010\n",
            "Epoch 59/500\n",
            "\u001b[1m19/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.4617 - custom_mse: 0.0522 - loss: 0.0522 \n",
            "Epoch 59: val_loss improved from 0.05417 to 0.05358, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - custom_accuracy_without_padding: 0.4633 - custom_mse: 0.0521 - loss: 0.0521 - val_custom_accuracy_without_padding: 0.4595 - val_custom_mse: 0.0537 - val_loss: 0.0536 - learning_rate: 0.0010\n",
            "Epoch 60/500\n",
            "\u001b[1m17/25\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - custom_accuracy_without_padding: 0.4670 - custom_mse: 0.0522 - loss: 0.0522\n",
            "Epoch 60: val_loss did not improve from 0.05358\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - custom_accuracy_without_padding: 0.4689 - custom_mse: 0.0520 - loss: 0.0520 - val_custom_accuracy_without_padding: 0.4529 - val_custom_mse: 0.0542 - val_loss: 0.0540 - learning_rate: 0.0010\n",
            "Epoch 61/500\n",
            "\u001b[1m15/25\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - custom_accuracy_without_padding: 0.4767 - custom_mse: 0.0517 - loss: 0.0517  \n",
            "Epoch 61: val_loss improved from 0.05358 to 0.05337, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4770 - custom_mse: 0.0516 - loss: 0.0516 - val_custom_accuracy_without_padding: 0.4608 - val_custom_mse: 0.0536 - val_loss: 0.0534 - learning_rate: 0.0010\n",
            "Epoch 62/500\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.4779 - custom_mse: 0.0510 - loss: 0.0510\n",
            "Epoch 62: val_loss improved from 0.05337 to 0.05303, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - custom_accuracy_without_padding: 0.4780 - custom_mse: 0.0510 - loss: 0.0510 - val_custom_accuracy_without_padding: 0.4628 - val_custom_mse: 0.0532 - val_loss: 0.0530 - learning_rate: 0.0010\n",
            "Epoch 63/500\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.4850 - custom_mse: 0.0500 - loss: 0.0500\n",
            "Epoch 63: val_loss did not improve from 0.05303\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - custom_accuracy_without_padding: 0.4847 - custom_mse: 0.0501 - loss: 0.0501 - val_custom_accuracy_without_padding: 0.4654 - val_custom_mse: 0.0537 - val_loss: 0.0534 - learning_rate: 0.0010\n",
            "Epoch 64/500\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.4741 - custom_mse: 0.0510 - loss: 0.0510\n",
            "Epoch 64: val_loss improved from 0.05303 to 0.05244, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - custom_accuracy_without_padding: 0.4738 - custom_mse: 0.0509 - loss: 0.0509 - val_custom_accuracy_without_padding: 0.4727 - val_custom_mse: 0.0527 - val_loss: 0.0524 - learning_rate: 0.0010\n",
            "Epoch 65/500\n",
            "\u001b[1m17/25\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.4866 - custom_mse: 0.0500 - loss: 0.0500\n",
            "Epoch 65: val_loss did not improve from 0.05244\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - custom_accuracy_without_padding: 0.4845 - custom_mse: 0.0502 - loss: 0.0502 - val_custom_accuracy_without_padding: 0.4744 - val_custom_mse: 0.0529 - val_loss: 0.0526 - learning_rate: 0.0010\n",
            "Epoch 66/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.4933 - custom_mse: 0.0495 - loss: 0.0495\n",
            "Epoch 66: val_loss did not improve from 0.05244\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - custom_accuracy_without_padding: 0.4930 - custom_mse: 0.0495 - loss: 0.0495 - val_custom_accuracy_without_padding: 0.4559 - val_custom_mse: 0.0528 - val_loss: 0.0526 - learning_rate: 0.0010\n",
            "Epoch 67/500\n",
            "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.4805 - custom_mse: 0.0510 - loss: 0.0510\n",
            "Epoch 67: val_loss improved from 0.05244 to 0.05222, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - custom_accuracy_without_padding: 0.4811 - custom_mse: 0.0509 - loss: 0.0509 - val_custom_accuracy_without_padding: 0.4749 - val_custom_mse: 0.0523 - val_loss: 0.0522 - learning_rate: 0.0010\n",
            "Epoch 68/500\n",
            "\u001b[1m14/25\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - custom_accuracy_without_padding: 0.4838 - custom_mse: 0.0488 - loss: 0.0488   \n",
            "Epoch 68: val_loss improved from 0.05222 to 0.05193, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.4827 - custom_mse: 0.0494 - loss: 0.0494 - val_custom_accuracy_without_padding: 0.4807 - val_custom_mse: 0.0522 - val_loss: 0.0519 - learning_rate: 0.0010\n",
            "Epoch 69/500\n",
            "\u001b[1m20/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.4895 - custom_mse: 0.0502 - loss: 0.0502\n",
            "Epoch 69: val_loss did not improve from 0.05193\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.4893 - custom_mse: 0.0501 - loss: 0.0501 - val_custom_accuracy_without_padding: 0.4800 - val_custom_mse: 0.0524 - val_loss: 0.0522 - learning_rate: 0.0010\n",
            "Epoch 70/500\n",
            "\u001b[1m17/25\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - custom_accuracy_without_padding: 0.4818 - custom_mse: 0.0493 - loss: 0.0493  \n",
            "Epoch 70: val_loss improved from 0.05193 to 0.05149, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - custom_accuracy_without_padding: 0.4831 - custom_mse: 0.0495 - loss: 0.0495 - val_custom_accuracy_without_padding: 0.4785 - val_custom_mse: 0.0517 - val_loss: 0.0515 - learning_rate: 0.0010\n",
            "Epoch 71/500\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.4941 - custom_mse: 0.0497 - loss: 0.0497\n",
            "Epoch 71: val_loss did not improve from 0.05149\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.4940 - custom_mse: 0.0497 - loss: 0.0497 - val_custom_accuracy_without_padding: 0.4749 - val_custom_mse: 0.0518 - val_loss: 0.0517 - learning_rate: 0.0010\n",
            "Epoch 72/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.4925 - custom_mse: 0.0487 - loss: 0.0487  \n",
            "Epoch 72: val_loss did not improve from 0.05149\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.4924 - custom_mse: 0.0488 - loss: 0.0488 - val_custom_accuracy_without_padding: 0.4858 - val_custom_mse: 0.0519 - val_loss: 0.0516 - learning_rate: 0.0010\n",
            "Epoch 73/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.4870 - custom_mse: 0.0486 - loss: 0.0486  \n",
            "Epoch 73: val_loss improved from 0.05149 to 0.05140, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.4869 - custom_mse: 0.0487 - loss: 0.0487 - val_custom_accuracy_without_padding: 0.4737 - val_custom_mse: 0.0515 - val_loss: 0.0514 - learning_rate: 0.0010\n",
            "Epoch 74/500\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.4837 - custom_mse: 0.0490 - loss: 0.0490 \n",
            "Epoch 74: val_loss improved from 0.05140 to 0.05107, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.4838 - custom_mse: 0.0491 - loss: 0.0491 - val_custom_accuracy_without_padding: 0.4934 - val_custom_mse: 0.0512 - val_loss: 0.0511 - learning_rate: 0.0010\n",
            "Epoch 75/500\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5017 - custom_mse: 0.0483 - loss: 0.0483 \n",
            "Epoch 75: val_loss improved from 0.05107 to 0.05065, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5014 - custom_mse: 0.0484 - loss: 0.0484 - val_custom_accuracy_without_padding: 0.4858 - val_custom_mse: 0.0509 - val_loss: 0.0507 - learning_rate: 0.0010\n",
            "Epoch 76/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - custom_accuracy_without_padding: 0.4907 - custom_mse: 0.0455 - loss: 0.0455\n",
            "Epoch 76: val_loss did not improve from 0.05065\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.4947 - custom_mse: 0.0486 - loss: 0.0486 - val_custom_accuracy_without_padding: 0.4974 - val_custom_mse: 0.0508 - val_loss: 0.0507 - learning_rate: 0.0010\n",
            "Epoch 77/500\n",
            "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5051 - custom_mse: 0.0480 - loss: 0.0480  \n",
            "Epoch 77: val_loss improved from 0.05065 to 0.05031, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5044 - custom_mse: 0.0481 - loss: 0.0481 - val_custom_accuracy_without_padding: 0.4916 - val_custom_mse: 0.0505 - val_loss: 0.0503 - learning_rate: 0.0010\n",
            "Epoch 78/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - custom_accuracy_without_padding: 0.5000 - custom_mse: 0.0472 - loss: 0.0472\n",
            "Epoch 78: val_loss improved from 0.05031 to 0.05011, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.4975 - custom_mse: 0.0478 - loss: 0.0478 - val_custom_accuracy_without_padding: 0.4854 - val_custom_mse: 0.0503 - val_loss: 0.0501 - learning_rate: 0.0010\n",
            "Epoch 79/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - custom_accuracy_without_padding: 0.4931 - custom_mse: 0.0419 - loss: 0.0419\n",
            "Epoch 79: val_loss improved from 0.05011 to 0.05001, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5022 - custom_mse: 0.0473 - loss: 0.0473 - val_custom_accuracy_without_padding: 0.4949 - val_custom_mse: 0.0502 - val_loss: 0.0500 - learning_rate: 0.0010\n",
            "Epoch 80/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - custom_accuracy_without_padding: 0.5127 - custom_mse: 0.0453 - loss: 0.0453\n",
            "Epoch 80: val_loss improved from 0.05001 to 0.04968, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5081 - custom_mse: 0.0478 - loss: 0.0478 - val_custom_accuracy_without_padding: 0.4909 - val_custom_mse: 0.0499 - val_loss: 0.0497 - learning_rate: 0.0010\n",
            "Epoch 81/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - custom_accuracy_without_padding: 0.5266 - custom_mse: 0.0479 - loss: 0.0479\n",
            "Epoch 81: val_loss did not improve from 0.04968\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.5060 - custom_mse: 0.0476 - loss: 0.0476 - val_custom_accuracy_without_padding: 0.4931 - val_custom_mse: 0.0506 - val_loss: 0.0504 - learning_rate: 0.0010\n",
            "Epoch 82/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - custom_accuracy_without_padding: 0.5231 - custom_mse: 0.0460 - loss: 0.0460\n",
            "Epoch 82: val_loss improved from 0.04968 to 0.04955, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5088 - custom_mse: 0.0472 - loss: 0.0472 - val_custom_accuracy_without_padding: 0.5061 - val_custom_mse: 0.0496 - val_loss: 0.0495 - learning_rate: 0.0010\n",
            "Epoch 83/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - custom_accuracy_without_padding: 0.5116 - custom_mse: 0.0471 - loss: 0.0471\n",
            "Epoch 83: val_loss improved from 0.04955 to 0.04935, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5120 - custom_mse: 0.0475 - loss: 0.0475 - val_custom_accuracy_without_padding: 0.4990 - val_custom_mse: 0.0495 - val_loss: 0.0493 - learning_rate: 0.0010\n",
            "Epoch 84/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5145 - custom_mse: 0.0467 - loss: 0.0467 \n",
            "Epoch 84: val_loss improved from 0.04935 to 0.04915, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5145 - custom_mse: 0.0467 - loss: 0.0467 - val_custom_accuracy_without_padding: 0.5058 - val_custom_mse: 0.0494 - val_loss: 0.0492 - learning_rate: 0.0010\n",
            "Epoch 85/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - custom_accuracy_without_padding: 0.5174 - custom_mse: 0.0479 - loss: 0.0479\n",
            "Epoch 85: val_loss did not improve from 0.04915\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.5128 - custom_mse: 0.0469 - loss: 0.0469 - val_custom_accuracy_without_padding: 0.5078 - val_custom_mse: 0.0493 - val_loss: 0.0492 - learning_rate: 0.0010\n",
            "Epoch 86/500\n",
            "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5102 - custom_mse: 0.0479 - loss: 0.0479  \n",
            "Epoch 86: val_loss did not improve from 0.04915\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.5104 - custom_mse: 0.0478 - loss: 0.0478 - val_custom_accuracy_without_padding: 0.4962 - val_custom_mse: 0.0498 - val_loss: 0.0497 - learning_rate: 0.0010\n",
            "Epoch 87/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5139 - custom_mse: 0.0467 - loss: 0.0467  \n",
            "Epoch 87: val_loss improved from 0.04915 to 0.04895, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5140 - custom_mse: 0.0467 - loss: 0.0467 - val_custom_accuracy_without_padding: 0.5126 - val_custom_mse: 0.0490 - val_loss: 0.0490 - learning_rate: 0.0010\n",
            "Epoch 88/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5210 - custom_mse: 0.0473 - loss: 0.0473  \n",
            "Epoch 88: val_loss improved from 0.04895 to 0.04884, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5210 - custom_mse: 0.0473 - loss: 0.0473 - val_custom_accuracy_without_padding: 0.5094 - val_custom_mse: 0.0490 - val_loss: 0.0488 - learning_rate: 0.0010\n",
            "Epoch 89/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - custom_accuracy_without_padding: 0.5093 - custom_mse: 0.0442 - loss: 0.0442\n",
            "Epoch 89: val_loss did not improve from 0.04884\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.5225 - custom_mse: 0.0462 - loss: 0.0462 - val_custom_accuracy_without_padding: 0.5126 - val_custom_mse: 0.0492 - val_loss: 0.0490 - learning_rate: 0.0010\n",
            "Epoch 90/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5164 - custom_mse: 0.0466 - loss: 0.0466  \n",
            "Epoch 90: val_loss did not improve from 0.04884\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.5165 - custom_mse: 0.0466 - loss: 0.0466 - val_custom_accuracy_without_padding: 0.5187 - val_custom_mse: 0.0490 - val_loss: 0.0489 - learning_rate: 0.0010\n",
            "Epoch 91/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - custom_accuracy_without_padding: 0.5347 - custom_mse: 0.0460 - loss: 0.0460\n",
            "Epoch 91: val_loss improved from 0.04884 to 0.04850, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5256 - custom_mse: 0.0464 - loss: 0.0464 - val_custom_accuracy_without_padding: 0.5210 - val_custom_mse: 0.0487 - val_loss: 0.0485 - learning_rate: 0.0010\n",
            "Epoch 92/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - custom_accuracy_without_padding: 0.5255 - custom_mse: 0.0459 - loss: 0.0459\n",
            "Epoch 92: val_loss did not improve from 0.04850\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.5224 - custom_mse: 0.0464 - loss: 0.0464 - val_custom_accuracy_without_padding: 0.5179 - val_custom_mse: 0.0488 - val_loss: 0.0487 - learning_rate: 0.0010\n",
            "Epoch 93/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - custom_accuracy_without_padding: 0.5174 - custom_mse: 0.0476 - loss: 0.0476\n",
            "Epoch 93: val_loss did not improve from 0.04850\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.5256 - custom_mse: 0.0466 - loss: 0.0466 - val_custom_accuracy_without_padding: 0.5228 - val_custom_mse: 0.0489 - val_loss: 0.0489 - learning_rate: 0.0010\n",
            "Epoch 94/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5209 - custom_mse: 0.0465 - loss: 0.0465  \n",
            "Epoch 94: val_loss improved from 0.04850 to 0.04821, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5209 - custom_mse: 0.0465 - loss: 0.0465 - val_custom_accuracy_without_padding: 0.5177 - val_custom_mse: 0.0483 - val_loss: 0.0482 - learning_rate: 0.0010\n",
            "Epoch 95/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5223 - custom_mse: 0.0471 - loss: 0.0471  \n",
            "Epoch 95: val_loss did not improve from 0.04821\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.5225 - custom_mse: 0.0471 - loss: 0.0471 - val_custom_accuracy_without_padding: 0.5230 - val_custom_mse: 0.0485 - val_loss: 0.0483 - learning_rate: 0.0010\n",
            "Epoch 96/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - custom_accuracy_without_padding: 0.5278 - custom_mse: 0.0491 - loss: 0.0491\n",
            "Epoch 96: val_loss did not improve from 0.04821\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.5266 - custom_mse: 0.0473 - loss: 0.0473 - val_custom_accuracy_without_padding: 0.5202 - val_custom_mse: 0.0485 - val_loss: 0.0484 - learning_rate: 0.0010\n",
            "Epoch 97/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - custom_accuracy_without_padding: 0.5116 - custom_mse: 0.0472 - loss: 0.0472\n",
            "Epoch 97: val_loss did not improve from 0.04821\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.5253 - custom_mse: 0.0464 - loss: 0.0464 - val_custom_accuracy_without_padding: 0.5172 - val_custom_mse: 0.0487 - val_loss: 0.0486 - learning_rate: 0.0010\n",
            "Epoch 98/500\n",
            "\u001b[1m16/25\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - custom_accuracy_without_padding: 0.5276 - custom_mse: 0.0462 - loss: 0.0462  \n",
            "Epoch 98: val_loss improved from 0.04821 to 0.04800, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.5287 - custom_mse: 0.0463 - loss: 0.0463 - val_custom_accuracy_without_padding: 0.5261 - val_custom_mse: 0.0482 - val_loss: 0.0480 - learning_rate: 0.0010\n",
            "Epoch 99/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - custom_accuracy_without_padding: 0.5255 - custom_mse: 0.0499 - loss: 0.0499\n",
            "Epoch 99: val_loss did not improve from 0.04800\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.5283 - custom_mse: 0.0471 - loss: 0.0471 - val_custom_accuracy_without_padding: 0.5124 - val_custom_mse: 0.0487 - val_loss: 0.0485 - learning_rate: 0.0010\n",
            "Epoch 100/500\n",
            "\u001b[1m15/25\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - custom_accuracy_without_padding: 0.5213 - custom_mse: 0.0463 - loss: 0.0463  \n",
            "Epoch 100: val_loss did not improve from 0.04800\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.5228 - custom_mse: 0.0462 - loss: 0.0462 - val_custom_accuracy_without_padding: 0.5296 - val_custom_mse: 0.0482 - val_loss: 0.0480 - learning_rate: 0.0010\n",
            "Epoch 101/500\n",
            "\u001b[1m14/25\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - custom_accuracy_without_padding: 0.5363 - custom_mse: 0.0451 - loss: 0.0451 \n",
            "Epoch 101: val_loss improved from 0.04800 to 0.04782, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.5346 - custom_mse: 0.0453 - loss: 0.0453 - val_custom_accuracy_without_padding: 0.5284 - val_custom_mse: 0.0479 - val_loss: 0.0478 - learning_rate: 0.0010\n",
            "Epoch 102/500\n",
            "\u001b[1m18/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - custom_accuracy_without_padding: 0.5331 - custom_mse: 0.0463 - loss: 0.0463  \n",
            "Epoch 102: val_loss did not improve from 0.04782\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5330 - custom_mse: 0.0461 - loss: 0.0461 - val_custom_accuracy_without_padding: 0.5293 - val_custom_mse: 0.0479 - val_loss: 0.0478 - learning_rate: 0.0010\n",
            "Epoch 103/500\n",
            "\u001b[1m14/25\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - custom_accuracy_without_padding: 0.5407 - custom_mse: 0.0452 - loss: 0.0452  \n",
            "Epoch 103: val_loss improved from 0.04782 to 0.04766, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.5377 - custom_mse: 0.0454 - loss: 0.0454 - val_custom_accuracy_without_padding: 0.5298 - val_custom_mse: 0.0478 - val_loss: 0.0477 - learning_rate: 0.0010\n",
            "Epoch 104/500\n",
            "\u001b[1m17/25\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - custom_accuracy_without_padding: 0.5392 - custom_mse: 0.0459 - loss: 0.0459  \n",
            "Epoch 104: val_loss did not improve from 0.04766\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.5385 - custom_mse: 0.0458 - loss: 0.0458 - val_custom_accuracy_without_padding: 0.5213 - val_custom_mse: 0.0480 - val_loss: 0.0478 - learning_rate: 0.0010\n",
            "Epoch 105/500\n",
            "\u001b[1m14/25\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - custom_accuracy_without_padding: 0.5364 - custom_mse: 0.0452 - loss: 0.0452 \n",
            "Epoch 105: val_loss did not improve from 0.04766\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.5350 - custom_mse: 0.0453 - loss: 0.0453 - val_custom_accuracy_without_padding: 0.5311 - val_custom_mse: 0.0481 - val_loss: 0.0479 - learning_rate: 0.0010\n",
            "Epoch 106/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5356 - custom_mse: 0.0446 - loss: 0.0446  \n",
            "Epoch 106: val_loss did not improve from 0.04766\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.5356 - custom_mse: 0.0446 - loss: 0.0446 - val_custom_accuracy_without_padding: 0.5205 - val_custom_mse: 0.0484 - val_loss: 0.0482 - learning_rate: 0.0010\n",
            "Epoch 107/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5326 - custom_mse: 0.0459 - loss: 0.0459  \n",
            "Epoch 107: val_loss improved from 0.04766 to 0.04757, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5326 - custom_mse: 0.0459 - loss: 0.0459 - val_custom_accuracy_without_padding: 0.5308 - val_custom_mse: 0.0478 - val_loss: 0.0476 - learning_rate: 0.0010\n",
            "Epoch 108/500\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5342 - custom_mse: 0.0455 - loss: 0.0455 \n",
            "Epoch 108: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.04757\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.5343 - custom_mse: 0.0455 - loss: 0.0455 - val_custom_accuracy_without_padding: 0.5106 - val_custom_mse: 0.0482 - val_loss: 0.0480 - learning_rate: 0.0010\n",
            "Epoch 109/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - custom_accuracy_without_padding: 0.5255 - custom_mse: 0.0476 - loss: 0.0476\n",
            "Epoch 109: val_loss improved from 0.04757 to 0.04711, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5376 - custom_mse: 0.0454 - loss: 0.0454 - val_custom_accuracy_without_padding: 0.5355 - val_custom_mse: 0.0473 - val_loss: 0.0471 - learning_rate: 5.0000e-04\n",
            "Epoch 110/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - custom_accuracy_without_padding: 0.5324 - custom_mse: 0.0441 - loss: 0.0441\n",
            "Epoch 110: val_loss did not improve from 0.04711\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.5460 - custom_mse: 0.0443 - loss: 0.0443 - val_custom_accuracy_without_padding: 0.5379 - val_custom_mse: 0.0474 - val_loss: 0.0473 - learning_rate: 5.0000e-04\n",
            "Epoch 111/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - custom_accuracy_without_padding: 0.5683 - custom_mse: 0.0414 - loss: 0.0414\n",
            "Epoch 111: val_loss did not improve from 0.04711\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.5503 - custom_mse: 0.0443 - loss: 0.0443 - val_custom_accuracy_without_padding: 0.5380 - val_custom_mse: 0.0473 - val_loss: 0.0471 - learning_rate: 5.0000e-04\n",
            "Epoch 112/500\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5405 - custom_mse: 0.0451 - loss: 0.0451  \n",
            "Epoch 112: val_loss did not improve from 0.04711\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.5409 - custom_mse: 0.0450 - loss: 0.0450 - val_custom_accuracy_without_padding: 0.5397 - val_custom_mse: 0.0474 - val_loss: 0.0473 - learning_rate: 5.0000e-04\n",
            "Epoch 113/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5468 - custom_mse: 0.0451 - loss: 0.0451  \n",
            "Epoch 113: val_loss improved from 0.04711 to 0.04704, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.5468 - custom_mse: 0.0451 - loss: 0.0451 - val_custom_accuracy_without_padding: 0.5379 - val_custom_mse: 0.0472 - val_loss: 0.0470 - learning_rate: 5.0000e-04\n",
            "Epoch 114/500\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5479 - custom_mse: 0.0439 - loss: 0.0439 \n",
            "Epoch 114: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 114: val_loss did not improve from 0.04704\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.5477 - custom_mse: 0.0440 - loss: 0.0440 - val_custom_accuracy_without_padding: 0.5355 - val_custom_mse: 0.0477 - val_loss: 0.0476 - learning_rate: 5.0000e-04\n",
            "Epoch 115/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5421 - custom_mse: 0.0445 - loss: 0.0445 \n",
            "Epoch 115: val_loss improved from 0.04704 to 0.04695, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.5423 - custom_mse: 0.0445 - loss: 0.0445 - val_custom_accuracy_without_padding: 0.5430 - val_custom_mse: 0.0471 - val_loss: 0.0469 - learning_rate: 2.5000e-04\n",
            "Epoch 116/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5473 - custom_mse: 0.0448 - loss: 0.0448 \n",
            "Epoch 116: val_loss improved from 0.04695 to 0.04693, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5473 - custom_mse: 0.0448 - loss: 0.0448 - val_custom_accuracy_without_padding: 0.5433 - val_custom_mse: 0.0471 - val_loss: 0.0469 - learning_rate: 2.5000e-04\n",
            "Epoch 117/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - custom_accuracy_without_padding: 0.5370 - custom_mse: 0.0451 - loss: 0.0451\n",
            "Epoch 117: val_loss did not improve from 0.04693\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.5449 - custom_mse: 0.0443 - loss: 0.0443 - val_custom_accuracy_without_padding: 0.5433 - val_custom_mse: 0.0472 - val_loss: 0.0470 - learning_rate: 2.5000e-04\n",
            "Epoch 118/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - custom_accuracy_without_padding: 0.5556 - custom_mse: 0.0437 - loss: 0.0437\n",
            "Epoch 118: val_loss did not improve from 0.04693\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.5489 - custom_mse: 0.0440 - loss: 0.0440 - val_custom_accuracy_without_padding: 0.5443 - val_custom_mse: 0.0471 - val_loss: 0.0469 - learning_rate: 2.5000e-04\n",
            "Epoch 119/500\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5465 - custom_mse: 0.0449 - loss: 0.0449  \n",
            "Epoch 119: val_loss did not improve from 0.04693\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.5467 - custom_mse: 0.0449 - loss: 0.0449 - val_custom_accuracy_without_padding: 0.5422 - val_custom_mse: 0.0471 - val_loss: 0.0469 - learning_rate: 2.5000e-04\n",
            "Epoch 120/500\n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - custom_accuracy_without_padding: 0.5523 - custom_mse: 0.0446 - loss: 0.0446  \n",
            "Epoch 120: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 120: val_loss did not improve from 0.04693\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.5518 - custom_mse: 0.0445 - loss: 0.0445 - val_custom_accuracy_without_padding: 0.5432 - val_custom_mse: 0.0471 - val_loss: 0.0469 - learning_rate: 2.5000e-04\n",
            "Epoch 121/500\n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - custom_accuracy_without_padding: 0.5506 - custom_mse: 0.0453 - loss: 0.0453  \n",
            "Epoch 121: val_loss improved from 0.04693 to 0.04690, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5505 - custom_mse: 0.0451 - loss: 0.0451 - val_custom_accuracy_without_padding: 0.5448 - val_custom_mse: 0.0471 - val_loss: 0.0469 - learning_rate: 1.2500e-04\n",
            "Epoch 122/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5534 - custom_mse: 0.0441 - loss: 0.0441  \n",
            "Epoch 122: val_loss improved from 0.04690 to 0.04681, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5533 - custom_mse: 0.0441 - loss: 0.0441 - val_custom_accuracy_without_padding: 0.5433 - val_custom_mse: 0.0469 - val_loss: 0.0468 - learning_rate: 1.2500e-04\n",
            "Epoch 123/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5458 - custom_mse: 0.0440 - loss: 0.0440 \n",
            "Epoch 123: val_loss did not improve from 0.04681\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.5460 - custom_mse: 0.0440 - loss: 0.0440 - val_custom_accuracy_without_padding: 0.5440 - val_custom_mse: 0.0470 - val_loss: 0.0468 - learning_rate: 1.2500e-04\n",
            "Epoch 124/500\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5454 - custom_mse: 0.0440 - loss: 0.0440 \n",
            "Epoch 124: val_loss did not improve from 0.04681\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5457 - custom_mse: 0.0441 - loss: 0.0441 - val_custom_accuracy_without_padding: 0.5450 - val_custom_mse: 0.0470 - val_loss: 0.0468 - learning_rate: 1.2500e-04\n",
            "Epoch 125/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - custom_accuracy_without_padding: 0.5579 - custom_mse: 0.0452 - loss: 0.0452\n",
            "Epoch 125: val_loss did not improve from 0.04681\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.5495 - custom_mse: 0.0446 - loss: 0.0446 - val_custom_accuracy_without_padding: 0.5445 - val_custom_mse: 0.0470 - val_loss: 0.0469 - learning_rate: 1.2500e-04\n",
            "Epoch 126/500\n",
            "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5484 - custom_mse: 0.0440 - loss: 0.0440  \n",
            "Epoch 126: val_loss improved from 0.04681 to 0.04680, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.5486 - custom_mse: 0.0440 - loss: 0.0440 - val_custom_accuracy_without_padding: 0.5450 - val_custom_mse: 0.0469 - val_loss: 0.0468 - learning_rate: 1.2500e-04\n",
            "Epoch 127/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - custom_accuracy_without_padding: 0.5509 - custom_mse: 0.0411 - loss: 0.0411\n",
            "Epoch 127: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 127: val_loss did not improve from 0.04680\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.5499 - custom_mse: 0.0444 - loss: 0.0444 - val_custom_accuracy_without_padding: 0.5445 - val_custom_mse: 0.0470 - val_loss: 0.0468 - learning_rate: 1.2500e-04\n",
            "Epoch 128/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5517 - custom_mse: 0.0442 - loss: 0.0442 \n",
            "Epoch 128: val_loss improved from 0.04680 to 0.04679, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5516 - custom_mse: 0.0442 - loss: 0.0442 - val_custom_accuracy_without_padding: 0.5451 - val_custom_mse: 0.0469 - val_loss: 0.0468 - learning_rate: 6.2500e-05\n",
            "Epoch 129/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - custom_accuracy_without_padding: 0.5312 - custom_mse: 0.0454 - loss: 0.0454\n",
            "Epoch 129: val_loss did not improve from 0.04679\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.5464 - custom_mse: 0.0444 - loss: 0.0444 - val_custom_accuracy_without_padding: 0.5450 - val_custom_mse: 0.0469 - val_loss: 0.0468 - learning_rate: 6.2500e-05\n",
            "Epoch 130/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5485 - custom_mse: 0.0450 - loss: 0.0450  \n",
            "Epoch 130: val_loss improved from 0.04679 to 0.04677, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5486 - custom_mse: 0.0450 - loss: 0.0450 - val_custom_accuracy_without_padding: 0.5450 - val_custom_mse: 0.0469 - val_loss: 0.0468 - learning_rate: 6.2500e-05\n",
            "Epoch 131/500\n",
            "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - custom_accuracy_without_padding: 0.5519 - custom_mse: 0.0436 - loss: 0.0436  \n",
            "Epoch 131: val_loss did not improve from 0.04677\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5517 - custom_mse: 0.0437 - loss: 0.0437 - val_custom_accuracy_without_padding: 0.5448 - val_custom_mse: 0.0469 - val_loss: 0.0468 - learning_rate: 6.2500e-05\n",
            "Epoch 132/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - custom_accuracy_without_padding: 0.5625 - custom_mse: 0.0475 - loss: 0.0475\n",
            "Epoch 132: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 132: val_loss improved from 0.04677 to 0.04675, saving model to /content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_27.keras\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5478 - custom_mse: 0.0449 - loss: 0.0449 - val_custom_accuracy_without_padding: 0.5453 - val_custom_mse: 0.0469 - val_loss: 0.0467 - learning_rate: 6.2500e-05\n",
            "Epoch 133/500\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5496 - custom_mse: 0.0443 - loss: 0.0443  \n",
            "Epoch 133: val_loss did not improve from 0.04675\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.5498 - custom_mse: 0.0443 - loss: 0.0443 - val_custom_accuracy_without_padding: 0.5455 - val_custom_mse: 0.0469 - val_loss: 0.0468 - learning_rate: 3.1250e-05\n",
            "Epoch 134/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - custom_accuracy_without_padding: 0.5822 - custom_mse: 0.0396 - loss: 0.0396\n",
            "Epoch 134: val_loss did not improve from 0.04675\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.5527 - custom_mse: 0.0434 - loss: 0.0434 - val_custom_accuracy_without_padding: 0.5450 - val_custom_mse: 0.0469 - val_loss: 0.0468 - learning_rate: 3.1250e-05\n",
            "Epoch 135/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5505 - custom_mse: 0.0447 - loss: 0.0447 \n",
            "Epoch 135: val_loss did not improve from 0.04675\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.5505 - custom_mse: 0.0447 - loss: 0.0447 - val_custom_accuracy_without_padding: 0.5446 - val_custom_mse: 0.0469 - val_loss: 0.0468 - learning_rate: 3.1250e-05\n",
            "Epoch 136/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5480 - custom_mse: 0.0441 - loss: 0.0441  \n",
            "Epoch 136: val_loss did not improve from 0.04675\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.5481 - custom_mse: 0.0441 - loss: 0.0441 - val_custom_accuracy_without_padding: 0.5443 - val_custom_mse: 0.0469 - val_loss: 0.0468 - learning_rate: 3.1250e-05\n",
            "Epoch 137/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - custom_accuracy_without_padding: 0.5613 - custom_mse: 0.0423 - loss: 0.0423\n",
            "Epoch 137: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\n",
            "Epoch 137: val_loss did not improve from 0.04675\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.5523 - custom_mse: 0.0440 - loss: 0.0440 - val_custom_accuracy_without_padding: 0.5450 - val_custom_mse: 0.0469 - val_loss: 0.0468 - learning_rate: 3.1250e-05\n",
            "Epoch 138/500\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5531 - custom_mse: 0.0438 - loss: 0.0438 \n",
            "Epoch 138: val_loss did not improve from 0.04675\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.5529 - custom_mse: 0.0439 - loss: 0.0439 - val_custom_accuracy_without_padding: 0.5458 - val_custom_mse: 0.0469 - val_loss: 0.0468 - learning_rate: 1.5625e-05\n",
            "Epoch 139/500\n",
            "\u001b[1m 1/25\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - custom_accuracy_without_padding: 0.5347 - custom_mse: 0.0463 - loss: 0.0463\n",
            "Epoch 139: val_loss did not improve from 0.04675\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.5497 - custom_mse: 0.0447 - loss: 0.0447 - val_custom_accuracy_without_padding: 0.5455 - val_custom_mse: 0.0469 - val_loss: 0.0468 - learning_rate: 1.5625e-05\n",
            "Epoch 140/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5510 - custom_mse: 0.0442 - loss: 0.0442  \n",
            "Epoch 140: val_loss did not improve from 0.04675\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.5510 - custom_mse: 0.0442 - loss: 0.0442 - val_custom_accuracy_without_padding: 0.5458 - val_custom_mse: 0.0469 - val_loss: 0.0468 - learning_rate: 1.5625e-05\n",
            "Epoch 141/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5541 - custom_mse: 0.0446 - loss: 0.0446  \n",
            "Epoch 141: val_loss did not improve from 0.04675\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.5540 - custom_mse: 0.0446 - loss: 0.0446 - val_custom_accuracy_without_padding: 0.5455 - val_custom_mse: 0.0469 - val_loss: 0.0468 - learning_rate: 1.5625e-05\n",
            "Epoch 142/500\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - custom_accuracy_without_padding: 0.5468 - custom_mse: 0.0442 - loss: 0.0442 \n",
            "Epoch 142: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\n",
            "Epoch 142: val_loss did not improve from 0.04675\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.5471 - custom_mse: 0.0442 - loss: 0.0442 - val_custom_accuracy_without_padding: 0.5456 - val_custom_mse: 0.0469 - val_loss: 0.0468 - learning_rate: 1.5625e-05\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "checkpoint_path = f\"/content/drive/MyDrive/10 Masters/Research/error-correcting-codes/ThisIsTheCleanest/weights/ANN_model_{n}.keras\"\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "adjust_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=5,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=500,\n",
        "    batch_size=32,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[adjust_lr, early_stopping, model_checkpoint]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yHldkKB39Ry"
      },
      "source": [
        "Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3v8j07n39Ry",
        "outputId": "adbb001b-bf1d-435b-c68b-eb9461132b8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.5527 - custom_mse: 0.0461 - loss: 0.0461 \n",
            "Test results - Loss: 0.046747706830501556, MSE: 0.046886708587408066, Accuracy: 0.5453042387962341\n"
          ]
        }
      ],
      "source": [
        "eval_results = model.evaluate(x_test, y_test)\n",
        "print(f\"Test results - Loss: {eval_results[0]}, MSE: {eval_results[1]}, Accuracy: {eval_results[2]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "PX7cZ6Rr39Rz",
        "outputId": "47b05fef-2e21-46da-c469-d95f25e277b2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['custom_accuracy_without_padding'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_custom_accuracy_without_padding'], label='Validation Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict"
      ],
      "metadata": {
        "id": "dvFI3YwIAwGM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9p3lDWX39R1",
        "outputId": "171366f0-acb0-49f8-fa30-ca3017f7f6d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Comparison of predictions and ground truth:\n",
            "Sample 1:\n",
            "  Predicted:    [3 3 3 3 2 3 3 3 3 3 2 2 3 1 3 2 5 1 4 3 4 4 6 5 2 3 1 0 0 0 0 0]\n",
            "  Ground Truth: [5 6 5 1 3 4 1 1 6 2 3 1 4 0 3 2 5 1 4 3 4 4 6 5 2 3 1 0 0 0 0 0]\n",
            "----------------------------------------\n",
            "Sample 2:\n",
            "  Predicted:    [4 3 3 3 3 3 3 3 2 4 3 3 3 2 3 2 1 2 0 1 1 5 2 1 4 0 4 0 0 0 0 0]\n",
            "  Ground Truth: [1 4 1 3 3 3 0 5 5 2 4 3 3 1 3 1 1 2 0 1 1 5 2 1 4 0 4 0 0 0 0 0]\n",
            "----------------------------------------\n",
            "Sample 3:\n",
            "  Predicted:    [3 3 3 3 3 3 3 3 3 2 3 3 3 4 3 3 5 1 4 6 0 4 3 2 3 4 4 0 0 0 0 0]\n",
            "  Ground Truth: [2 6 0 2 2 1 3 4 2 6 4 1 0 5 2 3 5 1 4 6 0 4 3 2 3 4 4 0 0 0 0 0]\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(x_test)\n",
        "y_pred_rescaled = y_pred * (q-1)\n",
        "y_test_rescaled = y_test * (q-1)\n",
        "\n",
        "print(\"Comparison of predictions and ground truth:\")\n",
        "for i in range(3):\n",
        "    print(f\"Sample {i+1}:\")\n",
        "    print(f\"  Predicted:    {np.round(y_pred_rescaled[i]).astype(int)}\")\n",
        "    print(f\"  Ground Truth: {np.round(y_test_rescaled[i]).astype(int)}\")\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"R² Score: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rrdoPg65FNz",
        "outputId": "657a3990-11c1-41f5-d35f-7b41d44065e2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² Score: 0.4228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- Inference time on Test Set ----------------------------\n",
        "\n",
        "import time\n",
        "\n",
        "_ = model.predict(x_test, verbose=0)  # warm up\n",
        "\n",
        "times = []\n",
        "for _ in range(100):\n",
        "    start = time.perf_counter()\n",
        "    _ = model.predict(x_test, verbose=0)\n",
        "    end = time.perf_counter()\n",
        "    times.append(end - start)\n",
        "\n",
        "average_inference_time = np.mean(times)\n",
        "print(f\"Average batch inference time over 100 runs: {average_inference_time:.6f} seconds\")\n",
        "\n",
        "average_per_sample = average_inference_time / x_test.shape[0]\n",
        "print(f\"Average inference time per sample (from batch): {average_per_sample:.6f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0GHeUug-lJM",
        "outputId": "9593d9b0-1143-414c-f723-a5e8e6a289fc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average batch inference time over 100 runs: 0.109672 seconds\n",
            "Average inference time per sample (from batch): 0.000548 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyQx5pZf39R1",
        "outputId": "37df16b8-992a-4907-d8d1-83fcb132ceed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "MSE on unseen data: 0.04372256621718407\n",
            "Accuracy on unseen data: 0.5481481552124023\n",
            "Sample 1:\n",
            "[6. 3. 4. 6. 2. 4. 4. 6. 1. 2. 6. 2. 2. 4. 3. 2. 5. 4. 1. 3. 5. 5. 1. 3.\n",
            " 4. 0. 3. 0. 0. 0. 0. 0.]: True values\n",
            "[3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 2 5 4 1 3 5 5 1 3 4 0 3 0 0 0 0 0]: Predicted values\n",
            "--------------------\n",
            "Sample 2:\n",
            "[1. 5. 4. 3. 0. 0. 2. 2. 6. 1. 3. 3. 6. 5. 5. 6. 5. 2. 3. 6. 3. 0. 2. 4.\n",
            " 2. 6. 4. 0. 0. 0. 0. 0.]: True values\n",
            "[3 3 4 4 4 3 3 3 3 3 3 4 4 4 4 6 5 2 3 6 3 0 2 4 2 6 4 0 0 0 0 0]: Predicted values\n",
            "--------------------\n",
            "Sample 3:\n",
            "[0. 6. 1. 3. 0. 3. 5. 1. 1. 0. 1. 4. 1. 3. 3. 6. 3. 6. 3. 4. 6. 2. 5. 0.\n",
            " 3. 1. 3. 0. 0. 0. 0. 0.]: True values\n",
            "[3 3 3 4 3 3 3 4 3 3 3 3 2 2 3 6 3 6 3 4 6 2 5 0 3 1 3 0 0 0 0 0]: Predicted values\n",
            "--------------------\n"
          ]
        }
      ],
      "source": [
        "# --------------------- Predictions on unseen samples -------------------------\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "unseen_data = np.random.randint(0, q, size=(num_unseen_samples, n))\n",
        "\n",
        "padded_unseen_data = np.hstack((unseen_data, np.zeros((num_unseen_samples, n_padded - n))))\n",
        "\n",
        "unseen_data_normalized = padded_unseen_data.astype(np.float32) / (q - 1)\n",
        "\n",
        "unseen_encoded = np.array([np.dot(M_tilde, x) for x in padded_unseen_data])\n",
        "unseen_encoded[np.abs(unseen_encoded) < 1e-10] = 0\n",
        "unseen_encoded = np.round(unseen_encoded, decimals=10)\n",
        "\n",
        "X_real_unseen = np.real(unseen_encoded).astype(np.float32)\n",
        "X_imag_unseen = np.imag(unseen_encoded).astype(np.float32)\n",
        "\n",
        "X_real_imag_unseen = np.hstack([X_real_unseen, X_imag_unseen])\n",
        "\n",
        "X_real_imag_unseen = (X_real_imag_unseen - X_real_imag_unseen.mean()) / X_real_imag_unseen.std()\n",
        "\n",
        "y_pred_unseen = model.predict(X_real_imag_unseen)\n",
        "\n",
        "mse_unseen = tf.reduce_mean(tf.square(unseen_data_normalized - y_pred_unseen)).numpy()\n",
        "print(f\"MSE on unseen data: {mse_unseen}\")\n",
        "\n",
        "accuracy_unseen = custom_accuracy_without_padding(unseen_data_normalized, y_pred_unseen)\n",
        "print(f\"Accuracy on unseen data: {accuracy_unseen}\")\n",
        "\n",
        "num_display_samples = 3\n",
        "for i in range(num_display_samples):\n",
        "    print(f\"Sample {i+1}:\")\n",
        "    true_labels = padded_unseen_data[i]\n",
        "    pred_scaled = y_pred_unseen[i] * (q - 1)\n",
        "    pred_rounded = tf.round(pred_scaled).numpy().astype(int)\n",
        "    print(f\"{true_labels}: True values\")\n",
        "    print(f\"{pred_rounded}: Predicted values\")\n",
        "    print(\"-\" * 20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# exclude zero pads\n",
        "y_pred_first_n = y_pred[:, :n]\n",
        "y_pred_first_n_rescaled = y_pred_first_n * (q - 1)\n",
        "\n",
        "plt.hist(y_pred_first_n_rescaled.flatten(), bins=50)\n",
        "plt.xlabel('Prediction Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "kD70EwfY5kFW",
        "outputId": "b2259c69-65f8-44bd-eaad-6c7397d34f1d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "8nidbP-E39R1"
      },
      "outputs": [],
      "source": [
        "# for layer in model.layers:\n",
        "#     if layer.trainable_variables:  # Check if the layer has trainable variables\n",
        "#         for i, var in enumerate(layer.trainable_variables):\n",
        "#             print(f\"{layer.name} - Variable {i} ({var.name}): values: {var.numpy()}\")\n",
        "#     else:\n",
        "#         print(layer.name, \"has no trainable variables.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "N7q_PYa739R2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}