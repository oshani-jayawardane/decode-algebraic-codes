{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-ud9f6pKYDR"
      },
      "source": [
        "### 3-layer DCT-III StNN - Generator matrix encoded data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qocs-9CH8ygv",
        "outputId": "29098832-fc13-4453-c0b0-b7b542429c6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 235,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%reset -f\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "id": "oneNe27mQFge"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from scipy.fftpack import dct\n",
        "import math\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "id": "MtNHp_3SQTvu"
      },
      "outputs": [],
      "source": [
        "# (x, y, z, w) --> (1, 2, 3, 4)\n",
        "global z0\n",
        "global w0\n",
        "\n",
        "w0 = 4\n",
        "z0 = 3\n",
        "\n",
        "n = 27\n",
        "q = 7\n",
        "\n",
        "num_samples = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0r-9MqtY73B",
        "outputId": "39a29177-80fa-427c-ccf9-a8c89ab87993"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original n: 27, Padded to: 32\n"
          ]
        }
      ],
      "source": [
        "def next_power_of_two(x):\n",
        "    return 2 ** math.ceil(math.log2(x))\n",
        "\n",
        "n_padded = next_power_of_two(n)\n",
        "\n",
        "x_original = np.random.randint(0, q, size=(num_samples, n))\n",
        "\n",
        "padding = n_padded - n\n",
        "dataset = np.pad(x_original, ((0, 0), (0, padding)), mode='constant', constant_values=0)\n",
        "\n",
        "print(f\"Original n: {n}, Padded to: {n_padded}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzQ0bCdWQXOk",
        "outputId": "ad302cb0-ea5c-4fb0-f48c-9ad5b0a3e494"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000, 27)"
            ]
          },
          "execution_count": 239,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_original.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vboxM2LadPcr",
        "outputId": "e260ba5c-d6e5-4300-d0a8-753b9ed8a6f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000, 32)"
            ]
          },
          "execution_count": 240,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqoj-jjAZAWc"
      },
      "source": [
        "Encode using generator matrix\n",
        "$$\n",
        "\\tilde{M}_{kj} = \\left[ \\left( \\frac{w_0}{z_0} \\right)^j \\zeta^{kj} \\right]_{k,j=0}^{n-1}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "64eOPlmF9Ex_"
      },
      "outputs": [],
      "source": [
        "def padded_generator_matrix(N, w0, z0):\n",
        "    n = np.arange(N)\n",
        "    k = n.reshape((N, 1))\n",
        "    zeta = np.exp(-2j * np.pi / N)\n",
        "    M_tilde = ((w0 / z0) ** n) * (zeta ** (k * n))\n",
        "    return M_tilde"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSIUpVnGQsG1",
        "outputId": "8528e1ec-f28e-4f81-d7d7-53e61a899ea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(32, 32)\n"
          ]
        }
      ],
      "source": [
        "M_tilde = padded_generator_matrix(n_padded, w0, z0)\n",
        "print(M_tilde.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRGEWiz9NzyQ",
        "outputId": "9b17f7b4-4099-4192-a5f4-c094c750e70f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000, 32)"
            ]
          },
          "execution_count": 243,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_dataset = np.array([np.dot(M_tilde, x) for x in dataset])\n",
        "encoded_dataset[np.abs(encoded_dataset) < 1e-10] = 0\n",
        "encoded_dataset = np.round(encoded_dataset, decimals=10)\n",
        "encoded_dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X06HpkJZG0d",
        "outputId": "201a3b5a-b691-47d3-a56d-5fa51a862f8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_original[0]: [6 3 4 6 2 4 4 6 1 2 6 2 2 4 3 2 5 4 1 3 5 5 1 3 4 0 3]\n",
            "\n",
            "After encoding:\n",
            " [18563.60052945    +0.j         -3175.07412411+14542.65392496j\n",
            " -9480.13851167 -1549.89213738j  -850.18419129 -5788.51248279j\n",
            "  2813.63372348 -2457.36436449j  3312.0476391   +337.88077825j\n",
            "  1059.2907911  +3489.68169028j -2366.82367016  +909.74502726j\n",
            "  -210.29906943  +357.85181443j -3878.07651347  +373.95548592j\n",
            "   -49.25036994 -6370.32567308j  6901.71964373 -1088.5938127j\n",
            "  2896.76301761 +7252.43377368j -6714.83312544 +4427.90575271j\n",
            " -5496.28870703 -5330.43278044j  2828.24226801 -6162.17891893j\n",
            "  6446.94186958    -0.j          2828.24226801 +6162.17891893j\n",
            " -5496.28870703 +5330.43278044j -6714.83312544 -4427.90575271j\n",
            "  2896.76301761 -7252.43377368j  6901.71964373 +1088.5938127j\n",
            "   -49.25036994 +6370.32567308j -3878.07651347  -373.95548592j\n",
            "  -210.29906943  -357.85181443j -2366.82367016  -909.74502726j\n",
            "  1059.2907911  -3489.68169028j  3312.0476391   -337.88077825j\n",
            "  2813.63372348 +2457.36436449j  -850.18419129 +5788.51248279j\n",
            " -9480.13851167 +1549.89213738j -3175.07412411-14542.65392496j]\n"
          ]
        }
      ],
      "source": [
        "print(f\"x_original[0]:\", x_original[0])\n",
        "print(f\"\\nAfter encoding:\\n\", encoded_dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWUxLrXBZIcT"
      },
      "outputs": [],
      "source": [
        "N = encoded_dataset.shape[1]\n",
        "\n",
        "k = np.arange(N)\n",
        "shift = np.exp(-1j * np.pi * k / (2 * N))\n",
        "alpha_k = np.where(k == 0, np.sqrt(1/N), np.sqrt(2/N))\n",
        "\n",
        "dct2_dataset = np.array([np.real(alpha_k * shift * y) for y in encoded_dataset])\n",
        "dct2_dataset[np.abs(dct2_dataset) < 1e-10] = 0\n",
        "dct2_dataset = np.round(dct2_dataset, decimals=10) # Round for numerical stability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwXaAAfPZKP4",
        "outputId": "9d523af0-7db3-4236-bb04-e3553ee852f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original x: [4 3 6 4 2 0 5 6 6 2 2 1 6 1 1 5 1 4 3 0 2 4 0 6 6 6 4 0 0 0 0 0]\n",
            "\n",
            "Encoded y: [ 29916.11588021    +0.j            328.95686704+26422.4846445j\n",
            " -21936.20111033 +3988.95593508j  -7301.38988823-17810.36382931j\n",
            "  13577.84642585 -8953.74117052j   9354.9421295  +8727.48732799j\n",
            "  -4221.49645678 +8798.15590637j  -7861.90722461  -861.73832776j\n",
            "   -779.76795929 -5322.56486315j   2168.22506293 -1740.90057156j\n",
            "   1615.33333537 -1441.8771791j    5127.91361716 +2018.69510167j\n",
            "  -2943.81135295 +6208.60576073j  -5262.87924206 -2070.18847016j\n",
            "    798.8487054  -4460.7613612j    2679.94226354  +633.97975698j\n",
            "   -477.22622529    -0.j           2679.94226354  -633.97975698j\n",
            "    798.8487054  +4460.7613612j   -5262.87924206 +2070.18847016j\n",
            "  -2943.81135295 -6208.60576073j   5127.91361716 -2018.69510167j\n",
            "   1615.33333537 +1441.8771791j    2168.22506293 +1740.90057156j\n",
            "   -779.76795929 +5322.56486315j  -7861.90722461  +861.73832776j\n",
            "  -4221.49645678 -8798.15590637j   9354.9421295  -8727.48732799j\n",
            "  13577.84642585 +8953.74117052j  -7301.38988823+17810.36382931j\n",
            " -21936.20111033 -3988.95593508j    328.95686704-26422.4846445j ]\n",
            "\n",
            "DCT Coefficients: [ 5288.4721   406.2626 -5359.8966 -2458.9216  2892.5409  2798.7982\n",
            "  -371.4376 -1923.1607  -689.3173   303.9303   186.2252  1359.0437\n",
            "   250.4067 -1365.0985  -553.0897   602.8653   -84.3625   332.4978\n",
            "   988.7499  -368.0756 -1699.4402   226.1955   508.2713   625.1978\n",
            "  1154.7511  -459.308  -2411.1865 -1548.2175  2857.651   4136.5643\n",
            " -1529.9679 -6593.6291]\n",
            "\n",
            "Reconstructed Signal: [ 4.0000000e+00  0.0000000e+00  4.0000000e+00  0.0000000e+00\n",
            "  1.0666700e+01 -0.0000000e+00  9.4815000e+00  0.0000000e+00\n",
            "  6.3210000e+00  0.0000000e+00  0.0000000e+00  7.0870769e+03\n",
            "  2.8093300e+01  7.9729615e+03  4.4949200e+01  5.9797211e+03\n",
            "  5.9932300e+01  4.4847908e+03  2.6636600e+01 -0.0000000e+00\n",
            "  3.5515500e+01  1.6817966e+03  2.3677000e+01  6.3067370e+02\n",
            "  1.8941580e+02  0.0000000e+00  4.2092400e+01  5.3213090e+02\n",
            "  5.6123200e+01  5.3213090e+02  3.7415460e+02  9.9774600e+01]\n",
            "\n",
            "After Permutation: [ 4.0000000e+00  4.0000000e+00  1.0666700e+01  9.4815000e+00\n",
            "  6.3210000e+00  0.0000000e+00  2.8093300e+01  4.4949200e+01\n",
            "  5.9932300e+01  2.6636600e+01  3.5515500e+01  2.3677000e+01\n",
            "  1.8941580e+02  4.2092400e+01  5.6123200e+01  3.7415460e+02\n",
            "  9.9774600e+01  5.3213090e+02  5.3213090e+02  0.0000000e+00\n",
            "  6.3067370e+02  1.6817966e+03 -0.0000000e+00  4.4847908e+03\n",
            "  5.9797211e+03  7.9729615e+03  7.0870769e+03  0.0000000e+00\n",
            "  0.0000000e+00 -0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            "\n",
            "After Scaling: [ 4.  3.  6.  4.  2.  0.  5.  6.  6.  2.  2.  1.  6.  1.  1.  5.  1.  4.\n",
            "  3.  0.  2.  4. -0.  6.  6.  6.  4.  0.  0. -0.  0.  0.]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "The part below is for testing purposes only\n",
        "\"\"\"\n",
        "\n",
        "from scipy.fftpack import dct\n",
        "\n",
        "dct3_dataset = np.array([dct(x, type=3, norm='ortho') for x in dct2_dataset])\n",
        "\n",
        "X_perm = np.hstack((dct3_dataset[:, ::2], dct3_dataset[:, 1::2][:, ::-1]))\n",
        "\n",
        "D_hat_n = np.array([(z0 / w0) ** k for k in range(N)])\n",
        "decoded_dataset = X_perm * D_hat_n\n",
        "\n",
        "# Print verification (for one sample)\n",
        "sample_idx = 78\n",
        "print(\"Original x:\", dataset[sample_idx])\n",
        "print(\"\\nEncoded y:\", encoded_dataset[sample_idx])\n",
        "print(\"\\nDCT Coefficients:\", np.round(dct2_dataset[sample_idx], 4))\n",
        "print(\"\\nReconstructed Signal:\", np.round(dct3_dataset[sample_idx], 4))\n",
        "print(\"\\nAfter Permutation:\", np.round(X_perm[sample_idx], 4))\n",
        "print(\"\\nAfter Scaling:\", np.round(decoded_dataset[sample_idx], 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "id": "928uXOxxWlF0"
      },
      "outputs": [],
      "source": [
        "y = dataset.astype(np.float32)\n",
        "y_normalized = y / (q - 1)  # Scale to [0, 1]\n",
        "\n",
        "# labels = y\n",
        "labels = y_normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZOVVoAFZLyI",
        "outputId": "2735d73d-0817-4da8-86bc-cde0471ab103"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(800, 32) (800, 32)\n",
            "(200, 32) (200, 32)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    dct2_dataset, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "8zK2aRevZPoV"
      },
      "outputs": [],
      "source": [
        "X_train = (X_train - X_train.mean()) / X_train.std()\n",
        "X_test = (X_test - X_test.mean()) / X_test.std()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5pqrx0t9He3"
      },
      "source": [
        "DCT-3 imposed 1 StNN (one custom layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "id": "oS5eTBiryfqP"
      },
      "outputs": [],
      "source": [
        "class FirstLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, trainable=True, **kwargs):\n",
        "        super(FirstLayer, self).__init__(**kwargs)\n",
        "        self.n = units\n",
        "        self.n1 = units // 2\n",
        "        self.trainable = trainable\n",
        "\n",
        "        init_diag = tf.ones(self.n1, dtype=tf.float32)\n",
        "        init_diag = tf.tensor_scatter_nd_update(init_diag, [[0]], [tf.sqrt(2.0)])\n",
        "\n",
        "        self.B_1 = self.add_weight(\n",
        "                shape=(self.n1,),\n",
        "                initializer=tf.keras.initializers.Constant(init_diag),\n",
        "                trainable=self.trainable,\n",
        "                name='B_1'\n",
        "            )\n",
        "        self.B_2 = self.add_weight(\n",
        "                shape=(self.n1,),\n",
        "                initializer='ones',\n",
        "                trainable=self.trainable,\n",
        "                name='B_2'\n",
        "            )\n",
        "        self.bias = self.add_weight(\n",
        "            shape=(self.n,),\n",
        "            initializer='zeros',\n",
        "            trainable=True,\n",
        "            name='bias'\n",
        "        )\n",
        "\n",
        "    def call(self, x):\n",
        "        even = x[:, ::2]\n",
        "        odd = x[:, 1::2]\n",
        "\n",
        "        d1 = tf.multiply(odd, self.B_1) # diagonal\n",
        "        d2 = tf.multiply(tf.concat([tf.zeros_like(odd[:, :1]), odd[:, :-1]], axis=1), self.B_2) # off-diagonal\n",
        "        B_n = tf.add(d1, d2)\n",
        "\n",
        "        u = tf.concat([even, B_n], axis=1)\n",
        "\n",
        "        return u + self.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcaYg5rTygAg"
      },
      "outputs": [],
      "source": [
        "class DCTIII(tf.keras.layers.Layer):\n",
        "    def __init__(self, n, trainable=True, **kwargs):\n",
        "        super(DCTIII, self).__init__(**kwargs)\n",
        "        self.n = n\n",
        "        self.n1 = n // 2 if n > 2 else 1\n",
        "        self.trainable = trainable\n",
        "\n",
        "        if n == 2:\n",
        "            # Base case: trainable 2x2 matrix\n",
        "            self.C_2 = self.add_weight(\n",
        "                shape=(2, 2),\n",
        "                initializer=tf.keras.initializers.Constant((1 / np.sqrt(2)) * np.array([[1., 1.], [1., -1.]])),\n",
        "                trainable=self.trainable,\n",
        "                name='C_2'\n",
        "            )\n",
        "        else:\n",
        "            init_diag = tf.ones(self.n1, dtype=tf.float32)\n",
        "            init_diag = tf.tensor_scatter_nd_update(init_diag, [[0]], [tf.sqrt(2.0)])\n",
        "\n",
        "            # Weights for B^T_{n/2}\n",
        "            self.B_1 = self.add_weight(\n",
        "                shape=(self.n1,),\n",
        "                initializer=tf.keras.initializers.Constant(init_diag),\n",
        "                trainable=self.trainable,\n",
        "                name='B_1'\n",
        "            )\n",
        "            self.B_2 = self.add_weight(\n",
        "                shape=(self.n1,),\n",
        "                initializer='ones',\n",
        "                trainable=self.trainable,\n",
        "                name='B_2'\n",
        "            )\n",
        "\n",
        "            k = tf.cast(tf.range(1, self.n1 + 1), tf.float32)\n",
        "            pi = tf.constant(np.pi, dtype=tf.float32)\n",
        "            init_W_c = 1 / (2 * tf.cos((2 * k - 1) * (pi / (2 * self.n))))\n",
        "\n",
        "            # Weight for W_c\n",
        "            self.w_c = self.add_weight(\n",
        "                shape=(self.n1,),\n",
        "                initializer=tf.keras.initializers.Constant(init_W_c),\n",
        "                trainable=self.trainable,\n",
        "                name='W_c'\n",
        "            )\n",
        "\n",
        "            # Recursive DCTIII for n/2\n",
        "            self.dctiii_layer1 = DCTIII(self.n1,trainable=self.trainable)\n",
        "            self.dctiii_layer2 = DCTIII(self.n1,trainable=self.trainable)\n",
        "\n",
        "    def call(self, x):\n",
        "        if self.n == 2:\n",
        "            y = tf.matmul(self.C_2, x, transpose_b=True)\n",
        "            return tf.transpose(y)\n",
        "        else:\n",
        "            # Permutation\n",
        "            even = x[:, ::2]\n",
        "            odd = x[:, 1::2]\n",
        "\n",
        "            # B^T\n",
        "            d1 = tf.multiply(odd, self.B_1)\n",
        "            d2 = tf.multiply(tf.concat([tf.zeros_like(odd[:, :1]), odd[:, :-1]], axis=1), self.B_2)\n",
        "            B_n = tf.add(d1, d2)\n",
        "            u = tf.concat([even, B_n], axis=1)\n",
        "\n",
        "            # Recursive DCTIII\n",
        "            z1 = self.dctiii_layer1(u[:, :self.n1])\n",
        "            z2 = self.dctiii_layer2(u[:, self.n1:])\n",
        "            recurs_out = tf.concat([z1, z2], axis=1)\n",
        "\n",
        "            # W_c\n",
        "            W_n = tf.multiply(recurs_out[:, self.n1:], self.w_c)\n",
        "            v = tf.concat([recurs_out[:, :self.n1], W_n], axis=1)\n",
        "\n",
        "            # H_n\n",
        "            out1 = v[:, :self.n1]\n",
        "            out2 = v[:, self.n1:]\n",
        "            y = (1 / tf.sqrt(tf.constant(2.0, dtype=tf.float32))) * tf.concat(\n",
        "                [(out1 + out2), tf.reverse((out1 - out2), axis=[1])],\n",
        "                axis=1\n",
        "            )\n",
        "\n",
        "            return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeXg1Z4SygVQ"
      },
      "outputs": [],
      "source": [
        "class SecondLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, trainable=True, **kwargs):\n",
        "        super(SecondLayer, self).__init__(**kwargs)\n",
        "        self.n = units\n",
        "        self.n1 = units // 2\n",
        "        self.trainable = trainable\n",
        "\n",
        "        self.bias = self.add_weight(\n",
        "            shape=(self.n,),\n",
        "            initializer='zeros',\n",
        "            trainable=True,\n",
        "            name='bias'\n",
        "        )\n",
        "\n",
        "        # Recursive DCTIII for n/2\n",
        "        self.dctiii1 = DCTIII(self.n1, trainable=self.trainable)\n",
        "        self.dctiii2 = DCTIII(self.n1,trainable=self.trainable)\n",
        "\n",
        "    def call(self, x):\n",
        "        z1 = self.dctiii1(x[:, :self.n1])\n",
        "        z2 = self.dctiii2(x[:, self.n1:])\n",
        "        out = tf.concat([z1, z2], axis=1)\n",
        "        return out + self.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glm5oQbeyg3Y"
      },
      "outputs": [],
      "source": [
        "class ThirdLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, trainable=True, **kwargs):\n",
        "        super(ThirdLayer, self).__init__(**kwargs)\n",
        "        self.n = units\n",
        "        self.n1 = units // 2\n",
        "        self.trainable = trainable\n",
        "\n",
        "        k = tf.cast(tf.range(1, self.n1 + 1), tf.float32)\n",
        "        pi = tf.constant(np.pi, dtype=tf.float32)\n",
        "        init_W_c = 1 / (2 * tf.cos((2 * k - 1) * (pi / (2 * self.n))))\n",
        "\n",
        "        self.w_c = self.add_weight(\n",
        "                shape=(self.n1,),\n",
        "                initializer=tf.keras.initializers.Constant(init_W_c),\n",
        "                trainable=self.trainable,\n",
        "                name='W_c'\n",
        "            )\n",
        "\n",
        "        self.bias = self.add_weight(\n",
        "            shape=(self.n,),\n",
        "            initializer='zeros',\n",
        "            trainable=True,\n",
        "            name='bias'\n",
        "        )\n",
        "\n",
        "    def call(self, x):\n",
        "        input1 = x[:, :self.n1]\n",
        "        input2 = x[:, self.n1:]\n",
        "\n",
        "        # W_{N/2}\n",
        "        W_n = tf.multiply(input2, self.w_c)\n",
        "        v = tf.concat([input1, W_n], axis=1)\n",
        "\n",
        "        # H_n^T\n",
        "        out1 = v[:, :self.n1]\n",
        "        out2 = v[:, self.n1:]\n",
        "\n",
        "        y = (1 / tf.sqrt(tf.constant(2.0, dtype=tf.float32))) * tf.concat([(out1 + out2), tf.reverse((out1 - out2), axis=[1])], axis=1)\n",
        "\n",
        "        return y + self.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "id": "pf57bB4nAyhO"
      },
      "outputs": [],
      "source": [
        "class DiagonalLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, trainable=True, kernel_initializer='he_normal', bias_initializer='zeros', **kwargs):\n",
        "        super(DiagonalLayer, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.bias_initializer = bias_initializer\n",
        "        self.trainable = trainable\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.diag = self.add_weight(\n",
        "            shape=(self.units,),\n",
        "            initializer=tf.keras.initializers.get(self.kernel_initializer),\n",
        "            trainable=self.trainable,\n",
        "            name='diag'\n",
        "        )\n",
        "        self.bias = self.add_weight(\n",
        "            shape=(self.units,),\n",
        "            initializer=tf.keras.initializers.get(self.bias_initializer),\n",
        "            trainable=self.trainable,\n",
        "            name='bias'\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        scaled = tf.multiply(inputs, self.diag)\n",
        "        return scaled + self.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AmJRF7yZkyY"
      },
      "outputs": [],
      "source": [
        "class ScalingLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, initial_scale=1.0, trainable=True, kernel_initializer='he_normal', bias_initializer='zeros', **kwargs):\n",
        "        super(ScalingLayer, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.initial_scale = initial_scale\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.bias_initializer = bias_initializer\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "      self.log_scale = self.add_weight(\n",
        "          shape=(),\n",
        "          initializer=tf.keras.initializers.Constant(self.initial_scale),\n",
        "          trainable=True,\n",
        "          name=\"log_scale\",\n",
        "      )\n",
        "      self.diag = self.add_weight(\n",
        "          shape=(self.units,),\n",
        "          initializer=tf.keras.initializers.get(self.kernel_initializer),\n",
        "          regularizer=tf.keras.regularizers.l2(1e-4),\n",
        "          trainable=True,\n",
        "          name='diag'\n",
        "      )\n",
        "      self.bias = self.add_weight(\n",
        "          shape=(self.units,),\n",
        "          initializer=tf.keras.initializers.get(self.bias_initializer),\n",
        "          trainable=True,\n",
        "          name='bias'\n",
        "        )\n",
        "\n",
        "      super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "      perm = tf.concat([inputs[:, ::2], inputs[:, 1::2][:, ::-1]], axis=-1)\n",
        "\n",
        "      dim = tf.shape(perm)[1]\n",
        "\n",
        "      D_hat_n = tf.exp(self.log_scale * tf.cast(tf.range(dim), tf.float32))\n",
        "\n",
        "      scaled = perm * D_hat_n * self.diag\n",
        "\n",
        "      return scaled + self.bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT8qO-gPZmDh"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJeHHbsUZXRH"
      },
      "outputs": [],
      "source": [
        "def custom_accuracy(y_true, y_pred):\n",
        "    y_true_int = tf.cast(y_true*(q-1), tf.int32)\n",
        "    y_pred_int = tf.cast(tf.round(y_pred*(q-1)), tf.int32)\n",
        "    correct = tf.cast(tf.equal(y_true_int, y_pred_int), tf.float32)\n",
        "    return tf.reduce_mean(correct)\n",
        "\n",
        "def custom_accuracy_without_padding(y_true, y_pred):\n",
        "    y_true_int = tf.cast(y_true * (q - 1), tf.int32)\n",
        "    y_pred_int = tf.cast(tf.round(y_pred * (q - 1)), tf.int32)\n",
        "    mask = tf.concat(\n",
        "        [tf.ones((tf.shape(y_true)[0], n), dtype=tf.float32),\n",
        "         tf.zeros((tf.shape(y_true)[0], n_padded - n), dtype=tf.float32)],\n",
        "        axis=1\n",
        "    )\n",
        "    correct = tf.cast(tf.equal(y_true_int, y_pred_int), tf.float32) * mask\n",
        "    return tf.reduce_sum(correct) / tf.reduce_sum(mask)\n",
        "\n",
        "def custom_mse(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    loss = tf.reduce_mean(tf.square(tf.cast(y_true - y_pred, tf.float32)))\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "CSdpIWpo_gzq",
        "outputId": "caac92b0-7124-4c36-e9ea-cffc9b7cdb10"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ first_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">FirstLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ second_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SecondLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ third_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ThirdLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ scaling_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ScalingLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DiagonalLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ first_layer (\u001b[38;5;33mFirstLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ second_layer (\u001b[38;5;33mSecondLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ third_layer (\u001b[38;5;33mThirdLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │              \u001b[38;5;34m48\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ scaling_layer (\u001b[38;5;33mScalingLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │              \u001b[38;5;34m65\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDiagonalLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">481</span> (1.88 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m481\u001b[0m (1.88 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">417</span> (1.63 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m417\u001b[0m (1.63 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tensorflow.keras.layers import InputLayer, LeakyReLU, Activation\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "initial_log_scale = np.log(z0 / w0)\n",
        "initial_scale = (z0 / w0)\n",
        "\n",
        "input_shape = (n_padded,)\n",
        "model = Sequential([\n",
        "    InputLayer(shape=input_shape),\n",
        "    FirstLayer(units=n_padded, trainable=True, name=\"first_layer\"),\n",
        "    # LeakyReLU(negative_slope=0.1),\n",
        "    SecondLayer(units=n_padded, trainable=True, name=\"second_layer\"),\n",
        "    # LeakyReLU(negative_slope=0.1),\n",
        "    ThirdLayer(units=n_padded, trainable=True, name=\"third_layer\"),\n",
        "    LeakyReLU(negative_slope=0.1),\n",
        "    ScalingLayer(units=n_padded, initial_scale=initial_log_scale, kernel_initializer='ones', bias_initializer='zeros', name=\"scaling_layer\"),\n",
        "    LeakyReLU(negative_slope=0.1),\n",
        "    DiagonalLayer(units=n_padded, trainable=False, kernel_initializer='ones', bias_initializer='zeros', name=\"output_layer\"),\n",
        "    Activation('linear')\n",
        "])\n",
        "\n",
        "# notes:\n",
        "# 1. adding the diagonal layers in the middle worsens results\n",
        "# 2. residual connections does not work\n",
        "# 3. removing bias in hidden layers worsens performance\n",
        "# 4. removing \"LeakyReLU\" activation in between layers improved performance\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss=custom_mse,\n",
        "    metrics=[custom_mse, custom_accuracy_without_padding]\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyCrYB69D1dF"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_4ibK4NcIlO",
        "outputId": "d572a74d-3dfd-4e74-9edb-081805e908ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 168ms/step - custom_accuracy_without_padding: 0.1415 - custom_mse: 0.2881 - loss: 0.2913 - val_custom_accuracy_without_padding: 0.1480 - val_custom_mse: 0.2402 - val_loss: 0.2443 - learning_rate: 0.0010\n",
            "Epoch 2/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.1401 - custom_mse: 0.2396 - loss: 0.2427 - val_custom_accuracy_without_padding: 0.1496 - val_custom_mse: 0.2068 - val_loss: 0.2110 - learning_rate: 0.0010\n",
            "Epoch 3/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.1393 - custom_mse: 0.2071 - loss: 0.2103 - val_custom_accuracy_without_padding: 0.1533 - val_custom_mse: 0.1821 - val_loss: 0.1864 - learning_rate: 0.0010\n",
            "Epoch 4/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.1504 - custom_mse: 0.1854 - loss: 0.1886 - val_custom_accuracy_without_padding: 0.1493 - val_custom_mse: 0.1605 - val_loss: 0.1645 - learning_rate: 0.0010\n",
            "Epoch 5/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.1422 - custom_mse: 0.1606 - loss: 0.1640 - val_custom_accuracy_without_padding: 0.1505 - val_custom_mse: 0.1323 - val_loss: 0.1361 - learning_rate: 0.0010\n",
            "Epoch 6/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.1502 - custom_mse: 0.1244 - loss: 0.1279 - val_custom_accuracy_without_padding: 0.1982 - val_custom_mse: 0.0856 - val_loss: 0.0890 - learning_rate: 0.0010\n",
            "Epoch 7/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.1942 - custom_mse: 0.0796 - loss: 0.0832 - val_custom_accuracy_without_padding: 0.1923 - val_custom_mse: 0.0692 - val_loss: 0.0728 - learning_rate: 0.0010\n",
            "Epoch 8/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.2021 - custom_mse: 0.0692 - loss: 0.0728 - val_custom_accuracy_without_padding: 0.1925 - val_custom_mse: 0.0659 - val_loss: 0.0695 - learning_rate: 0.0010\n",
            "Epoch 9/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.2119 - custom_mse: 0.0654 - loss: 0.0690 - val_custom_accuracy_without_padding: 0.2131 - val_custom_mse: 0.0645 - val_loss: 0.0681 - learning_rate: 0.0010\n",
            "Epoch 10/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.2377 - custom_mse: 0.0638 - loss: 0.0675 - val_custom_accuracy_without_padding: 0.2338 - val_custom_mse: 0.0633 - val_loss: 0.0669 - learning_rate: 0.0010\n",
            "Epoch 11/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.2498 - custom_mse: 0.0630 - loss: 0.0667 - val_custom_accuracy_without_padding: 0.2479 - val_custom_mse: 0.0624 - val_loss: 0.0660 - learning_rate: 0.0010\n",
            "Epoch 12/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.2604 - custom_mse: 0.0622 - loss: 0.0659 - val_custom_accuracy_without_padding: 0.2604 - val_custom_mse: 0.0615 - val_loss: 0.0651 - learning_rate: 0.0010\n",
            "Epoch 13/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.2707 - custom_mse: 0.0613 - loss: 0.0649 - val_custom_accuracy_without_padding: 0.2727 - val_custom_mse: 0.0610 - val_loss: 0.0645 - learning_rate: 0.0010\n",
            "Epoch 14/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.2824 - custom_mse: 0.0607 - loss: 0.0644 - val_custom_accuracy_without_padding: 0.2822 - val_custom_mse: 0.0600 - val_loss: 0.0635 - learning_rate: 0.0010\n",
            "Epoch 15/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.2896 - custom_mse: 0.0601 - loss: 0.0637 - val_custom_accuracy_without_padding: 0.2910 - val_custom_mse: 0.0593 - val_loss: 0.0628 - learning_rate: 0.0010\n",
            "Epoch 16/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.2942 - custom_mse: 0.0587 - loss: 0.0624 - val_custom_accuracy_without_padding: 0.2922 - val_custom_mse: 0.0586 - val_loss: 0.0621 - learning_rate: 0.0010\n",
            "Epoch 17/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.2995 - custom_mse: 0.0579 - loss: 0.0615 - val_custom_accuracy_without_padding: 0.3039 - val_custom_mse: 0.0581 - val_loss: 0.0616 - learning_rate: 0.0010\n",
            "Epoch 18/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.3063 - custom_mse: 0.0573 - loss: 0.0609 - val_custom_accuracy_without_padding: 0.3079 - val_custom_mse: 0.0575 - val_loss: 0.0609 - learning_rate: 0.0010\n",
            "Epoch 19/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.3091 - custom_mse: 0.0569 - loss: 0.0606 - val_custom_accuracy_without_padding: 0.3130 - val_custom_mse: 0.0569 - val_loss: 0.0603 - learning_rate: 0.0010\n",
            "Epoch 20/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.3157 - custom_mse: 0.0567 - loss: 0.0604 - val_custom_accuracy_without_padding: 0.3175 - val_custom_mse: 0.0563 - val_loss: 0.0598 - learning_rate: 0.0010\n",
            "Epoch 21/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.3195 - custom_mse: 0.0563 - loss: 0.0599 - val_custom_accuracy_without_padding: 0.3181 - val_custom_mse: 0.0558 - val_loss: 0.0592 - learning_rate: 0.0010\n",
            "Epoch 22/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.3207 - custom_mse: 0.0558 - loss: 0.0594 - val_custom_accuracy_without_padding: 0.3269 - val_custom_mse: 0.0553 - val_loss: 0.0588 - learning_rate: 0.0010\n",
            "Epoch 23/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.3281 - custom_mse: 0.0544 - loss: 0.0580 - val_custom_accuracy_without_padding: 0.3289 - val_custom_mse: 0.0547 - val_loss: 0.0581 - learning_rate: 0.0010\n",
            "Epoch 24/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.3355 - custom_mse: 0.0534 - loss: 0.0570 - val_custom_accuracy_without_padding: 0.3342 - val_custom_mse: 0.0543 - val_loss: 0.0576 - learning_rate: 0.0010\n",
            "Epoch 25/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.3415 - custom_mse: 0.0539 - loss: 0.0575 - val_custom_accuracy_without_padding: 0.3418 - val_custom_mse: 0.0539 - val_loss: 0.0573 - learning_rate: 0.0010\n",
            "Epoch 26/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.3493 - custom_mse: 0.0532 - loss: 0.0568 - val_custom_accuracy_without_padding: 0.3433 - val_custom_mse: 0.0533 - val_loss: 0.0567 - learning_rate: 0.0010\n",
            "Epoch 27/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.3520 - custom_mse: 0.0524 - loss: 0.0560 - val_custom_accuracy_without_padding: 0.3519 - val_custom_mse: 0.0527 - val_loss: 0.0561 - learning_rate: 0.0010\n",
            "Epoch 28/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.3583 - custom_mse: 0.0517 - loss: 0.0553 - val_custom_accuracy_without_padding: 0.3520 - val_custom_mse: 0.0525 - val_loss: 0.0559 - learning_rate: 0.0010\n",
            "Epoch 29/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.3677 - custom_mse: 0.0512 - loss: 0.0547 - val_custom_accuracy_without_padding: 0.3662 - val_custom_mse: 0.0519 - val_loss: 0.0553 - learning_rate: 0.0010\n",
            "Epoch 30/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.3808 - custom_mse: 0.0508 - loss: 0.0543 - val_custom_accuracy_without_padding: 0.3767 - val_custom_mse: 0.0513 - val_loss: 0.0546 - learning_rate: 0.0010\n",
            "Epoch 31/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.3899 - custom_mse: 0.0504 - loss: 0.0540 - val_custom_accuracy_without_padding: 0.3857 - val_custom_mse: 0.0510 - val_loss: 0.0543 - learning_rate: 0.0010\n",
            "Epoch 32/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.3906 - custom_mse: 0.0504 - loss: 0.0539 - val_custom_accuracy_without_padding: 0.3854 - val_custom_mse: 0.0504 - val_loss: 0.0537 - learning_rate: 0.0010\n",
            "Epoch 33/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.3961 - custom_mse: 0.0500 - loss: 0.0535 - val_custom_accuracy_without_padding: 0.3948 - val_custom_mse: 0.0503 - val_loss: 0.0536 - learning_rate: 0.0010\n",
            "Epoch 34/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.4030 - custom_mse: 0.0489 - loss: 0.0525 - val_custom_accuracy_without_padding: 0.4006 - val_custom_mse: 0.0497 - val_loss: 0.0530 - learning_rate: 0.0010\n",
            "Epoch 35/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.4024 - custom_mse: 0.0492 - loss: 0.0527 - val_custom_accuracy_without_padding: 0.4074 - val_custom_mse: 0.0493 - val_loss: 0.0526 - learning_rate: 0.0010\n",
            "Epoch 36/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.4148 - custom_mse: 0.0483 - loss: 0.0518 - val_custom_accuracy_without_padding: 0.4200 - val_custom_mse: 0.0490 - val_loss: 0.0522 - learning_rate: 0.0010\n",
            "Epoch 37/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.4312 - custom_mse: 0.0481 - loss: 0.0516 - val_custom_accuracy_without_padding: 0.4299 - val_custom_mse: 0.0485 - val_loss: 0.0517 - learning_rate: 0.0010\n",
            "Epoch 38/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.4374 - custom_mse: 0.0481 - loss: 0.0516 - val_custom_accuracy_without_padding: 0.4272 - val_custom_mse: 0.0485 - val_loss: 0.0516 - learning_rate: 0.0010\n",
            "Epoch 39/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.4474 - custom_mse: 0.0473 - loss: 0.0508 - val_custom_accuracy_without_padding: 0.4415 - val_custom_mse: 0.0478 - val_loss: 0.0510 - learning_rate: 0.0010\n",
            "Epoch 40/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.4562 - custom_mse: 0.0469 - loss: 0.0504 - val_custom_accuracy_without_padding: 0.4463 - val_custom_mse: 0.0475 - val_loss: 0.0507 - learning_rate: 0.0010\n",
            "Epoch 41/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.4642 - custom_mse: 0.0469 - loss: 0.0504 - val_custom_accuracy_without_padding: 0.4554 - val_custom_mse: 0.0473 - val_loss: 0.0504 - learning_rate: 0.0010\n",
            "Epoch 42/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.4734 - custom_mse: 0.0466 - loss: 0.0501 - val_custom_accuracy_without_padding: 0.4592 - val_custom_mse: 0.0473 - val_loss: 0.0505 - learning_rate: 0.0010\n",
            "Epoch 43/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.4764 - custom_mse: 0.0459 - loss: 0.0493 - val_custom_accuracy_without_padding: 0.4663 - val_custom_mse: 0.0466 - val_loss: 0.0496 - learning_rate: 0.0010\n",
            "Epoch 44/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.4869 - custom_mse: 0.0462 - loss: 0.0496 - val_custom_accuracy_without_padding: 0.4782 - val_custom_mse: 0.0460 - val_loss: 0.0491 - learning_rate: 0.0010\n",
            "Epoch 45/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.4980 - custom_mse: 0.0454 - loss: 0.0488 - val_custom_accuracy_without_padding: 0.4926 - val_custom_mse: 0.0459 - val_loss: 0.0489 - learning_rate: 0.0010\n",
            "Epoch 46/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.5054 - custom_mse: 0.0453 - loss: 0.0486 - val_custom_accuracy_without_padding: 0.4932 - val_custom_mse: 0.0457 - val_loss: 0.0488 - learning_rate: 0.0010\n",
            "Epoch 47/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.5088 - custom_mse: 0.0447 - loss: 0.0481 - val_custom_accuracy_without_padding: 0.4992 - val_custom_mse: 0.0452 - val_loss: 0.0482 - learning_rate: 0.0010\n",
            "Epoch 48/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.5127 - custom_mse: 0.0446 - loss: 0.0479 - val_custom_accuracy_without_padding: 0.5094 - val_custom_mse: 0.0450 - val_loss: 0.0480 - learning_rate: 0.0010\n",
            "Epoch 49/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.5195 - custom_mse: 0.0444 - loss: 0.0476 - val_custom_accuracy_without_padding: 0.5073 - val_custom_mse: 0.0448 - val_loss: 0.0477 - learning_rate: 0.0010\n",
            "Epoch 50/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.5247 - custom_mse: 0.0439 - loss: 0.0472 - val_custom_accuracy_without_padding: 0.5165 - val_custom_mse: 0.0445 - val_loss: 0.0475 - learning_rate: 0.0010\n",
            "Epoch 51/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.5292 - custom_mse: 0.0442 - loss: 0.0475 - val_custom_accuracy_without_padding: 0.5187 - val_custom_mse: 0.0440 - val_loss: 0.0469 - learning_rate: 0.0010\n",
            "Epoch 52/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.5338 - custom_mse: 0.0433 - loss: 0.0465 - val_custom_accuracy_without_padding: 0.5230 - val_custom_mse: 0.0438 - val_loss: 0.0467 - learning_rate: 0.0010\n",
            "Epoch 53/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.5340 - custom_mse: 0.0434 - loss: 0.0466 - val_custom_accuracy_without_padding: 0.5271 - val_custom_mse: 0.0434 - val_loss: 0.0464 - learning_rate: 0.0010\n",
            "Epoch 54/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.5406 - custom_mse: 0.0430 - loss: 0.0462 - val_custom_accuracy_without_padding: 0.5362 - val_custom_mse: 0.0434 - val_loss: 0.0463 - learning_rate: 0.0010\n",
            "Epoch 55/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.5396 - custom_mse: 0.0430 - loss: 0.0461 - val_custom_accuracy_without_padding: 0.5347 - val_custom_mse: 0.0431 - val_loss: 0.0460 - learning_rate: 0.0010\n",
            "Epoch 56/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.5461 - custom_mse: 0.0426 - loss: 0.0457 - val_custom_accuracy_without_padding: 0.5384 - val_custom_mse: 0.0428 - val_loss: 0.0456 - learning_rate: 0.0010\n",
            "Epoch 57/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.5470 - custom_mse: 0.0425 - loss: 0.0456 - val_custom_accuracy_without_padding: 0.5461 - val_custom_mse: 0.0428 - val_loss: 0.0456 - learning_rate: 0.0010\n",
            "Epoch 58/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.5518 - custom_mse: 0.0421 - loss: 0.0452 - val_custom_accuracy_without_padding: 0.5458 - val_custom_mse: 0.0425 - val_loss: 0.0453 - learning_rate: 0.0010\n",
            "Epoch 59/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.5565 - custom_mse: 0.0418 - loss: 0.0449 - val_custom_accuracy_without_padding: 0.5546 - val_custom_mse: 0.0423 - val_loss: 0.0451 - learning_rate: 0.0010\n",
            "Epoch 60/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.5562 - custom_mse: 0.0416 - loss: 0.0446 - val_custom_accuracy_without_padding: 0.5559 - val_custom_mse: 0.0418 - val_loss: 0.0447 - learning_rate: 0.0010\n",
            "Epoch 61/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.5606 - custom_mse: 0.0412 - loss: 0.0442 - val_custom_accuracy_without_padding: 0.5527 - val_custom_mse: 0.0422 - val_loss: 0.0449 - learning_rate: 0.0010\n",
            "Epoch 62/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.5633 - custom_mse: 0.0420 - loss: 0.0449 - val_custom_accuracy_without_padding: 0.5613 - val_custom_mse: 0.0415 - val_loss: 0.0443 - learning_rate: 0.0010\n",
            "Epoch 63/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.5683 - custom_mse: 0.0411 - loss: 0.0440 - val_custom_accuracy_without_padding: 0.5646 - val_custom_mse: 0.0416 - val_loss: 0.0442 - learning_rate: 0.0010\n",
            "Epoch 64/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.5733 - custom_mse: 0.0408 - loss: 0.0437 - val_custom_accuracy_without_padding: 0.5671 - val_custom_mse: 0.0413 - val_loss: 0.0440 - learning_rate: 0.0010\n",
            "Epoch 65/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.5738 - custom_mse: 0.0406 - loss: 0.0435 - val_custom_accuracy_without_padding: 0.5694 - val_custom_mse: 0.0410 - val_loss: 0.0437 - learning_rate: 0.0010\n",
            "Epoch 66/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.5778 - custom_mse: 0.0402 - loss: 0.0431 - val_custom_accuracy_without_padding: 0.5734 - val_custom_mse: 0.0408 - val_loss: 0.0435 - learning_rate: 0.0010\n",
            "Epoch 67/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.5824 - custom_mse: 0.0407 - loss: 0.0436 - val_custom_accuracy_without_padding: 0.5795 - val_custom_mse: 0.0406 - val_loss: 0.0432 - learning_rate: 0.0010\n",
            "Epoch 68/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.5853 - custom_mse: 0.0402 - loss: 0.0430 - val_custom_accuracy_without_padding: 0.5799 - val_custom_mse: 0.0404 - val_loss: 0.0430 - learning_rate: 0.0010\n",
            "Epoch 69/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.5847 - custom_mse: 0.0400 - loss: 0.0428 - val_custom_accuracy_without_padding: 0.5833 - val_custom_mse: 0.0405 - val_loss: 0.0431 - learning_rate: 0.0010\n",
            "Epoch 70/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.5864 - custom_mse: 0.0395 - loss: 0.0422 - val_custom_accuracy_without_padding: 0.5876 - val_custom_mse: 0.0406 - val_loss: 0.0431 - learning_rate: 0.0010\n",
            "Epoch 71/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.5924 - custom_mse: 0.0398 - loss: 0.0426 - val_custom_accuracy_without_padding: 0.5901 - val_custom_mse: 0.0404 - val_loss: 0.0428 - learning_rate: 0.0010\n",
            "Epoch 72/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.5882 - custom_mse: 0.0403 - loss: 0.0430 - val_custom_accuracy_without_padding: 0.5916 - val_custom_mse: 0.0400 - val_loss: 0.0425 - learning_rate: 0.0010\n",
            "Epoch 73/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.5945 - custom_mse: 0.0393 - loss: 0.0420 - val_custom_accuracy_without_padding: 0.5891 - val_custom_mse: 0.0399 - val_loss: 0.0424 - learning_rate: 0.0010\n",
            "Epoch 74/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.5937 - custom_mse: 0.0397 - loss: 0.0423 - val_custom_accuracy_without_padding: 0.5918 - val_custom_mse: 0.0395 - val_loss: 0.0420 - learning_rate: 0.0010\n",
            "Epoch 75/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.5933 - custom_mse: 0.0393 - loss: 0.0419 - val_custom_accuracy_without_padding: 0.5938 - val_custom_mse: 0.0395 - val_loss: 0.0419 - learning_rate: 0.0010\n",
            "Epoch 76/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.5986 - custom_mse: 0.0390 - loss: 0.0416 - val_custom_accuracy_without_padding: 0.5906 - val_custom_mse: 0.0394 - val_loss: 0.0418 - learning_rate: 0.0010\n",
            "Epoch 77/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.5972 - custom_mse: 0.0391 - loss: 0.0417 - val_custom_accuracy_without_padding: 0.5933 - val_custom_mse: 0.0391 - val_loss: 0.0416 - learning_rate: 0.0010\n",
            "Epoch 78/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.5980 - custom_mse: 0.0386 - loss: 0.0411 - val_custom_accuracy_without_padding: 0.5947 - val_custom_mse: 0.0393 - val_loss: 0.0417 - learning_rate: 0.0010\n",
            "Epoch 79/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.5971 - custom_mse: 0.0389 - loss: 0.0414 - val_custom_accuracy_without_padding: 0.5947 - val_custom_mse: 0.0388 - val_loss: 0.0411 - learning_rate: 0.0010\n",
            "Epoch 80/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.5973 - custom_mse: 0.0384 - loss: 0.0409 - val_custom_accuracy_without_padding: 0.5962 - val_custom_mse: 0.0388 - val_loss: 0.0411 - learning_rate: 0.0010\n",
            "Epoch 81/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.5963 - custom_mse: 0.0387 - loss: 0.0411 - val_custom_accuracy_without_padding: 0.5982 - val_custom_mse: 0.0390 - val_loss: 0.0412 - learning_rate: 0.0010\n",
            "Epoch 82/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.6011 - custom_mse: 0.0382 - loss: 0.0406 - val_custom_accuracy_without_padding: 0.5976 - val_custom_mse: 0.0383 - val_loss: 0.0406 - learning_rate: 0.0010\n",
            "Epoch 83/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6007 - custom_mse: 0.0383 - loss: 0.0408 - val_custom_accuracy_without_padding: 0.5999 - val_custom_mse: 0.0387 - val_loss: 0.0410 - learning_rate: 0.0010\n",
            "Epoch 84/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6028 - custom_mse: 0.0384 - loss: 0.0408 - val_custom_accuracy_without_padding: 0.6007 - val_custom_mse: 0.0382 - val_loss: 0.0405 - learning_rate: 0.0010\n",
            "Epoch 85/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6019 - custom_mse: 0.0382 - loss: 0.0406 - val_custom_accuracy_without_padding: 0.6022 - val_custom_mse: 0.0379 - val_loss: 0.0401 - learning_rate: 0.0010\n",
            "Epoch 86/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6034 - custom_mse: 0.0375 - loss: 0.0399 - val_custom_accuracy_without_padding: 0.6062 - val_custom_mse: 0.0381 - val_loss: 0.0403 - learning_rate: 0.0010\n",
            "Epoch 87/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6072 - custom_mse: 0.0380 - loss: 0.0404 - val_custom_accuracy_without_padding: 0.6100 - val_custom_mse: 0.0380 - val_loss: 0.0401 - learning_rate: 0.0010\n",
            "Epoch 88/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6092 - custom_mse: 0.0373 - loss: 0.0396 - val_custom_accuracy_without_padding: 0.6090 - val_custom_mse: 0.0376 - val_loss: 0.0398 - learning_rate: 0.0010\n",
            "Epoch 89/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.6094 - custom_mse: 0.0378 - loss: 0.0401 - val_custom_accuracy_without_padding: 0.6118 - val_custom_mse: 0.0376 - val_loss: 0.0398 - learning_rate: 0.0010\n",
            "Epoch 90/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6141 - custom_mse: 0.0369 - loss: 0.0392 - val_custom_accuracy_without_padding: 0.6143 - val_custom_mse: 0.0373 - val_loss: 0.0395 - learning_rate: 0.0010\n",
            "Epoch 91/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6165 - custom_mse: 0.0370 - loss: 0.0393 - val_custom_accuracy_without_padding: 0.6138 - val_custom_mse: 0.0375 - val_loss: 0.0395 - learning_rate: 0.0010\n",
            "Epoch 92/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.6145 - custom_mse: 0.0373 - loss: 0.0396 - val_custom_accuracy_without_padding: 0.6182 - val_custom_mse: 0.0371 - val_loss: 0.0392 - learning_rate: 0.0010\n",
            "Epoch 93/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.6196 - custom_mse: 0.0367 - loss: 0.0389 - val_custom_accuracy_without_padding: 0.6194 - val_custom_mse: 0.0369 - val_loss: 0.0389 - learning_rate: 0.0010\n",
            "Epoch 94/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.6205 - custom_mse: 0.0363 - loss: 0.0385 - val_custom_accuracy_without_padding: 0.6248 - val_custom_mse: 0.0374 - val_loss: 0.0394 - learning_rate: 0.0010\n",
            "Epoch 95/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.6251 - custom_mse: 0.0363 - loss: 0.0385 - val_custom_accuracy_without_padding: 0.6199 - val_custom_mse: 0.0367 - val_loss: 0.0388 - learning_rate: 0.0010\n",
            "Epoch 96/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.6225 - custom_mse: 0.0365 - loss: 0.0387 - val_custom_accuracy_without_padding: 0.6258 - val_custom_mse: 0.0365 - val_loss: 0.0385 - learning_rate: 0.0010\n",
            "Epoch 97/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6269 - custom_mse: 0.0365 - loss: 0.0387 - val_custom_accuracy_without_padding: 0.6257 - val_custom_mse: 0.0366 - val_loss: 0.0386 - learning_rate: 0.0010\n",
            "Epoch 98/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6252 - custom_mse: 0.0369 - loss: 0.0390 - val_custom_accuracy_without_padding: 0.6276 - val_custom_mse: 0.0366 - val_loss: 0.0386 - learning_rate: 0.0010\n",
            "Epoch 99/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6282 - custom_mse: 0.0367 - loss: 0.0388 - val_custom_accuracy_without_padding: 0.6271 - val_custom_mse: 0.0362 - val_loss: 0.0381 - learning_rate: 0.0010\n",
            "Epoch 100/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6312 - custom_mse: 0.0356 - loss: 0.0377 - val_custom_accuracy_without_padding: 0.6288 - val_custom_mse: 0.0363 - val_loss: 0.0383 - learning_rate: 0.0010\n",
            "Epoch 101/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6299 - custom_mse: 0.0362 - loss: 0.0382 - val_custom_accuracy_without_padding: 0.6310 - val_custom_mse: 0.0362 - val_loss: 0.0382 - learning_rate: 0.0010\n",
            "Epoch 102/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.6321 - custom_mse: 0.0353 - loss: 0.0373 - val_custom_accuracy_without_padding: 0.6319 - val_custom_mse: 0.0362 - val_loss: 0.0380 - learning_rate: 0.0010\n",
            "Epoch 103/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6352 - custom_mse: 0.0360 - loss: 0.0380 - val_custom_accuracy_without_padding: 0.6372 - val_custom_mse: 0.0364 - val_loss: 0.0382 - learning_rate: 0.0010\n",
            "Epoch 104/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6340 - custom_mse: 0.0361 - loss: 0.0381 - val_custom_accuracy_without_padding: 0.6364 - val_custom_mse: 0.0360 - val_loss: 0.0378 - learning_rate: 0.0010\n",
            "Epoch 105/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6392 - custom_mse: 0.0352 - loss: 0.0372 - val_custom_accuracy_without_padding: 0.6295 - val_custom_mse: 0.0361 - val_loss: 0.0379 - learning_rate: 0.0010\n",
            "Epoch 106/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6380 - custom_mse: 0.0353 - loss: 0.0373 - val_custom_accuracy_without_padding: 0.6414 - val_custom_mse: 0.0360 - val_loss: 0.0378 - learning_rate: 0.0010\n",
            "Epoch 107/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6422 - custom_mse: 0.0356 - loss: 0.0376 - val_custom_accuracy_without_padding: 0.6424 - val_custom_mse: 0.0357 - val_loss: 0.0374 - learning_rate: 0.0010\n",
            "Epoch 108/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6416 - custom_mse: 0.0357 - loss: 0.0376 - val_custom_accuracy_without_padding: 0.6397 - val_custom_mse: 0.0356 - val_loss: 0.0375 - learning_rate: 0.0010\n",
            "Epoch 109/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6435 - custom_mse: 0.0353 - loss: 0.0372 - val_custom_accuracy_without_padding: 0.6412 - val_custom_mse: 0.0353 - val_loss: 0.0370 - learning_rate: 0.0010\n",
            "Epoch 110/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6424 - custom_mse: 0.0354 - loss: 0.0373 - val_custom_accuracy_without_padding: 0.6326 - val_custom_mse: 0.0356 - val_loss: 0.0374 - learning_rate: 0.0010\n",
            "Epoch 111/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.6415 - custom_mse: 0.0349 - loss: 0.0368 - val_custom_accuracy_without_padding: 0.6447 - val_custom_mse: 0.0352 - val_loss: 0.0369 - learning_rate: 0.0010\n",
            "Epoch 112/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6464 - custom_mse: 0.0355 - loss: 0.0374 - val_custom_accuracy_without_padding: 0.6427 - val_custom_mse: 0.0355 - val_loss: 0.0373 - learning_rate: 0.0010\n",
            "Epoch 113/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.6501 - custom_mse: 0.0351 - loss: 0.0369 - val_custom_accuracy_without_padding: 0.6452 - val_custom_mse: 0.0350 - val_loss: 0.0368 - learning_rate: 0.0010\n",
            "Epoch 114/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6491 - custom_mse: 0.0352 - loss: 0.0371 - val_custom_accuracy_without_padding: 0.6486 - val_custom_mse: 0.0349 - val_loss: 0.0366 - learning_rate: 0.0010\n",
            "Epoch 115/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6464 - custom_mse: 0.0352 - loss: 0.0370 - val_custom_accuracy_without_padding: 0.6477 - val_custom_mse: 0.0352 - val_loss: 0.0370 - learning_rate: 0.0010\n",
            "Epoch 116/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6458 - custom_mse: 0.0354 - loss: 0.0372 - val_custom_accuracy_without_padding: 0.6458 - val_custom_mse: 0.0351 - val_loss: 0.0368 - learning_rate: 0.0010\n",
            "Epoch 117/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6477 - custom_mse: 0.0350 - loss: 0.0368 - val_custom_accuracy_without_padding: 0.6491 - val_custom_mse: 0.0349 - val_loss: 0.0368 - learning_rate: 0.0010\n",
            "Epoch 118/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6503 - custom_mse: 0.0348 - loss: 0.0365 - val_custom_accuracy_without_padding: 0.6420 - val_custom_mse: 0.0345 - val_loss: 0.0362 - learning_rate: 0.0010\n",
            "Epoch 119/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6490 - custom_mse: 0.0347 - loss: 0.0365 - val_custom_accuracy_without_padding: 0.6447 - val_custom_mse: 0.0347 - val_loss: 0.0362 - learning_rate: 0.0010\n",
            "Epoch 120/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6496 - custom_mse: 0.0343 - loss: 0.0361 - val_custom_accuracy_without_padding: 0.6435 - val_custom_mse: 0.0346 - val_loss: 0.0364 - learning_rate: 0.0010\n",
            "Epoch 121/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.6488 - custom_mse: 0.0346 - loss: 0.0364 - val_custom_accuracy_without_padding: 0.6462 - val_custom_mse: 0.0344 - val_loss: 0.0359 - learning_rate: 0.0010\n",
            "Epoch 122/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6473 - custom_mse: 0.0342 - loss: 0.0359 - val_custom_accuracy_without_padding: 0.6490 - val_custom_mse: 0.0347 - val_loss: 0.0363 - learning_rate: 0.0010\n",
            "Epoch 123/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6527 - custom_mse: 0.0340 - loss: 0.0357 - val_custom_accuracy_without_padding: 0.6450 - val_custom_mse: 0.0344 - val_loss: 0.0360 - learning_rate: 0.0010\n",
            "Epoch 124/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.6446 - custom_mse: 0.0346 - loss: 0.0363 - val_custom_accuracy_without_padding: 0.6387 - val_custom_mse: 0.0342 - val_loss: 0.0358 - learning_rate: 0.0010\n",
            "Epoch 125/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6424 - custom_mse: 0.0338 - loss: 0.0354 - val_custom_accuracy_without_padding: 0.6486 - val_custom_mse: 0.0345 - val_loss: 0.0359 - learning_rate: 0.0010\n",
            "Epoch 126/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6449 - custom_mse: 0.0341 - loss: 0.0357 - val_custom_accuracy_without_padding: 0.6415 - val_custom_mse: 0.0343 - val_loss: 0.0358 - learning_rate: 0.0010\n",
            "Epoch 127/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6467 - custom_mse: 0.0343 - loss: 0.0360 - val_custom_accuracy_without_padding: 0.6391 - val_custom_mse: 0.0346 - val_loss: 0.0361 - learning_rate: 0.0010\n",
            "Epoch 128/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6430 - custom_mse: 0.0344 - loss: 0.0361 - val_custom_accuracy_without_padding: 0.6472 - val_custom_mse: 0.0342 - val_loss: 0.0357 - learning_rate: 0.0010\n",
            "Epoch 129/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.6504 - custom_mse: 0.0334 - loss: 0.0350 - val_custom_accuracy_without_padding: 0.6453 - val_custom_mse: 0.0338 - val_loss: 0.0353 - learning_rate: 0.0010\n",
            "Epoch 130/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6476 - custom_mse: 0.0344 - loss: 0.0360 - val_custom_accuracy_without_padding: 0.6453 - val_custom_mse: 0.0334 - val_loss: 0.0349 - learning_rate: 0.0010\n",
            "Epoch 131/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6448 - custom_mse: 0.0338 - loss: 0.0354 - val_custom_accuracy_without_padding: 0.6435 - val_custom_mse: 0.0344 - val_loss: 0.0358 - learning_rate: 0.0010\n",
            "Epoch 132/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6476 - custom_mse: 0.0344 - loss: 0.0360 - val_custom_accuracy_without_padding: 0.6404 - val_custom_mse: 0.0341 - val_loss: 0.0356 - learning_rate: 0.0010\n",
            "Epoch 133/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.6466 - custom_mse: 0.0336 - loss: 0.0352 - val_custom_accuracy_without_padding: 0.6458 - val_custom_mse: 0.0334 - val_loss: 0.0348 - learning_rate: 0.0010\n",
            "Epoch 134/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.6404 - custom_mse: 0.0337 - loss: 0.0353 - val_custom_accuracy_without_padding: 0.6438 - val_custom_mse: 0.0331 - val_loss: 0.0346 - learning_rate: 0.0010\n",
            "Epoch 135/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.6427 - custom_mse: 0.0333 - loss: 0.0349 - val_custom_accuracy_without_padding: 0.6438 - val_custom_mse: 0.0335 - val_loss: 0.0349 - learning_rate: 0.0010\n",
            "Epoch 136/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.6445 - custom_mse: 0.0332 - loss: 0.0347 - val_custom_accuracy_without_padding: 0.6460 - val_custom_mse: 0.0328 - val_loss: 0.0342 - learning_rate: 0.0010\n",
            "Epoch 137/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.6474 - custom_mse: 0.0325 - loss: 0.0340 - val_custom_accuracy_without_padding: 0.6419 - val_custom_mse: 0.0330 - val_loss: 0.0345 - learning_rate: 0.0010\n",
            "Epoch 138/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.6435 - custom_mse: 0.0328 - loss: 0.0343 - val_custom_accuracy_without_padding: 0.6452 - val_custom_mse: 0.0326 - val_loss: 0.0341 - learning_rate: 0.0010\n",
            "Epoch 139/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6413 - custom_mse: 0.0334 - loss: 0.0349 - val_custom_accuracy_without_padding: 0.6417 - val_custom_mse: 0.0324 - val_loss: 0.0338 - learning_rate: 0.0010\n",
            "Epoch 140/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6414 - custom_mse: 0.0321 - loss: 0.0336 - val_custom_accuracy_without_padding: 0.6412 - val_custom_mse: 0.0324 - val_loss: 0.0339 - learning_rate: 0.0010\n",
            "Epoch 141/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.6465 - custom_mse: 0.0328 - loss: 0.0343 - val_custom_accuracy_without_padding: 0.6396 - val_custom_mse: 0.0325 - val_loss: 0.0338 - learning_rate: 0.0010\n",
            "Epoch 142/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6448 - custom_mse: 0.0325 - loss: 0.0340 - val_custom_accuracy_without_padding: 0.6452 - val_custom_mse: 0.0321 - val_loss: 0.0334 - learning_rate: 0.0010\n",
            "Epoch 143/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.6491 - custom_mse: 0.0316 - loss: 0.0331 - val_custom_accuracy_without_padding: 0.6354 - val_custom_mse: 0.0319 - val_loss: 0.0334 - learning_rate: 0.0010\n",
            "Epoch 144/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6433 - custom_mse: 0.0322 - loss: 0.0337 - val_custom_accuracy_without_padding: 0.6402 - val_custom_mse: 0.0319 - val_loss: 0.0335 - learning_rate: 0.0010\n",
            "Epoch 145/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6387 - custom_mse: 0.0320 - loss: 0.0335 - val_custom_accuracy_without_padding: 0.6308 - val_custom_mse: 0.0316 - val_loss: 0.0330 - learning_rate: 0.0010\n",
            "Epoch 146/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6471 - custom_mse: 0.0322 - loss: 0.0336 - val_custom_accuracy_without_padding: 0.6445 - val_custom_mse: 0.0327 - val_loss: 0.0343 - learning_rate: 0.0010\n",
            "Epoch 147/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.6457 - custom_mse: 0.0324 - loss: 0.0338 - val_custom_accuracy_without_padding: 0.6452 - val_custom_mse: 0.0314 - val_loss: 0.0329 - learning_rate: 0.0010\n",
            "Epoch 148/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.6487 - custom_mse: 0.0313 - loss: 0.0328 - val_custom_accuracy_without_padding: 0.6410 - val_custom_mse: 0.0315 - val_loss: 0.0328 - learning_rate: 0.0010\n",
            "Epoch 149/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.6491 - custom_mse: 0.0318 - loss: 0.0333 - val_custom_accuracy_without_padding: 0.6526 - val_custom_mse: 0.0308 - val_loss: 0.0322 - learning_rate: 0.0010\n",
            "Epoch 150/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6542 - custom_mse: 0.0311 - loss: 0.0325 - val_custom_accuracy_without_padding: 0.6458 - val_custom_mse: 0.0312 - val_loss: 0.0324 - learning_rate: 0.0010\n",
            "Epoch 151/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6463 - custom_mse: 0.0312 - loss: 0.0326 - val_custom_accuracy_without_padding: 0.6268 - val_custom_mse: 0.0312 - val_loss: 0.0326 - learning_rate: 0.0010\n",
            "Epoch 152/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6348 - custom_mse: 0.0316 - loss: 0.0330 - val_custom_accuracy_without_padding: 0.6625 - val_custom_mse: 0.0313 - val_loss: 0.0328 - learning_rate: 0.0010\n",
            "Epoch 153/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6545 - custom_mse: 0.0316 - loss: 0.0330 - val_custom_accuracy_without_padding: 0.6591 - val_custom_mse: 0.0299 - val_loss: 0.0313 - learning_rate: 0.0010\n",
            "Epoch 154/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6585 - custom_mse: 0.0308 - loss: 0.0322 - val_custom_accuracy_without_padding: 0.6581 - val_custom_mse: 0.0299 - val_loss: 0.0313 - learning_rate: 0.0010\n",
            "Epoch 155/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6573 - custom_mse: 0.0307 - loss: 0.0321 - val_custom_accuracy_without_padding: 0.6622 - val_custom_mse: 0.0299 - val_loss: 0.0313 - learning_rate: 0.0010\n",
            "Epoch 156/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6641 - custom_mse: 0.0305 - loss: 0.0319 - val_custom_accuracy_without_padding: 0.6610 - val_custom_mse: 0.0307 - val_loss: 0.0322 - learning_rate: 0.0010\n",
            "Epoch 157/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6618 - custom_mse: 0.0304 - loss: 0.0318 - val_custom_accuracy_without_padding: 0.6648 - val_custom_mse: 0.0296 - val_loss: 0.0310 - learning_rate: 0.0010\n",
            "Epoch 158/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6702 - custom_mse: 0.0298 - loss: 0.0312 - val_custom_accuracy_without_padding: 0.6713 - val_custom_mse: 0.0298 - val_loss: 0.0312 - learning_rate: 0.0010\n",
            "Epoch 159/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6704 - custom_mse: 0.0298 - loss: 0.0312 - val_custom_accuracy_without_padding: 0.6693 - val_custom_mse: 0.0294 - val_loss: 0.0308 - learning_rate: 0.0010\n",
            "Epoch 160/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6682 - custom_mse: 0.0298 - loss: 0.0311 - val_custom_accuracy_without_padding: 0.6554 - val_custom_mse: 0.0294 - val_loss: 0.0309 - learning_rate: 0.0010\n",
            "Epoch 161/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.6725 - custom_mse: 0.0300 - loss: 0.0314 - val_custom_accuracy_without_padding: 0.6754 - val_custom_mse: 0.0294 - val_loss: 0.0308 - learning_rate: 0.0010\n",
            "Epoch 162/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.6696 - custom_mse: 0.0300 - loss: 0.0314 - val_custom_accuracy_without_padding: 0.6693 - val_custom_mse: 0.0291 - val_loss: 0.0306 - learning_rate: 0.0010\n",
            "Epoch 163/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6777 - custom_mse: 0.0293 - loss: 0.0307 - val_custom_accuracy_without_padding: 0.6541 - val_custom_mse: 0.0306 - val_loss: 0.0323 - learning_rate: 0.0010\n",
            "Epoch 164/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6691 - custom_mse: 0.0301 - loss: 0.0315 - val_custom_accuracy_without_padding: 0.6786 - val_custom_mse: 0.0291 - val_loss: 0.0305 - learning_rate: 0.0010\n",
            "Epoch 165/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6726 - custom_mse: 0.0296 - loss: 0.0310 - val_custom_accuracy_without_padding: 0.6728 - val_custom_mse: 0.0287 - val_loss: 0.0302 - learning_rate: 0.0010\n",
            "Epoch 166/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6737 - custom_mse: 0.0297 - loss: 0.0311 - val_custom_accuracy_without_padding: 0.6749 - val_custom_mse: 0.0289 - val_loss: 0.0303 - learning_rate: 0.0010\n",
            "Epoch 167/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6805 - custom_mse: 0.0294 - loss: 0.0307 - val_custom_accuracy_without_padding: 0.6779 - val_custom_mse: 0.0289 - val_loss: 0.0302 - learning_rate: 0.0010\n",
            "Epoch 168/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6756 - custom_mse: 0.0296 - loss: 0.0310 - val_custom_accuracy_without_padding: 0.6647 - val_custom_mse: 0.0301 - val_loss: 0.0314 - learning_rate: 0.0010\n",
            "Epoch 169/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6696 - custom_mse: 0.0300 - loss: 0.0314 - val_custom_accuracy_without_padding: 0.6964 - val_custom_mse: 0.0287 - val_loss: 0.0302 - learning_rate: 0.0010\n",
            "Epoch 170/500\n",
            "\u001b[1m20/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.6882 - custom_mse: 0.0291 - loss: 0.0305\n",
            "Epoch 170: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.6876 - custom_mse: 0.0291 - loss: 0.0305 - val_custom_accuracy_without_padding: 0.6850 - val_custom_mse: 0.0287 - val_loss: 0.0301 - learning_rate: 0.0010\n",
            "Epoch 171/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.6956 - custom_mse: 0.0291 - loss: 0.0305 - val_custom_accuracy_without_padding: 0.6923 - val_custom_mse: 0.0289 - val_loss: 0.0302 - learning_rate: 5.0000e-04\n",
            "Epoch 172/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7006 - custom_mse: 0.0283 - loss: 0.0297 - val_custom_accuracy_without_padding: 0.7029 - val_custom_mse: 0.0278 - val_loss: 0.0293 - learning_rate: 5.0000e-04\n",
            "Epoch 173/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.6998 - custom_mse: 0.0283 - loss: 0.0297 - val_custom_accuracy_without_padding: 0.7002 - val_custom_mse: 0.0280 - val_loss: 0.0293 - learning_rate: 5.0000e-04\n",
            "Epoch 174/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.7048 - custom_mse: 0.0280 - loss: 0.0294 - val_custom_accuracy_without_padding: 0.7032 - val_custom_mse: 0.0280 - val_loss: 0.0293 - learning_rate: 5.0000e-04\n",
            "Epoch 175/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.7026 - custom_mse: 0.0283 - loss: 0.0297 - val_custom_accuracy_without_padding: 0.6978 - val_custom_mse: 0.0278 - val_loss: 0.0292 - learning_rate: 5.0000e-04\n",
            "Epoch 176/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.7072 - custom_mse: 0.0279 - loss: 0.0293 - val_custom_accuracy_without_padding: 0.7062 - val_custom_mse: 0.0280 - val_loss: 0.0294 - learning_rate: 5.0000e-04\n",
            "Epoch 177/500\n",
            "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - custom_accuracy_without_padding: 0.7027 - custom_mse: 0.0283 - loss: 0.0297\n",
            "Epoch 177: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - custom_accuracy_without_padding: 0.7028 - custom_mse: 0.0283 - loss: 0.0297 - val_custom_accuracy_without_padding: 0.6966 - val_custom_mse: 0.0277 - val_loss: 0.0292 - learning_rate: 5.0000e-04\n",
            "Epoch 178/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - custom_accuracy_without_padding: 0.7061 - custom_mse: 0.0280 - loss: 0.0294 - val_custom_accuracy_without_padding: 0.7093 - val_custom_mse: 0.0275 - val_loss: 0.0288 - learning_rate: 2.5000e-04\n",
            "Epoch 179/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.7087 - custom_mse: 0.0280 - loss: 0.0294 - val_custom_accuracy_without_padding: 0.7072 - val_custom_mse: 0.0275 - val_loss: 0.0288 - learning_rate: 2.5000e-04\n",
            "Epoch 180/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7083 - custom_mse: 0.0279 - loss: 0.0293 - val_custom_accuracy_without_padding: 0.7072 - val_custom_mse: 0.0275 - val_loss: 0.0289 - learning_rate: 2.5000e-04\n",
            "Epoch 181/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.7066 - custom_mse: 0.0280 - loss: 0.0294 - val_custom_accuracy_without_padding: 0.7060 - val_custom_mse: 0.0274 - val_loss: 0.0288 - learning_rate: 2.5000e-04\n",
            "Epoch 182/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7110 - custom_mse: 0.0276 - loss: 0.0289 - val_custom_accuracy_without_padding: 0.7034 - val_custom_mse: 0.0274 - val_loss: 0.0289 - learning_rate: 2.5000e-04\n",
            "Epoch 183/500\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.7070 - custom_mse: 0.0276 - loss: 0.0289\n",
            "Epoch 183: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7071 - custom_mse: 0.0276 - loss: 0.0289 - val_custom_accuracy_without_padding: 0.7085 - val_custom_mse: 0.0274 - val_loss: 0.0288 - learning_rate: 2.5000e-04\n",
            "Epoch 184/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7111 - custom_mse: 0.0279 - loss: 0.0293 - val_custom_accuracy_without_padding: 0.7108 - val_custom_mse: 0.0273 - val_loss: 0.0287 - learning_rate: 1.2500e-04\n",
            "Epoch 185/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7112 - custom_mse: 0.0272 - loss: 0.0286 - val_custom_accuracy_without_padding: 0.7090 - val_custom_mse: 0.0272 - val_loss: 0.0286 - learning_rate: 1.2500e-04\n",
            "Epoch 186/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.7128 - custom_mse: 0.0271 - loss: 0.0284 - val_custom_accuracy_without_padding: 0.7083 - val_custom_mse: 0.0272 - val_loss: 0.0286 - learning_rate: 1.2500e-04\n",
            "Epoch 187/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7126 - custom_mse: 0.0274 - loss: 0.0287 - val_custom_accuracy_without_padding: 0.7083 - val_custom_mse: 0.0273 - val_loss: 0.0287 - learning_rate: 1.2500e-04\n",
            "Epoch 188/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7112 - custom_mse: 0.0281 - loss: 0.0295 - val_custom_accuracy_without_padding: 0.7103 - val_custom_mse: 0.0272 - val_loss: 0.0286 - learning_rate: 1.2500e-04\n",
            "Epoch 189/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7127 - custom_mse: 0.0271 - loss: 0.0284 - val_custom_accuracy_without_padding: 0.7100 - val_custom_mse: 0.0272 - val_loss: 0.0286 - learning_rate: 1.2500e-04\n",
            "Epoch 190/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7123 - custom_mse: 0.0280 - loss: 0.0293 - val_custom_accuracy_without_padding: 0.7060 - val_custom_mse: 0.0271 - val_loss: 0.0286 - learning_rate: 1.2500e-04\n",
            "Epoch 191/500\n",
            "\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.7110 - custom_mse: 0.0276 - loss: 0.0290\n",
            "Epoch 191: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7110 - custom_mse: 0.0276 - loss: 0.0290 - val_custom_accuracy_without_padding: 0.7097 - val_custom_mse: 0.0271 - val_loss: 0.0285 - learning_rate: 1.2500e-04\n",
            "Epoch 192/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7133 - custom_mse: 0.0274 - loss: 0.0288 - val_custom_accuracy_without_padding: 0.7070 - val_custom_mse: 0.0271 - val_loss: 0.0286 - learning_rate: 6.2500e-05\n",
            "Epoch 193/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7126 - custom_mse: 0.0273 - loss: 0.0286 - val_custom_accuracy_without_padding: 0.7072 - val_custom_mse: 0.0271 - val_loss: 0.0285 - learning_rate: 6.2500e-05\n",
            "Epoch 194/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7097 - custom_mse: 0.0276 - loss: 0.0290 - val_custom_accuracy_without_padding: 0.7070 - val_custom_mse: 0.0271 - val_loss: 0.0285 - learning_rate: 6.2500e-05\n",
            "Epoch 195/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7132 - custom_mse: 0.0273 - loss: 0.0286 - val_custom_accuracy_without_padding: 0.7067 - val_custom_mse: 0.0271 - val_loss: 0.0285 - learning_rate: 6.2500e-05\n",
            "Epoch 196/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.7133 - custom_mse: 0.0273 - loss: 0.0287 - val_custom_accuracy_without_padding: 0.7073 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 6.2500e-05\n",
            "Epoch 197/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7106 - custom_mse: 0.0272 - loss: 0.0285 - val_custom_accuracy_without_padding: 0.7077 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 6.2500e-05\n",
            "Epoch 198/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7120 - custom_mse: 0.0267 - loss: 0.0280 - val_custom_accuracy_without_padding: 0.7092 - val_custom_mse: 0.0271 - val_loss: 0.0285 - learning_rate: 6.2500e-05\n",
            "Epoch 199/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7106 - custom_mse: 0.0275 - loss: 0.0289 - val_custom_accuracy_without_padding: 0.7068 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 6.2500e-05\n",
            "Epoch 200/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.7114 - custom_mse: 0.0270 - loss: 0.0283 - val_custom_accuracy_without_padding: 0.7085 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 6.2500e-05\n",
            "Epoch 201/500\n",
            "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.7150 - custom_mse: 0.0270 - loss: 0.0284\n",
            "Epoch 201: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.7146 - custom_mse: 0.0271 - loss: 0.0284 - val_custom_accuracy_without_padding: 0.7082 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 6.2500e-05\n",
            "Epoch 202/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7108 - custom_mse: 0.0274 - loss: 0.0288 - val_custom_accuracy_without_padding: 0.7078 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 3.1250e-05\n",
            "Epoch 203/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7099 - custom_mse: 0.0269 - loss: 0.0283 - val_custom_accuracy_without_padding: 0.7075 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 3.1250e-05\n",
            "Epoch 204/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.7127 - custom_mse: 0.0269 - loss: 0.0283 - val_custom_accuracy_without_padding: 0.7068 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 3.1250e-05\n",
            "Epoch 205/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7112 - custom_mse: 0.0277 - loss: 0.0290 - val_custom_accuracy_without_padding: 0.7067 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 3.1250e-05\n",
            "Epoch 206/500\n",
            "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.7109 - custom_mse: 0.0274 - loss: 0.0287\n",
            "Epoch 206: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7108 - custom_mse: 0.0274 - loss: 0.0287 - val_custom_accuracy_without_padding: 0.7062 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 3.1250e-05\n",
            "Epoch 207/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7103 - custom_mse: 0.0274 - loss: 0.0288 - val_custom_accuracy_without_padding: 0.7060 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 1.5625e-05\n",
            "Epoch 208/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7088 - custom_mse: 0.0268 - loss: 0.0282 - val_custom_accuracy_without_padding: 0.7075 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 1.5625e-05\n",
            "Epoch 209/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7113 - custom_mse: 0.0273 - loss: 0.0287 - val_custom_accuracy_without_padding: 0.7068 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 1.5625e-05\n",
            "Epoch 210/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.7091 - custom_mse: 0.0272 - loss: 0.0286 - val_custom_accuracy_without_padding: 0.7073 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 1.5625e-05\n",
            "Epoch 211/500\n",
            "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.7093 - custom_mse: 0.0275 - loss: 0.0288\n",
            "Epoch 211: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7095 - custom_mse: 0.0274 - loss: 0.0288 - val_custom_accuracy_without_padding: 0.7062 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 1.5625e-05\n",
            "Epoch 212/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7124 - custom_mse: 0.0273 - loss: 0.0287 - val_custom_accuracy_without_padding: 0.7075 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 7.8125e-06\n",
            "Epoch 213/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7120 - custom_mse: 0.0275 - loss: 0.0288 - val_custom_accuracy_without_padding: 0.7067 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 7.8125e-06\n",
            "Epoch 214/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7108 - custom_mse: 0.0268 - loss: 0.0282 - val_custom_accuracy_without_padding: 0.7067 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 7.8125e-06\n",
            "Epoch 215/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.7115 - custom_mse: 0.0271 - loss: 0.0285 - val_custom_accuracy_without_padding: 0.7077 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 7.8125e-06\n",
            "Epoch 216/500\n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7120 - custom_mse: 0.0270 - loss: 0.0284\n",
            "Epoch 216: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - custom_accuracy_without_padding: 0.7118 - custom_mse: 0.0270 - loss: 0.0284 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 7.8125e-06\n",
            "Epoch 217/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - custom_accuracy_without_padding: 0.7114 - custom_mse: 0.0271 - loss: 0.0285 - val_custom_accuracy_without_padding: 0.7063 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 3.9063e-06\n",
            "Epoch 218/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - custom_accuracy_without_padding: 0.7117 - custom_mse: 0.0270 - loss: 0.0284 - val_custom_accuracy_without_padding: 0.7067 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 3.9063e-06\n",
            "Epoch 219/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7103 - custom_mse: 0.0270 - loss: 0.0283 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 3.9063e-06\n",
            "Epoch 220/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7112 - custom_mse: 0.0274 - loss: 0.0288 - val_custom_accuracy_without_padding: 0.7063 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 3.9063e-06\n",
            "Epoch 221/500\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.7125 - custom_mse: 0.0275 - loss: 0.0288\n",
            "Epoch 221: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7123 - custom_mse: 0.0274 - loss: 0.0288 - val_custom_accuracy_without_padding: 0.7067 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 3.9063e-06\n",
            "Epoch 222/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7118 - custom_mse: 0.0271 - loss: 0.0284 - val_custom_accuracy_without_padding: 0.7068 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 1.9531e-06\n",
            "Epoch 223/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7099 - custom_mse: 0.0273 - loss: 0.0286 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 1.9531e-06\n",
            "Epoch 224/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7103 - custom_mse: 0.0273 - loss: 0.0286 - val_custom_accuracy_without_padding: 0.7068 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 1.9531e-06\n",
            "Epoch 225/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.7080 - custom_mse: 0.0275 - loss: 0.0288 - val_custom_accuracy_without_padding: 0.7067 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 1.9531e-06\n",
            "Epoch 226/500\n",
            "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.7087 - custom_mse: 0.0275 - loss: 0.0288\n",
            "Epoch 226: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7090 - custom_mse: 0.0274 - loss: 0.0288 - val_custom_accuracy_without_padding: 0.7067 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 1.9531e-06\n",
            "Epoch 227/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7101 - custom_mse: 0.0271 - loss: 0.0284 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 9.7656e-07\n",
            "Epoch 228/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7094 - custom_mse: 0.0276 - loss: 0.0290 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 9.7656e-07\n",
            "Epoch 229/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7117 - custom_mse: 0.0273 - loss: 0.0286 - val_custom_accuracy_without_padding: 0.7067 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 9.7656e-07\n",
            "Epoch 230/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - custom_accuracy_without_padding: 0.7096 - custom_mse: 0.0271 - loss: 0.0285 - val_custom_accuracy_without_padding: 0.7067 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 9.7656e-07\n",
            "Epoch 231/500\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.7120 - custom_mse: 0.0270 - loss: 0.0283\n",
            "Epoch 231: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7118 - custom_mse: 0.0270 - loss: 0.0283 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 9.7656e-07\n",
            "Epoch 232/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7097 - custom_mse: 0.0273 - loss: 0.0287 - val_custom_accuracy_without_padding: 0.7068 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 4.8828e-07\n",
            "Epoch 233/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7101 - custom_mse: 0.0272 - loss: 0.0285 - val_custom_accuracy_without_padding: 0.7063 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 4.8828e-07\n",
            "Epoch 234/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7119 - custom_mse: 0.0271 - loss: 0.0284 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 4.8828e-07\n",
            "Epoch 235/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7107 - custom_mse: 0.0269 - loss: 0.0282 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 4.8828e-07\n",
            "Epoch 236/500\n",
            "\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.7086 - custom_mse: 0.0270 - loss: 0.0284\n",
            "Epoch 236: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7089 - custom_mse: 0.0271 - loss: 0.0284 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 4.8828e-07\n",
            "Epoch 237/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7118 - custom_mse: 0.0272 - loss: 0.0286 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 2.4414e-07\n",
            "Epoch 238/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.7109 - custom_mse: 0.0269 - loss: 0.0282 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 2.4414e-07\n",
            "Epoch 239/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7101 - custom_mse: 0.0275 - loss: 0.0288 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 2.4414e-07\n",
            "Epoch 240/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7095 - custom_mse: 0.0270 - loss: 0.0283 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 2.4414e-07\n",
            "Epoch 241/500\n",
            "\u001b[1m23/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.7115 - custom_mse: 0.0272 - loss: 0.0285\n",
            "Epoch 241: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7114 - custom_mse: 0.0272 - loss: 0.0285 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 2.4414e-07\n",
            "Epoch 242/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - custom_accuracy_without_padding: 0.7107 - custom_mse: 0.0267 - loss: 0.0281 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 1.2207e-07\n",
            "Epoch 243/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7100 - custom_mse: 0.0272 - loss: 0.0285 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 1.2207e-07\n",
            "Epoch 244/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7117 - custom_mse: 0.0268 - loss: 0.0282 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 1.2207e-07\n",
            "Epoch 245/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - custom_accuracy_without_padding: 0.7095 - custom_mse: 0.0273 - loss: 0.0287 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 1.2207e-07\n",
            "Epoch 246/500\n",
            "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - custom_accuracy_without_padding: 0.7117 - custom_mse: 0.0270 - loss: 0.0284\n",
            "Epoch 246: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7115 - custom_mse: 0.0270 - loss: 0.0284 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 1.2207e-07\n",
            "Epoch 247/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7101 - custom_mse: 0.0272 - loss: 0.0286 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 1.0000e-07\n",
            "Epoch 248/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7124 - custom_mse: 0.0269 - loss: 0.0283 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 1.0000e-07\n",
            "Epoch 249/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7107 - custom_mse: 0.0272 - loss: 0.0285 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 1.0000e-07\n",
            "Epoch 250/500\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - custom_accuracy_without_padding: 0.7114 - custom_mse: 0.0270 - loss: 0.0284 - val_custom_accuracy_without_padding: 0.7065 - val_custom_mse: 0.0270 - val_loss: 0.0284 - learning_rate: 1.0000e-07\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "adjust_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=5,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=500,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[adjust_lr, early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98_GbV7sEJVR",
        "outputId": "29e74606-69a2-4d00-f946-80866d83611d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - custom_accuracy_without_padding: 0.7084 - custom_mse: 0.0265 - loss: 0.0278 \n",
            "Test results - Loss: 0.028354652225971222, MSE: 0.026951540261507034, Accuracy: 0.7065146565437317\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "eval_results = model.evaluate(X_test, y_test)\n",
        "print(f\"Test results - Loss: {eval_results[0]}, MSE: {eval_results[1]}, Accuracy: {eval_results[2]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "Dj_btsBkEPeB",
        "outputId": "6690e707-54e7-42cd-8573-fc59e84cfa9a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['custom_accuracy_without_padding'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_custom_accuracy_without_padding'], label='Validation Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fHImfiSERH2",
        "outputId": "50610471-0a4c-4ef5-913b-d5d9e6557d55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 317ms/step\n",
            "R² Score: 0.6015\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"R² Score: {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc61iBzoEY73",
        "outputId": "373671b3-d604-4ae3-9c11-3758dd8a1a96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Comparison of predictions and ground truth:\n",
            "Sample 1:\n",
            "  Predicted:    [3 3 3 3 3 3 3 3 4 2 3 1 4 0 3 2 5 1 4 3 4 4 6 5 2 3 1 0 0 0 0 0]\n",
            "  Ground Truth: [5 6 5 1 3 4 1 1 6 2 3 1 4 0 3 2 5 1 4 3 4 4 6 5 2 3 1 0 0 0 0 0]\n",
            "----------------------------------------\n",
            "Sample 2:\n",
            "  Predicted:    [3 3 3 3 3 3 3 3 3 2 4 3 3 1 3 1 1 2 0 1 1 5 2 1 4 0 4 0 0 0 0 0]\n",
            "  Ground Truth: [1 4 1 3 3 3 0 5 5 2 4 3 3 1 3 1 1 2 0 1 1 5 2 1 4 0 4 0 0 0 0 0]\n",
            "----------------------------------------\n",
            "Sample 3:\n",
            "  Predicted:    [3 3 3 3 3 3 3 3 3 6 4 1 0 5 2 3 5 1 4 6 0 4 3 2 3 4 4 0 0 0 0 0]\n",
            "  Ground Truth: [2 6 0 2 2 1 3 4 2 6 4 1 0 5 2 3 5 1 4 6 0 4 3 2 3 4 4 0 0 0 0 0]\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test_rescaled = y_test * (q - 1)\n",
        "y_pred_rescaled = y_pred * (q - 1)\n",
        "\n",
        "print(\"Comparison of predictions and ground truth:\")\n",
        "for i in range(3):\n",
        "    print(f\"Sample {i+1}:\")\n",
        "    print(f\"  Predicted:    {np.round(y_pred_rescaled[i]).astype(int)}\")\n",
        "    print(f\"  Ground Truth: {np.round(y_test_rescaled[i]).astype(int)}\")\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjgc4S3JQ0Ix"
      },
      "source": [
        "Test on unseen samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XPHxylAQ4GV",
        "outputId": "25494dbc-34ae-4dc6-c3a3-ea95e856688f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 17700.17533602    +0.j            958.67427771+14545.05859731j\n",
            " -11067.68026502 +4750.16621573j  -7541.94219873 -8050.90562821j\n",
            "   4801.06762678 -8458.12148009j   8081.44036169 +1412.87970794j\n",
            "    909.73843657 +6296.7835732j   -2846.8320572  +2775.87690291j\n",
            "  -3741.2973968   +487.64736489j  -3997.29300812 -2951.21922264j\n",
            "   1247.21351285 -6986.82292053j   9126.05640729 -1748.64789028j\n",
            "   4268.0738087 +10289.38728272j  -8635.34104673 +6950.27874978j\n",
            " -10343.34361125 -6073.81272702j   3258.84443464-12644.40361606j\n",
            "  13345.0660992     -0.j           3258.84443464+12644.40361606j\n",
            " -10343.34361125 +6073.81272702j  -8635.34104673 -6950.27874978j\n",
            "   4268.0738087 -10289.38728272j   9126.05640729 +1748.64789028j\n",
            "   1247.21351285 +6986.82292053j  -3997.29300812 +2951.21922264j\n",
            "  -3741.2973968   -487.64736489j  -2846.8320572  -2775.87690291j\n",
            "    909.73843657 -6296.7835732j    8081.44036169 -1412.87970794j\n",
            "   4801.06762678 +8458.12148009j  -7541.94219873 +8050.90562821j\n",
            " -11067.68026502 -4750.16621573j    958.67427771-14545.05859731j]\n",
            "\n",
            "\n",
            "[ 17685.50621736    +0.j            958.13940474+14718.69027913j\n",
            " -10866.15121927 +4763.14132265j  -7638.88750337 -8213.44469659j\n",
            "   4812.97669571 -8414.04905691j   8088.60462578 +1416.30285088j\n",
            "    904.24712697 +6275.20847853j  -2788.76176949 +2780.92281477j\n",
            "  -3728.70610943  +480.84046464j  -3970.44026918 -2949.71443438j\n",
            "   1257.37336381 -6953.38451909j   9096.77506001 -1760.76472909j\n",
            "   4321.07322341+10240.94223445j  -8545.48734868 +6910.82724291j\n",
            " -10355.97287415 -6102.68051517j   3289.42109035-12749.3704538j\n",
            "  13510.5363654     +0.j           3284.75534607+12709.66018938j\n",
            " -10429.73324342 +5967.96477778j  -8643.31619231 -6937.56036626j\n",
            "   4288.36296969-10236.4848483j    9149.06506648 +1724.99392037j\n",
            "   1237.91961694 +6981.47374786j  -4008.74778817 +2924.17012263j\n",
            "  -3728.13302011  -482.10609168j  -2889.79686183 -2781.58494841j\n",
            "    909.91429078 -6204.02451263j   8137.73928965 -1394.19751892j\n",
            "   4814.65167321 +8484.11575432j  -7606.61274736 +8223.41299751j\n",
            " -11143.10786048 -4824.95659829j    972.92971852-14334.82181284j]\n"
          ]
        }
      ],
      "source": [
        "num_unseen_samples = 20\n",
        "x_unseen_original = np.random.randint(0, q, size=(num_unseen_samples, n))\n",
        "x_unseen_original_padded = np.pad(x_unseen_original, ((0, 0), (0, padding)), mode='constant', constant_values=0)\n",
        "\n",
        "encoded_dataset_unseen = np.array([np.dot(M_tilde, x) for x in x_unseen_original_padded])\n",
        "encoded_dataset_unseen[np.abs(encoded_dataset_unseen) < 1e-10] = 0\n",
        "encoded_dataset_unseen = np.round(encoded_dataset_unseen, decimals=10)\n",
        "\n",
        "# add some noise to simulate channel distortion\n",
        "noise_ratio = 0.01\n",
        "real_parts = np.real(encoded_dataset_unseen)\n",
        "imag_parts = np.imag(encoded_dataset_unseen)\n",
        "noise_std_real = np.abs(real_parts) * noise_ratio\n",
        "noise_std_imag = np.abs(imag_parts) * noise_ratio\n",
        "noise_real = np.random.normal(0, noise_std_real, size=encoded_dataset_unseen.shape)\n",
        "noise_imag = np.random.normal(0, noise_std_imag, size=encoded_dataset_unseen.shape)\n",
        "noise = noise_real + 1j * noise_imag\n",
        "\n",
        "encoded_noisy = encoded_dataset_unseen + noise\n",
        "\n",
        "print(encoded_dataset_unseen[0])\n",
        "print(\"\\n\")\n",
        "print(encoded_noisy[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3nJbA-y-ZXc",
        "outputId": "d7d3724f-bf39-4ddb-c8d9-5eef6f02ab9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 3128.97850207   417.80292772 -2637.19716272 -2160.40631628\n",
            "   764.67970384  2045.63787182   674.60629805  -436.31326629\n",
            "  -817.47338064 -1218.82972282  -548.40535184  1732.1737495\n",
            "  2316.31274132  -698.92368709 -2962.17468438 -1519.20450647\n",
            "  2359.09668353  2889.34781282  -466.65674826 -2681.64572333\n",
            " -1546.02452359  1547.89899174  1687.44002098   239.70189834\n",
            "  -470.5649872   -893.1698145  -1440.39076453   148.27308981\n",
            "  2308.06071922  1714.28349356 -1453.02880918 -3620.12463   ]\n",
            "\n",
            "\n",
            "[ 3126.38534375   419.79929625 -2586.73955992 -2190.34267946\n",
            "   769.74928953  2047.58320081   671.72685429  -422.21935348\n",
            "  -815.21639446 -1212.60023073  -542.22461636  1724.33756215\n",
            "  2320.60093533  -686.75620414 -2969.19370517 -1531.16340956\n",
            "  2388.34797036  2905.78597183  -500.81339168 -2680.27954514\n",
            " -1532.20981845  1545.78402376  1685.16535565   232.36448675\n",
            "  -468.02567276  -898.13201027 -1418.18678094   156.22354753\n",
            "  2315.0969486   1754.57126786 -1473.48467009 -3567.4538734 ]\n"
          ]
        }
      ],
      "source": [
        "# projection to get real-valued DCT-2 like input\n",
        "N = encoded_dataset_unseen.shape[1]\n",
        "\n",
        "k = np.arange(N)\n",
        "shift = np.exp(-1j * np.pi * k / (2 * N))\n",
        "alpha_k = np.where(k == 0, np.sqrt(1/N), np.sqrt(2/N))\n",
        "\n",
        "x_unseen_dct2 = np.array([np.real(alpha_k * shift * y) for y in encoded_dataset_unseen])\n",
        "x_unseen_dct2[np.abs(x_unseen_dct2) < 1e-10] = 0\n",
        "x_unseen_dct2 = np.round(x_unseen_dct2, decimals=10) # for numerical stability\n",
        "\n",
        "x_unseen_dct2_noisy = np.array([np.real(alpha_k * shift * y) for y in encoded_noisy])\n",
        "x_unseen_dct2_noisy[np.abs(x_unseen_dct2_noisy) < 1e-10] = 0\n",
        "x_unseen_dct2_noisy = np.round(x_unseen_dct2_noisy, decimals=10) # for numerical stability\n",
        "\n",
        "print(x_unseen_dct2[0])\n",
        "print(\"\\n\")\n",
        "print(x_unseen_dct2_noisy[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "id": "PmZu8EKvTttT"
      },
      "outputs": [],
      "source": [
        "# classical algorithm\n",
        "from scipy.fft import ifft\n",
        "\n",
        "def lrc(y, n, q, r, w0, z0):\n",
        "    if n >= 2:\n",
        "        z1 = ifft(y, n)\n",
        "\n",
        "        D_hat_n = np.diag([(z0 / w0) ** k for k in range(n)])\n",
        "        z2 = np.dot(D_hat_n, z1)\n",
        "\n",
        "        J_rxn = np.hstack([np.eye(r), np.zeros((r, n - r))])\n",
        "        z3 = np.dot(J_rxn, z2)\n",
        "\n",
        "        z4 = np.abs(z3)\n",
        "\n",
        "        # z5 = np.ceil(z4)\n",
        "        z5 = np.round(z4)\n",
        "\n",
        "        x_tilde = np.mod(z5, q)\n",
        "\n",
        "        return x_tilde\n",
        "\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhXXYUbREbRz",
        "outputId": "13f81376-241c-4ebc-923b-eea88824f07b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625ms/step\n",
            "\n",
            "Classical DCT-III:\n",
            "  MSE: 15.607465744018555\n",
            "  Accuracy: 0.39814814925193787\n",
            "\n",
            "Classical Algorithm:\n",
            "  MSE: 1.9171874523162842\n",
            "  Accuracy: 0.6592592597007751\n",
            "\n",
            "Neural Network:\n",
            "  MSE: 3.604687452316284\n",
            "  Accuracy: 0.49259260296821594\n",
            "\n",
            "Sample 1:\n",
            "Original     : [0 5 3 5 5 5 3 5 3 4 6 0 1 5 2 4 2 1 3 1 2 1 0 1 5 0 5 0 0 0 0 0]\n",
            "Classical Al : [0 1 2 4 6 0 5 3 3 3 5 1 1 6 2 4 2 1 3 1 2 1 0 1 5 0 5 0 0 0 0 0]\n",
            "NN Pred      : [3 3 3 3 3 3 4 3 3 3 0 0 1 0 3 5 2 1 3 1 2 1 0 1 6 0 6 0 0 0 0 0]\n",
            "\n",
            "Sample 2:\n",
            "Original     : [6 6 1 0 0 6 1 4 3 3 3 0 6 3 6 0 6 4 1 6 6 1 0 0 6 4 3 0 0 0 0 0]\n",
            "Classical Al : [0 3 3 1 1 4 1 5 3 2 2 1 6 3 6 0 6 4 1 6 6 1 0 0 6 4 3 0 0 0 0 0]\n",
            "NN Pred      : [3 3 3 3 3 3 3 4 2 3 2 0 6 3 6 0 0 4 1 0 0 1 0 0 0 4 3 0 0 0 0 0]\n",
            "\n",
            "Sample 3:\n",
            "Original     : [4 1 1 5 3 6 1 5 0 1 2 3 5 3 3 2 4 0 3 1 0 1 0 6 0 5 1 0 0 0 0 0]\n",
            "Classical Al : [0 0 4 6 4 0 4 4 2 1 3 3 5 3 3 2 4 0 3 1 0 1 0 6 0 5 1 0 0 0 0 0]\n",
            "NN Pred      : [3 3 3 3 3 3 3 3 3 2 1 3 6 3 3 3 5 0 3 1 0 1 0 0 0 6 1 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "############## just to compare with classical dct3 ##############\n",
        "\n",
        "classical_dct3_pred = np.array([dct(x, type=3, norm='ortho') for x in x_unseen_dct2_noisy])\n",
        "after_perm = np.hstack((classical_dct3_pred[:, ::2], classical_dct3_pred[:, 1::2][:, ::-1]))\n",
        "D_hat_n = np.array([(z0 / w0) ** k for k in range(N)])\n",
        "scaled_dct3_pred = after_perm * D_hat_n\n",
        "\n",
        "mse_classical_dct3 = custom_mse(x_unseen_original_padded, scaled_dct3_pred)\n",
        "acc_classical_dct3 = custom_accuracy_without_padding(x_unseen_original_padded, scaled_dct3_pred)\n",
        "\n",
        "############## classical algorithm for recovery (here we assume the classical algorithm can also be used for global recovery. just to compare) ##############\n",
        "\n",
        "classical_pred = np.array([lrc(y=x, n=n_padded, q=q, r=n_padded, w0=w0, z0=z0) for x in encoded_noisy])\n",
        "mse_classical = custom_mse(x_unseen_original_padded, classical_pred)\n",
        "acc_classical = custom_accuracy_without_padding(x_unseen_original_padded, classical_pred)\n",
        "\n",
        "############## predictions of our StNN ##############\n",
        "\n",
        "x_unseen_original_padded_normalized = x_unseen_original_padded.astype(np.float32) / (q - 1)  # Scale to [0, 1]\n",
        "\n",
        "x_unseen_dct2_noisy = (x_unseen_dct2_noisy - x_unseen_dct2_noisy.mean()) / x_unseen_dct2_noisy.std()\n",
        "nn_pred = model.predict(x_unseen_dct2_noisy)\n",
        "\n",
        "y_pred_final = np.mod(np.round(nn_pred * (q - 1)), q)\n",
        "\n",
        "mse_nn = custom_mse(x_unseen_original_padded, y_pred_final)\n",
        "acc_nn = custom_accuracy_without_padding(x_unseen_original_padded_normalized, nn_pred)\n",
        "\n",
        "############## display ##############\n",
        "\n",
        "print(f\"\\nClassical DCT-III:\")\n",
        "print(f\"  MSE: {mse_classical_dct3}\")\n",
        "print(f\"  Accuracy: {acc_classical_dct3}\")\n",
        "\n",
        "print(f\"\\nClassical Algorithm:\")\n",
        "print(f\"  MSE: {mse_classical}\")\n",
        "print(f\"  Accuracy: {acc_classical}\")\n",
        "\n",
        "print(f\"\\nNeural Network:\")\n",
        "print(f\"  MSE: {mse_nn}\")\n",
        "print(f\"  Accuracy: {acc_nn}\")\n",
        "\n",
        "num_display_samples = 3\n",
        "for i in range(num_display_samples):\n",
        "    print(f\"\\nSample {i+1}:\")\n",
        "    print(f\"Original     : {x_unseen_original_padded[i]}\")\n",
        "    # print(f\"DCT-III Pred : {np.round(scaled_dct3_pred[i]).astype(int)}\")\n",
        "    print(f\"Classical Al : {np.round(classical_pred[i]).astype(int)}\")\n",
        "    print(f\"NN Pred      : {np.mod(np.round(nn_pred[i]*(q-1)), q).astype(int)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8BovHaCR0xB"
      },
      "source": [
        "Visualize and Analyse model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 847
        },
        "id": "LUT9w-n75IKZ",
        "outputId": "e1d46e30-6d4c-4b70-bd34-3a3e4dd20e6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([1.479e+03, 5.700e+01, 7.000e+00, 1.700e+01, 1.000e+01, 3.700e+01,\n",
              "        2.040e+02, 2.320e+02, 4.600e+01, 6.000e+00, 3.000e+00, 4.000e+00,\n",
              "        1.800e+01, 1.260e+02, 2.970e+02, 1.050e+02, 2.900e+01, 3.700e+01,\n",
              "        6.300e+01, 8.500e+01, 2.470e+02, 8.860e+02, 5.640e+02, 1.460e+02,\n",
              "        5.700e+01, 3.900e+01, 4.400e+01, 4.700e+01, 1.890e+02, 2.760e+02,\n",
              "        4.900e+01, 8.000e+00, 3.000e+00, 2.000e+00, 1.300e+01, 9.500e+01,\n",
              "        3.100e+02, 6.400e+01, 1.200e+01, 8.000e+00, 2.000e+00, 1.000e+01,\n",
              "        5.000e+01, 2.510e+02, 1.070e+02, 2.300e+01, 1.600e+01, 1.200e+01,\n",
              "        7.000e+00, 1.000e+00]),\n",
              " array([-1.05405517e-03,  2.22476535e-02,  4.55493629e-02,  6.88510761e-02,\n",
              "         9.21527818e-02,  1.15454488e-01,  1.38756216e-01,  1.62057921e-01,\n",
              "         1.85359627e-01,  2.08661333e-01,  2.31963038e-01,  2.55264759e-01,\n",
              "         2.78566480e-01,  3.01868170e-01,  3.25169891e-01,  3.48471582e-01,\n",
              "         3.71773303e-01,  3.95075023e-01,  4.18376714e-01,  4.41678435e-01,\n",
              "         4.64980125e-01,  4.88281846e-01,  5.11583567e-01,  5.34885287e-01,\n",
              "         5.58187008e-01,  5.81488669e-01,  6.04790390e-01,  6.28092110e-01,\n",
              "         6.51393831e-01,  6.74695551e-01,  6.97997212e-01,  7.21298933e-01,\n",
              "         7.44600654e-01,  7.67902374e-01,  7.91204095e-01,  8.14505756e-01,\n",
              "         8.37807477e-01,  8.61109197e-01,  8.84410918e-01,  9.07712638e-01,\n",
              "         9.31014299e-01,  9.54316020e-01,  9.77617741e-01,  1.00091946e+00,\n",
              "         1.02422118e+00,  1.04752290e+00,  1.07082462e+00,  1.09412634e+00,\n",
              "         1.11742806e+00,  1.14072967e+00,  1.16403139e+00]),\n",
              " <BarContainer object of 50 artists>)"
            ]
          },
          "execution_count": 267,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(y_pred.flatten(), bins=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORZAY2sdoc3a",
        "outputId": "e48db347-0c4f-419a-c82a-2bd021b50f0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first_layer - Variable 0 (B_1): values: [1.5617666  1.0402123  1.0186718  1.0366426  1.0704058  1.0300487\n",
            " 1.0298858  1.0538523  1.1174018  1.0451584  1.0538269  1.0444632\n",
            " 1.0413015  1.0138091  1.0191019  0.98636407]\n",
            "first_layer - Variable 1 (B_2): values: [1.        1.0225952 1.0200723 1.0117565 1.0585263 1.0251638 1.0272615\n",
            " 1.0368515 1.1155035 1.0334078 1.050324  1.0526329 1.0276366 1.017031\n",
            " 1.0607955 1.0248648]\n",
            "first_layer - Variable 2 (bias): values: [-0.09495096  0.15015669  0.0446674  -0.03476667  0.05724891 -0.03577304\n",
            "  0.04303388  0.01933845  0.02384249  0.03326129  0.08459681  0.04572241\n",
            "  0.07154721  0.11122643  0.04201946  0.20667669  0.16571103  0.07630511\n",
            " -0.03237079 -0.00876974  0.01115838 -0.00326111 -0.00258211  0.0107482\n",
            " -0.00091992  0.0064886   0.03897548 -0.01453951  0.00649328  0.0180587\n",
            " -0.01861875 -0.00567097]\n",
            "second_layer - Variable 0 (bias): values: [ 0.06628799  0.07976314  0.07266404  0.05792183  0.07933764  0.06066126\n",
            "  0.04880022  0.05479135  0.05301251  0.05838402  0.02342447 -0.1078592\n",
            "  0.0069986  -0.02342832  0.04918904  0.04300948  0.21508497 -0.03063614\n",
            "  0.22947952 -0.01135975  0.22371326 -0.03626778  0.14727652 -0.04040636\n",
            "  0.11660548 -0.05125041  0.06313401 -0.184388    0.04400134 -0.10205418\n",
            "  0.00986698 -0.01037886]\n",
            "second_layer - Variable 1 (B_1): values: [1.4883349 1.0463173 1.0398208 1.0410945 1.1074258 1.0573239 1.0471542\n",
            " 1.0805867]\n",
            "second_layer - Variable 2 (B_2): values: [1.        0.996104  1.0283827 1.0104023 1.065903  1.0626707 1.0099066\n",
            " 0.9931074]\n",
            "second_layer - Variable 3 (W_c): values: [0.56885713 0.6342837  0.68963134 0.7256304  0.8586096  1.2863035\n",
            " 2.0778742  5.3350973 ]\n",
            "second_layer - Variable 4 (B_1): values: [1.5089834 1.0803179 1.0739753 1.035677 ]\n",
            "second_layer - Variable 5 (B_2): values: [1.        1.0034311 1.068074  1.023602 ]\n",
            "second_layer - Variable 6 (W_c): values: [0.58208364 0.7144036  1.0679748  2.6798537 ]\n",
            "second_layer - Variable 7 (B_1): values: [1.5241215 1.1970832]\n",
            "second_layer - Variable 8 (B_2): values: [1.         0.98330206]\n",
            "second_layer - Variable 9 (W_c): values: [0.6121715 1.5142808]\n",
            "second_layer - Variable 10 (C_2): values: [[ 0.84277886  0.9289893 ]\n",
            " [ 0.9632163  -1.0908095 ]]\n",
            "second_layer - Variable 11 (C_2): values: [[ 0.8272361   0.698166  ]\n",
            " [ 0.7719507  -0.79167384]]\n",
            "second_layer - Variable 12 (B_1): values: [1.4396536 1.0712179]\n",
            "second_layer - Variable 13 (B_2): values: [1.        0.9982855]\n",
            "second_layer - Variable 14 (W_c): values: [0.57176614 1.4725289 ]\n",
            "second_layer - Variable 15 (C_2): values: [[ 0.7550863   0.79147595]\n",
            " [ 0.8529677  -0.8728117 ]]\n",
            "second_layer - Variable 16 (C_2): values: [[ 0.75123125  0.7240511 ]\n",
            " [ 0.73777163 -0.74003667]]\n",
            "second_layer - Variable 17 (B_1): values: [1.4662938 1.0394698 1.0443339 1.0228693]\n",
            "second_layer - Variable 18 (B_2): values: [1.        0.9990056 1.0370041 1.0025629]\n",
            "second_layer - Variable 19 (W_c): values: [0.5317193  0.6510859  0.98611325 2.5696604 ]\n",
            "second_layer - Variable 20 (B_1): values: [1.4632618 1.0833601]\n",
            "second_layer - Variable 21 (B_2): values: [1.        1.0004919]\n",
            "second_layer - Variable 22 (W_c): values: [0.5702277 1.4136415]\n",
            "second_layer - Variable 23 (C_2): values: [[ 0.7433032   0.78354543]\n",
            " [ 0.8134185  -0.83744437]]\n",
            "second_layer - Variable 24 (C_2): values: [[ 0.7452758   0.7224504 ]\n",
            " [ 0.7439533  -0.74600637]]\n",
            "second_layer - Variable 25 (B_1): values: [1.4490771 1.046374 ]\n",
            "second_layer - Variable 26 (B_2): values: [1.        1.0040083]\n",
            "second_layer - Variable 27 (W_c): values: [0.55541   1.3620523]\n",
            "second_layer - Variable 28 (C_2): values: [[ 0.72477126  0.7475607 ]\n",
            " [ 0.77034485 -0.7559886 ]]\n",
            "second_layer - Variable 29 (C_2): values: [[ 0.72260755  0.71670204]\n",
            " [ 0.7166701  -0.7164819 ]]\n",
            "second_layer - Variable 30 (B_1): values: [1.5116041  1.0233306  1.0488943  1.0123516  1.0840174  1.0531267\n",
            " 1.0295908  0.99438924]\n",
            "second_layer - Variable 31 (B_2): values: [1.         0.99458957 1.0265397  1.019864   1.0605695  1.0582206\n",
            " 1.0057734  1.0833366 ]\n",
            "second_layer - Variable 32 (W_c): values: [0.55410075 0.63175565 0.6878995  0.68711674 0.85697997 1.2898617\n",
            " 2.0830011  5.5017443 ]\n",
            "second_layer - Variable 33 (B_1): values: [1.5309303 1.0529433 1.0609616 1.0225936]\n",
            "second_layer - Variable 34 (B_2): values: [1.        1.0204018 1.0551474 1.0300385]\n",
            "second_layer - Variable 35 (W_c): values: [0.5516084  0.72031075 1.064551   2.6548524 ]\n",
            "second_layer - Variable 36 (B_1): values: [1.5143713 1.1410997]\n",
            "second_layer - Variable 37 (B_2): values: [1.        0.9972637]\n",
            "second_layer - Variable 38 (W_c): values: [0.5965888 1.5931073]\n",
            "second_layer - Variable 39 (C_2): values: [[ 0.8171414  0.8496799]\n",
            " [ 1.0133334 -1.0253693]]\n",
            "second_layer - Variable 40 (C_2): values: [[ 0.789954    0.71969116]\n",
            " [ 0.76483625 -0.7927026 ]]\n",
            "second_layer - Variable 41 (B_1): values: [1.4844184 1.0636013]\n",
            "second_layer - Variable 42 (B_2): values: [1.        1.0109166]\n",
            "second_layer - Variable 43 (W_c): values: [0.5699945 1.4613681]\n",
            "second_layer - Variable 44 (C_2): values: [[ 0.7657322   0.78930724]\n",
            " [ 0.8642921  -0.875941  ]]\n",
            "second_layer - Variable 45 (C_2): values: [[ 0.7551461   0.71855253]\n",
            " [ 0.741372   -0.7498677 ]]\n",
            "second_layer - Variable 46 (B_1): values: [1.4814807 1.0433035 1.0292825 1.0266626]\n",
            "second_layer - Variable 47 (B_2): values: [1.         1.0100178  1.0541269  0.99419045]\n",
            "second_layer - Variable 48 (W_c): values: [0.5246194  0.66688883 0.96327317 2.612615  ]\n",
            "second_layer - Variable 49 (B_1): values: [1.464467  1.1018147]\n",
            "second_layer - Variable 50 (B_2): values: [1.        1.0092965]\n",
            "second_layer - Variable 51 (W_c): values: [0.5679839 1.4398495]\n",
            "second_layer - Variable 52 (C_2): values: [[ 0.7449999  0.764423 ]\n",
            " [ 0.8548619 -0.8462956]]\n",
            "second_layer - Variable 53 (C_2): values: [[ 0.75023156  0.7092058 ]\n",
            " [ 0.7457026  -0.74031436]]\n",
            "second_layer - Variable 54 (B_1): values: [1.467126  1.0345033]\n",
            "second_layer - Variable 55 (B_2): values: [1.         0.99368054]\n",
            "second_layer - Variable 56 (W_c): values: [0.55468357 1.34587   ]\n",
            "second_layer - Variable 57 (C_2): values: [[ 0.7416961   0.73979574]\n",
            " [ 0.7951734  -0.7770013 ]]\n",
            "second_layer - Variable 58 (C_2): values: [[ 0.72714907  0.7229846 ]\n",
            " [ 0.7211045  -0.7319119 ]]\n",
            "third_layer - Variable 0 (W_c): values: [0.5581186  1.1225681  0.48849666 1.3272617  0.516235   1.3092579\n",
            " 0.5882572  1.5138439  0.73669696 1.5389496  0.9265389  1.1437318\n",
            " 1.4926997  1.9794639  3.2357762  9.931543  ]\n",
            "third_layer - Variable 1 (bias): values: [ 0.12828414  0.17042908  0.1352766  -0.09286073  0.13731937  0.03205708\n",
            "  0.09138078  0.05573551  0.08421803  0.10124921  0.0419465   0.14515765\n",
            "  0.02591589  0.27089268  0.02841559  0.15160263  0.02760277  0.23498943\n",
            "  0.0340718   0.19560672  0.04699143  0.17511044  0.05840072  0.09160242\n",
            "  0.05482861  0.06853682  0.06070792  0.0095701   0.05801605 -0.04501771\n",
            "  0.07961254 -0.0247895 ]\n",
            "leaky_re_lu_2 has no trainable variables.\n",
            "scaling_layer - Variable 0 (log_scale): values: 0.223085418343544\n",
            "scaling_layer - Variable 1 (diag): values: [ 6.41269624e-01  6.99787199e-01  6.53380871e-01  7.55544722e-01\n",
            "  7.76481032e-01  9.15261745e-01  1.03089595e+00  1.27326918e+00\n",
            "  1.09912574e+00  1.79837430e+00  1.63298750e+00  5.07497549e-01\n",
            "  3.08386654e-01  1.47193670e-01  1.00039534e-01  5.28372563e-02\n",
            "  5.87496758e-02  3.19018997e-02  2.35479660e-02  1.14843808e-02\n",
            "  8.10731668e-03  4.11016075e-03  2.94018094e-03  1.48590747e-03\n",
            "  1.03870453e-03  5.37899439e-04  3.95595678e-04 -1.75192667e-07\n",
            " -2.08863309e-12 -3.43028672e-09 -5.03432140e-09 -2.13254132e-12]\n",
            "scaling_layer - Variable 2 (bias): values: [ 1.3750914e-01  1.2432172e-01  1.1338832e-01  7.1188539e-02\n",
            "  4.8970081e-02  3.9768014e-02  3.4459397e-02  4.5021247e-02\n",
            "  3.5033543e-02  4.5531150e-02  2.6251012e-02  1.3356523e-02\n",
            "  6.4388635e-03  1.6821007e-03  1.4343391e-03  1.0279210e-03\n",
            "  1.5534721e-03  2.6927672e-03  2.9802311e-03  3.2015718e-03\n",
            "  5.2902997e-03  4.1193371e-03  4.7959546e-03 -7.5212740e-03\n",
            " -9.5514888e-03  1.4141646e-02  2.7559301e-02 -2.0051366e-06\n",
            " -2.0559304e-11 -6.5999082e-08 -1.0805295e-07 -6.7039312e-11]\n",
            "leaky_re_lu_3 has no trainable variables.\n",
            "output_layer has no trainable variables.\n",
            "activation_1 has no trainable variables.\n"
          ]
        }
      ],
      "source": [
        "for layer in model.layers:\n",
        "    if layer.trainable_variables:  # Check if the layer has trainable variables\n",
        "        for i, var in enumerate(layer.trainable_variables):\n",
        "            print(f\"{layer.name} - Variable {i} ({var.name}): values: {var.numpy()}\")\n",
        "    else:\n",
        "        print(layer.name, \"has no trainable variables.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "id": "iIDKNMn9P4aW"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "K.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "id": "qfK5aX4sZt2Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
